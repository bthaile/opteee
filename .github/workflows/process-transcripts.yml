name: Process Video Transcripts Weekly

on:
  schedule:
    - cron: '0 20 * * 0'  # Run at 8:00 PM UTC every Sunday (3:00 PM CT, avoiding DST issues)
  workflow_dispatch:  # Allow manual triggering of the workflow

jobs:
  process-transcripts:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # 3 hours timeout for large transcript processing
    permissions:
      contents: write  # Add explicit write permission
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch all history for proper git operations
          token: ${{ secrets.GITHUB_TOKEN }}  # Use token for checkout

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create necessary directories
        run: |
          mkdir -p transcripts
          mkdir -p processed_transcripts
          mkdir -p audio_files

      - name: Run video discovery
        env:
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
        run: |
          echo " Step 1: Discovering videos..."
          python3 run_pipeline.py --step scrape --non-interactive
          echo " Video discovery completed"

      - name: Run transcript generation
        env:
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
        run: |
          echo "ðŸŽ¤ Step 2: Generating transcripts..."
          python3 run_pipeline.py --step transcripts --non-interactive
          echo " Transcript generation completed"

      - name: Run transcript preprocessing
        env:
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
        run: |
          echo " Step 3: Processing transcripts into chunks..."
          python3 run_pipeline.py --step preprocess --non-interactive
          echo " Transcript preprocessing completed"

      - name: Verify processing outputs
        run: |
          echo "ðŸ“Š Verifying processing outputs..."
          
          # Check video discovery
          if [ -f "outlier_trading_videos.json" ]; then
            VIDEO_COUNT=$(python3 -c "import json; print(len(json.load(open('outlier_trading_videos.json'))))")
            echo " Videos discovered: $VIDEO_COUNT"
          else
            echo "âŒ No video data found"
          fi
          
          # Check transcripts
          if [ -d "transcripts" ]; then
            TRANSCRIPT_COUNT=$(find transcripts -name "*.txt" | wc -l)
            echo " Transcripts generated: $TRANSCRIPT_COUNT"
          else
            echo "âŒ No transcripts directory found"
          fi
          
          # Check processed transcripts
          if [ -d "processed_transcripts" ]; then
            PROCESSED_COUNT=$(find processed_transcripts -name "*.json" | wc -l)
            echo " Processed transcript files: $PROCESSED_COUNT"
          else
            echo "âŒ No processed transcripts directory found"
          fi
          
          # Note: Vector store creation happens on Hugging Face during Docker build
          echo "â„¹ï¸  Vector store will be created by Hugging Face during Docker build"

      - name: Run system validation
        run: |
          echo " Running system validation..."
          python3 validate_system.py || echo "âš ï¸ System validation had issues (non-critical)"

      - name: Generate processing report
        run: |
          echo "ðŸ“‹ Generating processing report..."
          cat > processing_report.md << 'EOF'
          # Weekly Transcript Processing Report
          
          **Processing Date:** $(date '+%Y-%m-%d %H:%M:%S UTC')
          **Pipeline Version:** GitHub Actions (Steps 1-3 only)
          
          ## Processing Summary
          
          - **Videos Discovered:** $(python3 -c "import json; print(len(json.load(open('outlier_trading_videos.json'))))" 2>/dev/null || echo "0")
          - **Transcripts Generated:** $(find transcripts -name "*.txt" 2>/dev/null | wc -l)
          - **Processed Chunks:** $(find processed_transcripts -name "*.json" 2>/dev/null | wc -l)
          - **Vector Store:** Created by Hugging Face during Docker build
          
          ## Processing Configuration
          
          - **Chunk Size:** 250 words
          - **Overlap:** 50 words
          - **Processing Mode:** Non-interactive (CI/CD)
          - **Architecture:** GitHub Actions handles transcripts, Hugging Face handles vector store
          
          ## Files Updated
          
          - `outlier_trading_videos.json` - Video metadata
          - `transcripts/` - Raw transcript files
          - `processed_transcripts/` - Chunked transcript data
          
          ## Next Steps
          
          - Vector store creation happens automatically on Hugging Face during Docker build
          - Hugging Face deployment will be triggered after this workflow completes
          
          ---
          *This report was generated automatically by GitHub Actions*
          EOF

      - name: Check for changes
        id: check_changes
        run: |
          git add .
          if git diff --staged --quiet; then
            echo "changes=false" >> $GITHUB_OUTPUT
            echo "No changes to commit"
          else
            echo "changes=true" >> $GITHUB_OUTPUT
            echo "Changes detected, preparing to commit"
          fi

      - name: Commit and push changes
        if: steps.check_changes.outputs.changes == 'true'
        run: |
          git config --global user.email "github-actions@github.com"
          git config --global user.name "GitHub Actions Bot"
          
          # Add all generated files
          git add .
          
          # Create commit message with details
          COMMIT_MSG="Weekly transcript update $(date +'%Y-%m-%d')

          Automated processing results:
          - Videos: $(python3 -c "import json; print(len(json.load(open('outlier_trading_videos.json'))))" 2>/dev/null || echo "0")
          - Transcripts: $(find transcripts -name "*.txt" 2>/dev/null | wc -l)
          - Processed: $(find processed_transcripts -name "*.json" 2>/dev/null | wc -l)
          - Vector store: Built by Hugging Face during Docker deployment
          
          Generated by: GitHub Actions workflow"
          
          git commit -m "$COMMIT_MSG"
          git push

      - name: Trigger Hugging Face deployment
        if: steps.check_changes.outputs.changes == 'true'
        uses: peter-evans/repository-dispatch@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          event-type: transcript-update
          client-payload: '{"updated_files": ["transcripts", "processed_transcripts"]}'

      - name: Create workflow summary
        if: always()
        run: |
          echo "## ðŸŽ¯ Weekly Transcript Processing Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Date:** $(date '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "**Status:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“Š Processing Results" >> $GITHUB_STEP_SUMMARY
          echo "- Videos discovered: $(python3 -c "import json; print(len(json.load(open('outlier_trading_videos.json'))))" 2>/dev/null || echo "0")" >> $GITHUB_STEP_SUMMARY
          echo "- Transcripts generated: $(find transcripts -name "*.txt" 2>/dev/null | wc -l)" >> $GITHUB_STEP_SUMMARY
          echo "- Processed chunks: $(find processed_transcripts -name "*.json" 2>/dev/null | wc -l)" >> $GITHUB_STEP_SUMMARY
          echo "- Vector store: Built by Hugging Face during Docker deployment" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ”„ Changes Committed" >> $GITHUB_STEP_SUMMARY
          echo "- Changes detected: ${{ steps.check_changes.outputs.changes }}" >> $GITHUB_STEP_SUMMARY
          echo "- Hugging Face deployment: ${{ steps.check_changes.outputs.changes == 'true' && 'Triggered' || 'Skipped' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ—ï¸ Architecture" >> $GITHUB_STEP_SUMMARY
          echo "- GitHub Actions: Video discovery, transcript generation, text processing" >> $GITHUB_STEP_SUMMARY
          echo "- Hugging Face: Vector store creation during Docker build" >> $GITHUB_STEP_SUMMARY 