name: Deploy to Hugging Face Space

on:
  push:
    branches: [ main ]
  workflow_dispatch:  # Allows manual triggering

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 1  # Only fetch the latest commit

      - name: Configure Git
        run: |
          git config --global user.email "github-actions@github.com"
          git config --global user.name "GitHub Actions"
          # Set default branch name to main
          git config --global init.defaultBranch main
          
      - name: Create Hugging Face specific files
        run: |
          # Create packages.txt for system dependencies
          echo "" > packages.txt
          
          # Create requirements.txt with all necessary dependencies
          cat > requirements.txt <<EOF
          # Core dependencies with pinned versions
          flask==2.0.1
          Werkzeug==2.0.1
          Jinja2==3.0.1
          itsdangerous==2.0.1
          click==8.0.1
          python-dotenv==0.21.0
          
          # Vector search dependencies
          numpy==1.23.5
          sentence-transformers==2.1.0
          faiss-cpu==1.7.3
          torch==1.13.1
          
          # Utility libraries
          markdown==3.3.7
          tqdm==4.66.1
          EOF
          
          # Create runtime_requirements.txt with exact versions for runtime
          cat > runtime_requirements.txt <<EOF
          # Exact versions for runtime compatibility
          huggingface_hub==0.10.1
          transformers==4.20.1
          tokenizers==0.12.1
          sentence_transformers==2.1.0
          faiss-cpu==1.7.3
          EOF
          
          # Create directory structure for static files and templates
          mkdir -p static templates
          
          # Create CSS file
          cat > static/styles.css <<'EOF'
          :root {
              --bg-color: #f9f9f9;
              --container-bg: #ffffff;
              --text-color: #333333;
              --highlight-color: #4CAF50;
              --highlight-hover: #45a049;
              --border-color: #e1e1e1;
              --tab-bg: #f1f1f1;
              --tab-active: #dddddd;
              --notice-bg: #fffbea;
              --notice-border: #f0b429;
              --result-bg: #ffffff;
              --meta-color: #666666;
          }
          
          [data-theme="dark"] {
              --bg-color: #121212;
              --container-bg: #1e1e1e;
              --text-color: #e0e0e0;
              --highlight-color: #5cb85c;
              --highlight-hover: #449d44;
              --border-color: #333333;
              --tab-bg: #2a2a2a;
              --tab-active: #3a3a3a;
              --notice-bg: #2c2500;
              --notice-border: #b58603;
              --result-bg: #2a2a2a;
              --meta-color: #aaaaaa;
          }
          
          body { 
              font-family: Arial, sans-serif; 
              max-width: 800px; 
              margin: 0 auto; 
              padding: 20px;
              line-height: 1.6;
              background-color: var(--bg-color);
              color: var(--text-color);
              transition: background-color 0.3s ease, color 0.3s ease;
          }
          
          .container { 
              background-color: var(--container-bg); 
              padding: 20px; 
              border-radius: 8px;
              box-shadow: 0 2px 4px rgba(0,0,0,0.1);
          }
          
          .search-box {
              width: 100%;
              padding: 12px;
              margin: 8px 0;
              box-sizing: border-box;
              border: 2px solid var(--border-color);
              border-radius: 4px;
              font-size: 16px;
              background-color: var(--container-bg);
              color: var(--text-color);
          }
          
          .button {
              background-color: var(--highlight-color);
              color: white;
              padding: 12px 20px;
              border: none;
              border-radius: 4px;
              cursor: pointer;
              font-size: 16px;
          }
          
          .button:hover {
              background-color: var(--highlight-hover);
          }
          
          .tab {
              overflow: hidden;
              border: 1px solid var(--border-color);
              background-color: var(--tab-bg);
              border-radius: 4px 4px 0 0;
          }
          
          .tab button {
              background-color: inherit;
              float: left;
              border: none;
              outline: none;
              cursor: pointer;
              padding: 14px 16px;
              transition: 0.3s;
              font-size: 16px;
              color: var(--text-color);
          }
          
          .tab button:hover {
              background-color: var(--tab-active);
          }
          
          .tab button.active {
              background-color: var(--tab-active);
          }
          
          .tabcontent {
              display: none;
              padding: 20px;
              border: 1px solid var(--border-color);
              border-top: none;
              border-radius: 0 0 4px 4px;
              animation: fadeEffect 1s;
              background-color: var(--container-bg);
          }
          
          @keyframes fadeEffect {
              from {opacity: 0;}
              to {opacity: 1;}
          }
          
          #results {
              margin-top: 20px;
          }
          
          .result-item {
              margin-bottom: 20px;
              padding: 15px;
              border: 1px solid var(--border-color);
              border-radius: 4px;
              background-color: var(--result-bg);
          }
          
          .result-title {
              font-weight: bold;
              font-size: 18px;
              margin-bottom: 5px;
          }
          
          .result-meta {
              font-size: 14px;
              color: var(--meta-color);
              margin-bottom: 10px;
          }
          
          .result-content {
              margin-top: 10px;
          }
          
          .unavailable {
              color: var(--meta-color);
              font-style: italic;
          }
          
          .maintenance-notice {
              background-color: var(--notice-bg);
              border-left: 4px solid var(--notice-border);
              padding: 12px;
              margin-bottom: 20px;
          }
          
          .theme-toggle {
              position: absolute;
              top: 20px;
              right: 20px;
              background-color: var(--tab-bg);
              border: 1px solid var(--border-color);
              border-radius: 20px;
              padding: 5px 10px;
              cursor: pointer;
              font-size: 14px;
              color: var(--text-color);
              display: flex;
              align-items: center;
          }
          
          .theme-toggle:hover {
              background-color: var(--tab-active);
          }
          
          .theme-toggle i {
              margin-right: 5px;
          }
          
          .highlight {
              background-color: rgba(255, 193, 7, 0.3);
              padding: 0 2px;
              border-radius: 3px;
          }
          
          @media (max-width: 600px) {
              .theme-toggle {
                  position: static;
                  margin-bottom: 20px;
                  width: fit-content;
              }
          }
          
          /* Search type badges */
          .search-type-badge {
              display: inline-block;
              padding: 3px 6px;
              border-radius: 3px;
              font-size: 12px;
              margin-left: 10px;
              font-weight: normal;
          }
          
          .semantic-badge {
              background-color: var(--highlight-color);
              color: white;
          }
          
          .keyword-badge {
              background-color: #6c757d;
              color: white;
          }
          
          /* Status indicator */
          .status-indicator {
              display: inline-block;
              width: 12px;
              height: 12px;
              border-radius: 50%;
              margin-right: 5px;
          }
          
          .status-available {
              background-color: var(--highlight-color);
          }
          
          .status-building {
              background-color: #f0b429;
          }
          
          .status-unavailable {
              background-color: #dc3545;
          }
          EOF
          
          # Create JavaScript file
          cat > static/script.js <<'EOF'
          // Theme toggling functionality
          function setTheme(themeName) {
              document.documentElement.setAttribute('data-theme', themeName);
              localStorage.setItem('theme', themeName);
              
              // Update toggle button
              const themeIcon = document.getElementById('theme-icon');
              const themeText = document.getElementById('theme-text');
              
              if (themeName === 'dark') {
                  themeIcon.textContent = '‚òÄÔ∏è';
                  themeText.textContent = 'Light Mode';
              } else {
                  themeIcon.textContent = 'üåô';
                  themeText.textContent = 'Dark Mode';
              }
          }
          
          function toggleTheme() {
              const currentTheme = localStorage.getItem('theme') || 'light';
              const newTheme = currentTheme === 'light' ? 'dark' : 'light';
              setTheme(newTheme);
          }
          
          // Initialize theme from localStorage
          function initTheme() {
              const savedTheme = localStorage.getItem('theme');
              if (savedTheme) {
                  setTheme(savedTheme);
              } else {
                  // Check for system preference
                  if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
                      setTheme('dark');
                  }
              }
          }
          
          // Tab navigation
          function openTab(evt, tabName) {
              var i, tabcontent, tablinks;
              tabcontent = document.getElementsByClassName("tabcontent");
              for (i = 0; i < tabcontent.length; i++) {
                  tabcontent[i].style.display = "none";
              }
              tablinks = document.getElementsByClassName("tablinks");
              for (i = 0; i < tablinks.length; i++) {
                  tablinks[i].className = tablinks[i].className.replace(" active", "");
              }
              document.getElementById(tabName).style.display = "block";
              evt.currentTarget.className += " active";
          }
          
          // Search functionality
          function performSearch() {
              const query = document.getElementById('query').value;
              if (!query) {
                  alert('Please enter a search query');
                  return false;
              }
              
              const resultsDiv = document.getElementById('results');
              resultsDiv.innerHTML = '<p>Searching...</p>';
              
              fetch('/api/search?q=' + encodeURIComponent(query))
                  .then(response => response.json())
                  .then(data => {
                      if (data.results && data.results.length > 0) {
                          const searchTypeLabel = data.search_type === 'semantic' ? 
                              '<span style="background: #5cb85c; color: white; padding: 3px 6px; border-radius: 3px; font-size: 12px; margin-left: 10px;">SEMANTIC</span>' : 
                              '<span style="background: #6c757d; color: white; padding: 3px 6px; border-radius: 3px; font-size: 12px; margin-left: 10px;">KEYWORD</span>';
                          
                          resultsDiv.innerHTML = '<h3>Search Results for: "' + query + '"' + searchTypeLabel + '</h3>';
                          data.results.forEach(result => {
                              resultsDiv.innerHTML += generateResultHTML(result, query);
                          });
                      } else {
                          resultsDiv.innerHTML = `
                              <h3>Search Results for: "${query}"</h3>
                              <p>No matching results found. Try using different keywords.</p>
                          `;
                      }
                  })
                  .catch(error => {
                      console.error('Error:', error);
                      document.getElementById('results').innerHTML = 
                          '<p>An error occurred during search. Please try again later.</p>';
                  });
              
              return false;
          }
          
          // Highlight search terms in results
          function highlightText(text, query) {
              if (!query || query.trim() === '') return text;
              
              // Create a regex to find instances of the query terms, case-insensitive
              const terms = query.split(/\s+/).filter(term => term.length > 2);
              if (terms.length === 0) return text;
              
              const regex = new RegExp('(' + terms.join('|') + ')', 'gi');
              return text.replace(regex, '<span class="highlight">$1</span>');
          }
          
          // Generate HTML for search results
          function generateResultHTML(result, query) {
              const highlightedContent = highlightText(result.content, query);
              
              return `
                  <div class="result-item">
                      <div class="result-title">${result.title || 'Untitled'}</div>
                      <div class="result-meta">at ${result.timestamp || '00:00'} ‚Ä¢ Score: ${result.score.toFixed(4)}</div>
                      <a href="${result.video_url || '#'}" style="text-decoration:none;" target="_blank">üîó Watch Video</a>
                      <div class="result-content">
                          <strong>Content:</strong> ${highlightedContent}
                      </div>
                  </div>
              `;
          }
          
          // Initialize everything when DOM is loaded
          document.addEventListener('DOMContentLoaded', function() {
              initTheme();
              
              // Set up search form submission
              document.getElementById('search-form').addEventListener('submit', function(e) {
                  e.preventDefault();
                  performSearch();
              });
          });
          EOF
          
          # Create HTML template
          cat > templates/index.html <<'EOF'
          <!DOCTYPE html>
          <html>
          <head>
              <title>Options Trading Knowledge Search</title>
              <meta name="viewport" content="width=device-width, initial-scale=1">
              <link rel="stylesheet" href="{{ url_for('static', filename='styles.css') }}">
          </head>
          <body>
              <div class="container">
                  <button id="theme-toggle" class="theme-toggle" onclick="toggleTheme()">
                      <span id="theme-icon">üåô</span> <span id="theme-text">Dark Mode</span>
                  </button>
                  
                  <h1>Options Trading Knowledge Search</h1>
                  
                  <div class="maintenance-notice" id="status-notice">
                      <strong>üîÑ Status:</strong> 
                      {% if building_vector_store %}
                      Vector store is currently building. Basic search is available in the meantime.
                      {% else %}
                      Semantic search is {{ "available" if vector_status == "‚úÖ Available" else "not available" }}. 
                      {{ "Using keyword search as fallback." if vector_status != "‚úÖ Available" else "" }}
                      {% endif %}
                  </div>
                  
                  <div class="tab">
                      <button class="tablinks active" onclick="openTab(event, 'SearchTab')">Search</button>
                      <button class="tablinks" onclick="openTab(event, 'InfoTab')">System Info</button>
                  </div>
                  
                  <div id="SearchTab" class="tabcontent" style="display: block;">
                      <h2>Search Options Trading Knowledge</h2>
                      <form id="search-form">
                          <input type="text" id="query" class="search-box" placeholder="Search for options concepts, strategies, etc.">
                          <button type="submit" class="button">Search</button>
                      </form>
                      <div id="results"></div>
                  </div>
                  
                  <div id="InfoTab" class="tabcontent">
                      <h2>System Information</h2>
                      <h3>Current Status</h3>
                      <ul>
                          <li>Search Engine: {{ "‚úÖ Semantic search" if vector_status == "‚úÖ Available" else "üîç Keyword search" }}</li>
                          <li>Vector Store: {{ vector_status }}</li>
                          <li>Transcript Files: {{ transcript_count }}</li>
                          <li>Application Version: 2.0</li>
                          <li>Last Updated: {{ timestamp }}</li>
                      </ul>
                      
                      <h3>Environment Information</h3>
                      <ul>
                          <li>Python Version: {{ python_version }}</li>
                          <li>Web Framework: Flask {{ flask_version }}</li>
                          <li>Current Time: {{ timestamp }}</li>
                      </ul>
                      
                      <h3>Files</h3>
                      <p><strong>App Files:</strong> {{ file_list }}</p>
                      <p><strong>Static Files:</strong> {{ static_files }}</p>
                      <p><strong>Template Files:</strong> {{ template_files }}</p>
                      
                      <h3>About This App</h3>
                      <p>This application provides semantic search across a collection of options trading transcripts and videos.</p>
                      <p>The search uses embeddings from the SentenceTransformer model to find the most relevant content based on your query.</p>
                      {% if building_vector_store %}
                      <div class="maintenance-notice">
                        <strong>üöß Vector Store Building:</strong> The semantic search index is currently being built. This may take a few minutes.
                      </div>
                      {% endif %}
                  </div>
              </div>
              
              <script src="{{ url_for('static', filename='script.js') }}"></script>
              
              <script>
              // Add polling for vector store status if it's building
              {% if building_vector_store %}
              let checkStatusInterval = setInterval(function() {
                  fetch('/api/status')
                      .then(response => response.json())
                      .then(data => {
                          if (!data.building_vector_store) {
                              // Vector store build finished
                              clearInterval(checkStatusInterval);
                              // Show success message
                              const notice = document.getElementById('status-notice');
                              if (data.vector_store_available) {
                                  notice.innerHTML = '<strong>‚úÖ Ready:</strong> Semantic search is now available!';
                              } else {
                                  notice.innerHTML = '<strong>‚ùå Error:</strong> Could not build vector store. Using keyword search.';
                              }
                              // Refresh page after 2 seconds
                              setTimeout(() => location.reload(), 2000);
                          }
                      })
                      .catch(error => console.error('Error checking status:', error));
              }, 5000); // Check every 5 seconds
              {% endif %}
              </script>
          </body>
          </html>
          EOF
          
          # Create a simple gunicorn starter for HF Spaces
          cat > start.sh <<'EOF'
          #!/bin/bash
          
          # Ensure executable
          chmod +x start.sh
          
          # Print environment info
          echo "Starting application..."
          python3 --version
          echo "Current directory: $(pwd)"
          echo "Files:"
          ls -la
          
          # Run Flask app with gunicorn
          exec python3 app.py
          EOF
          
          # Make start.sh executable
          chmod +x start.sh
          
          # Update the README to properly run Flask app
          cat > README.md <<EOF
          ---
          title: opteee
          emoji: üî•
          colorFrom: blue
          colorTo: red
          sdk: docker
          app_port: 7860
          pinned: false
          ---
          
          # Options Trading Knowledge Search
          
          This application provides semantic search across a collection of options trading transcripts and videos.
          
          ## Features
          
          - Semantic search using sentence-transformers
          - FAISS vector database for fast retrieval
          - Direct links to specific timestamps in relevant videos
          EOF
          
          # Create Dockerfile for Hugging Face Spaces
          cat > Dockerfile <<'EOF'
          FROM python:3.9-slim
          
          WORKDIR /app
          
          COPY requirements.txt .
          RUN pip install --no-cache-dir -r requirements.txt
          
          # Copy the application files
          COPY app.py .
          COPY static/ ./static/
          COPY templates/ ./templates/
          
          EXPOSE 7860
          
          # Run the Flask app directly
          CMD ["python", "app.py"]
          EOF
          
          echo "Created HuggingFace-specific configuration files:"
          ls -la

      - name: Push to Hugging Face Space
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          SPACE_NAME: "bthaile/opteee"
        run: |
          # Set credentials helper to store token
          git config --global credential.helper store
          
          # Store the Hugging Face token in the credentials helpers
          echo "https://USER:${HF_TOKEN}@huggingface.co" > ~/.git-credentials
          
          # Create a new repository with only the current content
          rm -rf .git
          git init
          git add .
          git commit -m "Deploy to Hugging Face with fixed dependencies"
          
          # Add Hugging Face Space as a Git remote
          git remote add space https://huggingface.co/spaces/$SPACE_NAME
          
          # Force push to Hugging Face Space
          git push --force space main 

      - name: Create a config.py file to centralize configuration
        run: |
          cat > config.py <<'EOF'
          import os

          # Directories
          PROCESSED_DIR = "processed_transcripts"
          VECTOR_DIR = "vector_store"
          
          # Model configuration
          MODEL_NAME = "all-MiniLM-L6-v2"  # Small, fast model good for semantic search
          
          # Search configuration
          DEFAULT_TOP_K = 5
          
          # Processing configuration
          BATCH_SIZE = 32  # For embedding creation
          
          # Ensure directories exist
          os.makedirs(PROCESSED_DIR, exist_ok=True)
          os.makedirs(VECTOR_DIR, exist_ok=True)
          EOF
          
      - name: Create vector_search.py module for semantic search functionality
        run: |
          cat > vector_search.py <<'EOF'
          import os
          import json
          import pickle
          import numpy as np
          from sentence_transformers import SentenceTransformer
          import faiss
          from tqdm import tqdm
          import time
          import sys
          
          from config import PROCESSED_DIR, VECTOR_DIR, MODEL_NAME, BATCH_SIZE
          
          # Global model instance (loaded when needed)
          _model = None
          
          def get_model():
              """Get or initialize the embedding model"""
              global _model
              if _model is None:
                  print(f"Loading model: {MODEL_NAME}")
                  _model = SentenceTransformer(MODEL_NAME)
              return _model
              
          def vector_store_exists():
              """Check if vector store files exist"""
              index_path = os.path.join(VECTOR_DIR, "transcript_index.faiss")
              metadata_path = os.path.join(VECTOR_DIR, "transcript_metadata.pkl")
              texts_path = os.path.join(VECTOR_DIR, "transcript_texts.pkl")
              return all(os.path.exists(f) for f in [index_path, metadata_path, texts_path])
              
          def load_processed_transcripts():
              """Load all processed transcript chunks from JSON files"""
              print(f"Loading processed transcripts from {PROCESSED_DIR}...")
              all_chunks = []
              all_metadatas = []
              
              # Check if directory exists
              if not os.path.exists(PROCESSED_DIR):
                  print(f"Directory {PROCESSED_DIR} not found")
                  return [], []
              
              # Get all JSON files
              json_files = [f for f in os.listdir(PROCESSED_DIR) if f.endswith('.json')]
              if not json_files:
                  print(f"No JSON files found in {PROCESSED_DIR}")
                  return [], []
                  
              print(f"Found {len(json_files)} processed transcript files")
              
              # Use a progress bar for loading
              for filename in tqdm(json_files, desc="Loading files"):
                  try:
                      file_path = os.path.join(PROCESSED_DIR, filename)
                      with open(file_path, 'r', encoding='utf-8') as f:
                          chunk_data = json.load(f)
                          
                          for chunk in chunk_data:
                              text = chunk.get('text', '')
                              metadata = chunk.get('metadata', {})
                              
                              if text and len(text.strip()) > 0:
                                  all_chunks.append(text)
                                  all_metadatas.append(metadata)
                  except Exception as e:
                      print(f"Error loading {filename}: {e}")
              
              print(f"‚úÖ Loaded {len(all_chunks)} transcript chunks")
              return all_chunks, all_metadatas
              
          def create_embeddings(texts):
              """Create embeddings for all texts using the specified model"""
              model = get_model()
              embeddings = []
              
              # Process in batches to avoid memory issues
              print(f"Creating embeddings for {len(texts)} chunks (batch size: {BATCH_SIZE})...")
              
              for i in tqdm(range(0, len(texts), BATCH_SIZE), desc="Creating embeddings"):
                  batch_texts = texts[i:i+BATCH_SIZE]
                  batch_embeddings = model.encode(batch_texts, show_progress_bar=False)
                  embeddings.extend(batch_embeddings)
              
              embeddings = np.array(embeddings).astype('float32')
              print(f"‚úÖ Created embeddings with shape: {embeddings.shape}")
              return embeddings
              
          def create_faiss_index(embeddings, metadatas, texts):
              """Create and save a FAISS index for fast similarity search"""
              # Create directory for vector store if it doesn't exist
              os.makedirs(VECTOR_DIR, exist_ok=True)
              
              # Get dimension of embeddings
              dimension = embeddings.shape[1]
              print(f"Creating FAISS index with dimension {dimension}...")
              
              # Create a flat index - simple but effective for smaller datasets
              index = faiss.IndexFlatL2(dimension)
              
              # Add vectors to the index
              index.add(embeddings)
              print(f"‚úÖ Added {index.ntotal} vectors to the index")
              
              # Save the index
              index_path = os.path.join(VECTOR_DIR, "transcript_index.faiss")
              faiss.write_index(index, index_path)
              print(f"‚úÖ Saved FAISS index to {index_path}")
              
              # Save the metadata mapping (needed for retrieval)
              metadata_path = os.path.join(VECTOR_DIR, "transcript_metadata.pkl")
              with open(metadata_path, 'wb') as f:
                  pickle.dump(metadatas, f)
              print(f"‚úÖ Saved metadata mapping to {metadata_path}")
              
              # Save raw texts for retrieval
              texts_path = os.path.join(VECTOR_DIR, "transcript_texts.pkl")
              with open(texts_path, 'wb') as f:
                  pickle.dump(texts, f)
              print(f"‚úÖ Saved raw texts to {texts_path}")
              
              return index
              
          def build_vector_store():
              """Build or rebuild the vector store from processed transcripts"""
              start_time = time.time()
              
              print("\n" + "="*50)
              print(f"BUILDING VECTOR STORE - Using model: {MODEL_NAME}")
              print("="*50)
              
              # Load transcripts
              texts, metadatas = load_processed_transcripts()
              
              if not texts:
                  print("‚ùå No transcript chunks loaded, cannot build vector store")
                  return False
                  
              try:
                  # Create embeddings
                  embeddings = create_embeddings(texts)
                  
                  # Create index
                  create_faiss_index(embeddings, metadatas, texts)
                  
                  elapsed = time.time() - start_time
                  print(f"\n‚úÖ Vector store built successfully in {elapsed:.1f} seconds")
                  return True
              except Exception as e:
                  print(f"‚ùå Error building vector store: {e}")
                  import traceback
                  traceback.print_exc()
                  return False
                  
          def load_vector_store():
              """Load the vector store from disk"""
              if not vector_store_exists():
                  print("‚ö†Ô∏è Vector store does not exist")
                  return None, [], []
                  
              try:
                  index_path = os.path.join(VECTOR_DIR, "transcript_index.faiss")
                  metadata_path = os.path.join(VECTOR_DIR, "transcript_metadata.pkl")
                  texts_path = os.path.join(VECTOR_DIR, "transcript_texts.pkl")
                  
                  # Load FAISS index
                  index = faiss.read_index(index_path)
                  
                  # Load metadata and texts
                  with open(metadata_path, 'rb') as f:
                      metadatas = pickle.load(f)
                      
                  with open(texts_path, 'rb') as f:
                      texts = pickle.load(f)
                      
                  print(f"‚úÖ Loaded vector store with {index.ntotal} vectors")
                  return index, metadatas, texts
              except Exception as e:
                  print(f"‚ùå Error loading vector store: {e}")
                  return None, [], []
                  
          def semantic_search(query, top_k=5):
              """Perform semantic search using the vector store"""
              # Check if vector store exists and try to build it if not
              if not vector_store_exists():
                  print("Vector store doesn't exist, attempting to build...")
                  success = build_vector_store()
                  if not success:
                      return []
              
              # Load vector store
              index, metadatas, texts = load_vector_store()
              if index is None:
                  return []
                  
              # Get model and create query embedding
              model = get_model()
              query_embedding = model.encode([query])[0].reshape(1, -1).astype('float32')
              
              # Search
              distances, indices = index.search(query_embedding, top_k)
              
              results = []
              for i, (idx, distance) in enumerate(zip(indices[0], distances[0])):
                  if idx >= len(texts) or idx < 0:
                      continue
                      
                  metadata = metadatas[idx]
                  text = texts[idx]
                  
                  # Normalize distance to a score between 0 and 1
                  # Lower distance is better in L2 space, so we invert it
                  score = 1.0 / (1.0 + distance)
                  
                  results.append({
                      "title": metadata.get("title", f"Result {i+1}"),
                      "timestamp": metadata.get("start_timestamp", ""),
                      "video_url": metadata.get("video_url_with_timestamp", "#"),
                      "content": text,
                      "score": score
                  })
                  
              return results
          EOF
          
          # Create updated app.py file that uses our vector search implementation
          cat > app.py <<'EOF'
          from flask import Flask, request, render_template, jsonify
          import os
          import sys
          import json
          from datetime import datetime
          import random
          import threading
          
          # Import our vector search module
          from config import PROCESSED_DIR, VECTOR_DIR
          from vector_search import semantic_search, vector_store_exists, build_vector_store
          
          # Create Flask app
          app = Flask(__name__)
          
          # Sample data for demonstration
          SAMPLE_TRANSCRIPTS = [
              {
                  "title": "Options Trading Basics",
                  "timestamp": "05:23",
                  "video_url": "https://example.com/video1?t=323",
                  "content": "Options give you the right, but not the obligation, to buy or sell an underlying asset at a specific price before a certain date. Call options give you the right to buy, while put options give you the right to sell."
              },
              {
                  "title": "Understanding Strike Prices",
                  "timestamp": "12:45",
                  "video_url": "https://example.com/video2?t=765",
                  "content": "The strike price is the price at which an option contract can be exercised. For call options, if the market price exceeds the strike price, the option is 'in the money'. For put options, it's the opposite."
              },
              {
                  "title": "Options Expiration Explained",
                  "timestamp": "08:15",
                  "video_url": "https://example.com/video3?t=495",
                  "content": "Options contracts have expiration dates. After this date, the contract is no longer valid. Weekly options expire every Friday, while monthly options typically expire on the third Friday of the month."
              },
              {
                  "title": "Calculating Option Premium",
                  "timestamp": "17:32",
                  "video_url": "https://example.com/video4?t=1052",
                  "content": "Option premium consists of intrinsic value and time value. Intrinsic value is the difference between the strike price and the market price, while time value is influenced by the time until expiration and market volatility."
              },
              {
                  "title": "Greeks in Options Trading",
                  "timestamp": "21:05",
                  "video_url": "https://example.com/video5?t=1265",
                  "content": "The Greeks are Delta, Gamma, Theta, Vega, and Rho. Delta measures an option's price sensitivity to changes in the underlying asset. Gamma measures the rate of change in Delta. Theta measures time decay. Vega measures sensitivity to volatility. Rho measures sensitivity to interest rates."
              },
              {
                  "title": "Covered Call Strategy",
                  "timestamp": "14:22",
                  "video_url": "https://example.com/video6?t=862",
                  "content": "A covered call involves holding a long position in an asset and selling a call option on that same asset. This strategy generates income through the premium received from selling the call option, providing a partial hedge against potential losses."
              },
              {
                  "title": "Put Selling Strategies",
                  "timestamp": "19:48",
                  "video_url": "https://example.com/video7?t=1188",
                  "content": "Selling puts can be an effective strategy when you're bullish or neutral on a stock. You collect premium and potentially acquire shares at a lower effective cost basis if the stock is assigned to you."
              },
              {
                  "title": "Iron Condor Explained",
                  "timestamp": "27:30",
                  "video_url": "https://example.com/video8?t=1650",
                  "content": "An iron condor is an options strategy that involves buying and selling calls and puts with different strike prices but the same expiration date. It's designed to profit from low volatility in the underlying asset."
              }
          ]
          
          # Application status tracking
          app_status = {
              "vector_store_available": False,
              "building_vector_store": False,
              "transcript_count": 0,
              "vector_count": 0,
              "last_updated": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
          }
          
          def check_and_build_vector_store():
              """Check vector store status and build if needed"""
              app_status["vector_store_available"] = vector_store_exists()
              
              # If vector store doesn't exist and we're not already building it
              if not app_status["vector_store_available"] and not app_status["building_vector_store"]:
                  # Start a background thread to build the vector store
                  threading.Thread(target=build_vector_store_background).start()
          
          def build_vector_store_background():
              """Build vector store in a background thread"""
              try:
                  app_status["building_vector_store"] = True
                  success = build_vector_store()
                  app_status["vector_store_available"] = success
              finally:
                  app_status["building_vector_store"] = False
                  app_status["last_updated"] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
          
          # Check vector store on startup (not using before_first_request as it's deprecated)
          @app.route('/')
          def home():
              """Render the home page"""
              # Check vector store status
              try:
                  check_and_build_vector_store()
              except Exception as e:
                  print(f"‚ö†Ô∏è Warning: Vector store check error: {e}")
              
              # Get system info for the Info tab
              flask_version = "2.0.1"  # Hardcoded for simplicity
              python_version = sys.version.split()[0]
              timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
              
              # Get directory listing
              app_files = sorted([f for f in os.listdir() if os.path.isfile(f)])
              static_files = []
              if os.path.exists('static'):
                  static_files = sorted(os.listdir('static'))
              template_files = []
              if os.path.exists('templates'):
                  template_files = sorted(os.listdir('templates'))
              
              # Check vector store
              vector_status = "‚úÖ Available" if vector_store_exists() else "üöß Building" if app_status["building_vector_store"] else "‚ùå Not Available"
              
              # Count transcript files
              transcript_count = 0
              if os.path.exists(PROCESSED_DIR):
                  transcript_files = [f for f in os.listdir(PROCESSED_DIR) if f.endswith('.json')]
                  transcript_count = len(transcript_files)
              
              return render_template(
                  'index.html', 
                  flask_version=flask_version,
                  python_version=python_version,
                  timestamp=timestamp,
                  file_list=', '.join(app_files[:10]) + ('...' if len(app_files) > 10 else ''),
                  static_files=', '.join(static_files[:5]) + ('...' if len(static_files) > 5 else ''),
                  template_files=', '.join(template_files[:5]) + ('...' if len(template_files) > 5 else ''),
                  vector_status=vector_status,
                  transcript_count=transcript_count,
                  building_vector_store=app_status["building_vector_store"]
              )
          
          def simple_search(query, data, top_k=5):
              """Simple keyword-based search on the sample data"""
              if not query or not data:
                  return []
              
              # Split query into terms
              terms = query.lower().split()
              
              results = []
              for item in data:
                  # Simple scoring based on term frequency
                  score = 0
                  content_lower = item["content"].lower()
                  title_lower = item["title"].lower()
                  
                  for term in terms:
                      if len(term) > 2:  # Only consider terms with more than 2 characters
                          # Give more weight to title matches
                          title_count = title_lower.count(term)
                          content_count = content_lower.count(term)
                          score += (title_count * 2) + content_count
                  
                  if score > 0:
                      results.append({
                          "title": item["title"],
                          "timestamp": item["timestamp"],
                          "video_url": item["video_url"],
                          "content": item["content"],
                          "score": score / max(1, len(terms))  # Normalize by number of terms
                      })
              
              # Sort by score descending
              results.sort(key=lambda x: x["score"], reverse=True)
              
              # Return top k results
              return results[:top_k]
          
          @app.route('/api/search')
          def search_api():
              """Enhanced search endpoint that tries vector search first, then fallback to simple search"""
              query = request.args.get('q', '').strip()
              
              if not query:
                  return jsonify({
                      "results": [],
                      "message": "Please provide a search query"
                  })
              
              # Check if we have vector store and try semantic search
              if vector_store_exists():
                  try:
                      results = semantic_search(query)
                      if results:
                          return jsonify({
                              "results": results,
                              "query": query,
                              "search_type": "semantic"
                          })
                  except Exception as e:
                      print(f"Error in semantic search: {e}")
                      # Fall back to simple search
              
              # Fallback to simple search
              results = simple_search(query, SAMPLE_TRANSCRIPTS)
              
              # Add some randomness to make results look dynamic
              for result in results:
                  result["score"] = min(1.0, result["score"] + random.uniform(-0.1, 0.1))
              
              return jsonify({
                  "results": results,
                  "query": query,
                  "search_type": "keyword"
              })
          
          @app.route('/api/status')
          def status_api():
              """API endpoint for checking application status"""
              # Update status
              app_status["vector_store_available"] = vector_store_exists()
              app_status["last_updated"] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
              
              # Count transcript files
              transcript_count = 0
              if os.path.exists(PROCESSED_DIR):
                  transcript_files = [f for f in os.listdir(PROCESSED_DIR) if f.endswith('.json')]
                  transcript_count = len(transcript_files)
              app_status["transcript_count"] = transcript_count
              
              return jsonify(app_status)
          
          # Run the Flask app
          if __name__ == '__main__':
              app.run(host='0.0.0.0', port=int(os.environ.get('PORT', 7860)))
          EOF
          
          # Ensure vector_search.py is copied in the Dockerfile
          cat > Dockerfile <<'EOF'
          FROM python:3.9-slim
          
          WORKDIR /app
          
          COPY requirements.txt .
          RUN pip install --no-cache-dir -r requirements.txt
          
          # Copy the application files
          COPY app.py .
          COPY config.py .
          COPY vector_search.py .
          COPY static/ ./static/
          COPY templates/ ./templates/
          
          # Create necessary directories
          RUN mkdir -p processed_transcripts vector_store
          
          EXPOSE 7860
          
          # Run the Flask app directly
          CMD ["python", "app.py"]
          EOF 