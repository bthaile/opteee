name: Deploy to Hugging Face Space

on:
  push:
    branches: [ main ]
  workflow_dispatch:  # Allows manual triggering

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 1  # Only fetch the latest commit

      - name: Configure Git
        run: |
          git config --global user.email "github-actions@github.com"
          git config --global user.name "GitHub Actions"
          # Set default branch name to main
          git config --global init.defaultBranch main
          
      - name: Create Hugging Face specific files
        run: |
          # Create packages.txt for system dependencies
          echo "" > packages.txt
          
          # Create requirements.txt with minimal dependencies for build time
          cat > requirements.txt <<EOF
          # Minimal dependencies for build process
          torch==1.13.1
          gradio==3.14.0
          python-dotenv==0.21.0
          # Keep these unversioned to avoid build conflicts
          numpy
          EOF
          
          # Create runtime_requirements.txt with exact versions for runtime
          cat > runtime_requirements.txt <<EOF
          # Exact versions for runtime compatibility
          huggingface_hub==0.10.1
          transformers==4.20.1
          tokenizers==0.12.1
          sentence_transformers==2.1.0
          faiss-cpu==1.7.3
          EOF
          
          # Create a modernized version of create_vector_store.py 
          cat > create_vector_store.py <<'EOF'
          import os
          import json
          import numpy as np
          from tqdm import tqdm
          import faiss
          import pickle
          from sentence_transformers import SentenceTransformer
          import argparse

          # Configuration
          PROCESSED_DIR = "processed_transcripts"
          VECTOR_DIR = "vector_store"
          MODEL_NAME = "all-MiniLM-L6-v2"  # A good balance between performance and speed
          BATCH_SIZE = 32  # Adjust based on your available memory

          def load_processed_transcripts():
              """Load all processed transcript chunks from JSON files"""
              print(f"Loading processed transcripts from {PROCESSED_DIR}...")
              all_chunks = []
              all_metadatas = []
              
              # Ensure directory exists
              if not os.path.exists(PROCESSED_DIR):
                  raise FileNotFoundError(f"Directory {PROCESSED_DIR} not found. Run preprocess_transcripts.py first.")
              
              # Get all JSON files
              json_files = [f for f in os.listdir(PROCESSED_DIR) if f.endswith('.json')]
              print(f"Found {len(json_files)} processed transcript files")
              
              for filename in tqdm(json_files, desc="Loading files"):
                  try:
                      file_path = os.path.join(PROCESSED_DIR, filename)
                      with open(file_path, 'r', encoding='utf-8') as f:
                          chunk_data = json.load(f)
                          
                          for chunk in chunk_data:
                              text = chunk.get('text', '')
                              metadata = chunk.get('metadata', {})
                              
                              if text and len(text.strip()) > 0:
                                  all_chunks.append(text)
                                  all_metadatas.append(metadata)
                  except Exception as e:
                      print(f"Error loading {filename}: {e}")
              
              print(f"âœ… Loaded {len(all_chunks)} transcript chunks")
              return all_chunks, all_metadatas

          def create_embeddings(texts, model_name=MODEL_NAME, batch_size=BATCH_SIZE):
              """Create embeddings for all texts using the specified model"""
              print(f"\nLoading embedding model: {model_name}")
              model = SentenceTransformer(model_name)
              
              print(f"Creating embeddings for {len(texts)} chunks (batch size: {batch_size})...")
              embeddings = []
              
              # Process in batches to avoid memory issues
              for i in tqdm(range(0, len(texts), batch_size), desc="Creating embeddings"):
                  batch_texts = texts[i:i+batch_size]
                  batch_embeddings = model.encode(batch_texts, show_progress_bar=False)
                  embeddings.extend(batch_embeddings)
              
              embeddings = np.array(embeddings).astype('float32')
              print(f"âœ… Created embeddings with shape: {embeddings.shape}")
              return embeddings

          def create_faiss_index(embeddings, metadatas, texts):
              """Create and save a FAISS index for fast similarity search"""
              # Create directory for vector store if it doesn't exist
              os.makedirs(VECTOR_DIR, exist_ok=True)
              
              # Get dimension of embeddings
              dimension = embeddings.shape[1]
              print(f"\nCreating FAISS index with dimension {dimension}...")
              
              # Create a flat index - simple but effective for smaller datasets
              index = faiss.IndexFlatL2(dimension)
              
              # Add vectors to the index
              index.add(embeddings)
              print(f"âœ… Added {index.ntotal} vectors to the index")
              
              # Save the index
              index_path = os.path.join(VECTOR_DIR, "transcript_index.faiss")
              faiss.write_index(index, index_path)
              print(f"âœ… Saved FAISS index to {index_path}")
              
              # Save the metadata mapping (needed for retrieval)
              metadata_path = os.path.join(VECTOR_DIR, "transcript_metadata.pkl")
              with open(metadata_path, 'wb') as f:
                  pickle.dump(metadatas, f)
              print(f"âœ… Saved metadata mapping to {metadata_path}")
              
              # Save raw texts for retrieval
              texts_path = os.path.join(VECTOR_DIR, "transcript_texts.pkl")
              with open(texts_path, 'wb') as f:
                  pickle.dump(texts, f)
              print(f"âœ… Saved raw texts to {texts_path}")
              
              return index

          def main(args):
              print("="*80)
              print(f"VECTOR STORE CREATION - Using model: {args.model}")
              print("="*80)
              
              # Load processed transcript chunks
              texts, metadatas = load_processed_transcripts()
              
              # Create embeddings
              embeddings = create_embeddings(texts, model_name=args.model, batch_size=args.batch_size)
              
              # Create and save FAISS index
              index = create_faiss_index(embeddings, metadatas, texts)
              
              print("\n"+"="*80)
              print("ðŸ“ Vector store creation complete!")
              print(f"âœ… Model used: {args.model}")
              print(f"âœ… Total chunks indexed: {len(texts)}")
              print(f"ðŸ“ Vector store saved to {VECTOR_DIR}/")
              print("="*80)
              print("\nTo search your vector store, use search_transcripts.py")

          if __name__ == "__main__":
              parser = argparse.ArgumentParser(description='Create a vector store from processed transcripts')
              parser.add_argument('--model', type=str, default=MODEL_NAME, 
                                  help=f'Sentence transformer model to use (default: {MODEL_NAME})')
              parser.add_argument('--batch-size', type=int, default=BATCH_SIZE,
                                  help=f'Batch size for embedding creation (default: {BATCH_SIZE})')
              parser.add_argument('--test-search', action='store_true',
                                  help='Run test queries after creating the index')
              
              args = parser.parse_args()
              main(args)
          EOF
          
          # Create functional app.py 
          cat > app.py <<'EOF'
          import os
          import gradio as gr
          import pickle
          import faiss
          from sentence_transformers import SentenceTransformer
          import numpy as np
          import json
          from datetime import datetime
          import sys
          
          # Configuration
          VECTOR_DIR = "vector_store"
          MODEL_NAME = "all-MiniLM-L6-v2"
          
          # Check if vector store exists, if not pre-build it
          def vector_store_exists():
              if not os.path.exists(VECTOR_DIR):
                  os.makedirs(VECTOR_DIR, exist_ok=True)
                  return False
              index_path = os.path.join(VECTOR_DIR, "transcript_index.faiss")
              metadata_path = os.path.join(VECTOR_DIR, "transcript_metadata.pkl")
              texts_path = os.path.join(VECTOR_DIR, "transcript_texts.pkl")
              return os.path.exists(index_path) and os.path.exists(metadata_path) and os.path.exists(texts_path)
          
          # Function to load transcripts
          def load_processed_transcripts():
              """Load all processed transcript chunks from JSON files"""
              processed_dir = "processed_transcripts"
              print(f"Loading processed transcripts from {processed_dir}...")
              all_chunks = []
              all_metadatas = []
              
              # Ensure directory exists
              if not os.path.exists(processed_dir):
                  print(f"âš ï¸ Directory {processed_dir} not found.")
                  return [], []
              
              # Get all JSON files
              json_files = [f for f in os.listdir(processed_dir) if f.endswith('.json')]
              print(f"Found {len(json_files)} processed transcript files")
              
              for filename in json_files[:10]:  # Limit to first 10 files for testing
                  try:
                      file_path = os.path.join(processed_dir, filename)
                      with open(file_path, 'r', encoding='utf-8') as f:
                          chunk_data = json.load(f)
                          
                          for chunk in chunk_data:
                              text = chunk.get('text', '')
                              metadata = chunk.get('metadata', {})
                              
                              if text and len(text.strip()) > 0:
                                  all_chunks.append(text)
                                  all_metadatas.append(metadata)
                  except Exception as e:
                      print(f"Error loading {filename}: {e}")
              
              print(f"âœ… Loaded {len(all_chunks)} transcript chunks")
              return all_chunks, all_metadatas
          
          # Function to build or rebuild the vector store
          def ensure_vector_store():
              if vector_store_exists():
                  print("âœ… Vector store exists, using existing store")
                  return True
              
              print("âš ï¸ Vector store doesn't exist, attempting to build...")
              try:
                  from create_vector_store import create_embeddings, create_faiss_index
                  
                  # Load transcript chunks
                  texts, metadatas = load_processed_transcripts()
                  
                  if not texts:
                      print("âŒ No transcript chunks found, cannot build vector store")
                      return False
                  
                  # Create embeddings
                  print("Creating embeddings...")
                  model = SentenceTransformer(MODEL_NAME)
                  batch_size = 32
                  
                  # Process in batches
                  embeddings = []
                  for i in range(0, len(texts), batch_size):
                      batch_texts = texts[i:i+batch_size]
                      batch_embeddings = model.encode(batch_texts, show_progress_bar=True)
                      embeddings.extend(batch_embeddings)
                  
                  embeddings = np.array(embeddings).astype('float32')
                  print(f"âœ… Created embeddings with shape: {embeddings.shape}")
                  
                  # Create FAISS index
                  print("Creating FAISS index...")
                  os.makedirs(VECTOR_DIR, exist_ok=True)
                  
                  # Create a flat index
                  dimension = embeddings.shape[1]
                  index = faiss.IndexFlatL2(dimension)
                  
                  # Add vectors to the index
                  index.add(embeddings)
                  print(f"âœ… Added {index.ntotal} vectors to the index")
                  
                  # Save the index
                  index_path = os.path.join(VECTOR_DIR, "transcript_index.faiss")
                  faiss.write_index(index, index_path)
                  print(f"âœ… Saved FAISS index to {index_path}")
                  
                  # Save the metadata mapping (needed for retrieval)
                  metadata_path = os.path.join(VECTOR_DIR, "transcript_metadata.pkl")
                  with open(metadata_path, 'wb') as f:
                      pickle.dump(metadatas, f)
                  print(f"âœ… Saved metadata mapping to {metadata_path}")
                  
                  # Save raw texts for retrieval
                  texts_path = os.path.join(VECTOR_DIR, "transcript_texts.pkl")
                  with open(texts_path, 'wb') as f:
                      pickle.dump(texts, f)
                  print(f"âœ… Saved raw texts to {texts_path}")
                  
                  return True
              except Exception as e:
                  print(f"âŒ Error building vector store: {e}")
                  return False
          
          # Load vector store if it exists
          def load_vector_store():
              if not vector_store_exists():
                  dummy_data = (
                      lambda: None,  # Dummy index
                      [{"title": "Dummy Title", "start_timestamp": "00:00", "video_url_with_timestamp": "#"}] * 5,  # Dummy metadata
                      ["This is dummy text for demonstration purposes."] * 5  # Dummy texts
                  )
                  return dummy_data
              
              try:
                  index_path = os.path.join(VECTOR_DIR, "transcript_index.faiss")
                  metadata_path = os.path.join(VECTOR_DIR, "transcript_metadata.pkl")
                  texts_path = os.path.join(VECTOR_DIR, "transcript_texts.pkl")
                  
                  index = faiss.read_index(index_path)
                  
                  with open(metadata_path, 'rb') as f:
                      metadatas = pickle.load(f)
                      
                  with open(texts_path, 'rb') as f:
                      texts = pickle.load(f)
                      
                  return index, metadatas, texts
              except Exception as e:
                  print(f"âŒ Error loading vector store: {e}")
                  return None, [], []
          
          # Simple search function
          def search_transcripts(query, model=None, top_k=5):
              try:
                  # Load model if not provided
                  if model is None:
                      model = SentenceTransformer(MODEL_NAME)
                      
                  # Load vector store
                  index, metadatas, texts = load_vector_store()
                  
                  # If using dummy data or no real index
                  if not isinstance(index, faiss.swigfaiss.IndexFlat):
                      return [{
                          "text": "Vector store is not available. Please check back later.",
                          "metadata": {"title": "No Data", "start_timestamp": "", "video_url_with_timestamp": ""},
                          "distance": 0.0
                      }]
                  
                  # Create query embedding
                  query_embedding = model.encode([query])[0].reshape(1, -1).astype('float32')
                  
                  # Search
                  distances, indices = index.search(query_embedding, top_k)
                  
                  results = []
                  for i, (idx, distance) in enumerate(zip(indices[0], distances[0])):
                      # Get metadata for this result
                      try:
                          metadata = metadatas[idx]
                          text = texts[idx]
                      except IndexError:
                          metadata = {"title": f"Result {i+1}", "start_timestamp": "", "video_url_with_timestamp": ""}
                          text = "Content unavailable"
                      
                      result = {
                          "text": text,
                          "metadata": metadata,
                          "distance": float(distance)
                      }
                      results.append(result)
                      
                  return results
              except Exception as e:
                  print(f"Error in search: {e}")
                  return []
          
          # Gradio interface
          def search_interface(query):
              if not query or len(query.strip()) == 0:
                  return "Please enter a search query"
              
              try:
                  # Check vector store status
                  if not vector_store_exists():
                      return """
                      # Vector Store Not Available
                      
                      The vector store is currently being built or is not available.
                      
                      Please check back later or contact the administrator.
                      """
                  
                  model = SentenceTransformer(MODEL_NAME)
                  results = search_transcripts(query, model=model, top_k=5)
                  
                  if not results:
                      return "No results found or search error occurred"
                  
                  output = f"## Search Results for: '{query}'\n\n"
                  
                  for i, result in enumerate(results):
                      metadata = result["metadata"]
                      text = result["text"]
                      distance = result["distance"]
                      
                      title = metadata.get("title", "Untitled")
                      timestamp = metadata.get("start_timestamp", "")
                      url = metadata.get("video_url_with_timestamp", "")
                      
                      output += f"### {i+1}. {title} (at {timestamp}) - Score: {distance:.4f}\n"
                      output += f"ðŸ”— [Watch Video]({url})\n\n"
                      output += f"**Content:** {text}\n\n"
                      output += "---\n\n"
                      
                  return output
              except Exception as e:
                  return f"Error: {str(e)}"
          
          # Info page content
          def info_page():
              status = "âœ… Available" if vector_store_exists() else "âš ï¸ Not Available"
              
              # Get environment info
              env_info = {
                  "Python Version": sys.version,
                  "Libraries": {
                      "gradio": gr.__version__,
                      "faiss": faiss.__version__ if hasattr(faiss, "__version__") else "Unknown",
                      "numpy": np.__version__,
                      "sentence_transformers": SentenceTransformer.__version__ if hasattr(SentenceTransformer, "__version__") else "Unknown"
                  },
                  "Vector Store Status": status,
                  "Current Directory Files": os.listdir()[:10]  # First 10 files
              }
              
              info_md = f"""
              # Options Trading Knowledge Base
              
              ## System Status
              
              - Vector Store: {status}
              - Application Version: 1.0
              - Last Updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
              
              ## Environment Information
              
              - Python Version: {env_info['Python Version'].split()[0]}
              - Gradio Version: {env_info['Libraries']['gradio']}
              - FAISS Version: {env_info['Libraries']['faiss']}
              - NumPy Version: {env_info['Libraries']['numpy']}
              
              ## About This App
              
              This application provides semantic search across a collection of options trading transcripts and videos.
              
              The search uses embeddings from the model `{MODEL_NAME}` to find the most relevant content based on your query.
              
              ## Files in Directory (Sample)
              
              {', '.join(env_info['Current Directory Files'])}...
              """
              
              return info_md
          
          # Create the Gradio interface
          search_tab = gr.Interface(
              fn=search_interface,
              inputs=gr.Textbox(
                  lines=2, 
                  placeholder="Search for options trading concepts..."
              ),
              outputs=gr.Markdown(),
              title="Options Trading Knowledge Search",
              description="Search through hundreds of transcripts about options trading",
              theme="default"
          )
          
          # Info tab
          info_tab = gr.Interface(
              fn=lambda: info_page(),
              inputs=None,
              outputs=gr.Markdown(),
              title="System Information",
              description="Status and information about this knowledge base",
              theme="default"
          )
          
          # Combine interfaces
          app = gr.TabbedInterface(
              [search_tab, info_tab],
              ["Search", "System Info"],
          )
          EOF
          
          # Create startup wrapper script to install runtime dependencies
          cat > start.py <<'EOF'
          import os
          import sys
          import subprocess
          import time
          from datetime import datetime
          
          def install_runtime_dependencies():
              """Install runtime dependencies before starting the app"""
              print("=" * 40)
              print(f"Installing runtime dependencies at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
              print("=" * 40)
              
              if os.path.exists("runtime_requirements.txt"):
                  print("Found runtime_requirements.txt, installing dependencies...")
                  result = subprocess.run(
                      [sys.executable, "-m", "pip", "install", "-r", "runtime_requirements.txt"],
                      capture_output=True,
                      text=True
                  )
                  
                  print(f"Installation stdout: {result.stdout}")
                  if result.stderr:
                      print(f"Installation stderr: {result.stderr}")
                      
                  if result.returncode == 0:
                      print("âœ… Successfully installed runtime dependencies")
                  else:
                      print("âŒ Failed to install some runtime dependencies")
              else:
                  print("âš ï¸ No runtime_requirements.txt file found")
              
              print("=" * 40)
          
          # Install runtime dependencies
          install_runtime_dependencies()
          
          # Import the actual app
          try:
              print("Starting application...")
              from app import app
          except Exception as e:
              print(f"âŒ Error importing app: {e}")
              import gradio as gr
              
              # Fallback to minimal app if the import fails
              app = gr.Interface(
                  fn=lambda x: f"Application failed to start: {str(e)}",
                  inputs=gr.Textbox(placeholder="Error occurred..."),
                  outputs=gr.Textbox(),
                  title="Application Error"
              )
          EOF
          
          # Update the README to use start.py
          cat > README.md <<EOF
          ---
          title: opteee
          emoji: ðŸ”¥
          colorFrom: blue
          colorTo: red
          sdk: gradio
          sdk_version: 4.19.2
          app_file: start.py
          pinned: false
          ---
          
          # Options Trading Knowledge Search
          
          This application provides semantic search across a collection of options trading transcripts and videos.
          
          ## Features
          
          - Semantic search using sentence-transformers
          - FAISS vector database for fast retrieval
          - Direct links to specific timestamps in relevant videos
          EOF
          
          echo "Created HuggingFace-specific configuration files:"
          ls -la

      - name: Push to Hugging Face Space
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          SPACE_NAME: "bthaile/opteee"
        run: |
          # Set credentials helper to store token
          git config --global credential.helper store
          
          # Store the Hugging Face token in the credentials helpers
          echo "https://USER:${HF_TOKEN}@huggingface.co" > ~/.git-credentials
          
          # Create a new repository with only the current content
          rm -rf .git
          git init
          git add .
          git commit -m "Deploy to Hugging Face with fixed dependencies"
          
          # Add Hugging Face Space as a Git remote
          git remote add space https://huggingface.co/spaces/$SPACE_NAME
          
          # Force push to Hugging Face Space
          git push --force space main 