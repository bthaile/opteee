[
  {
    "text": "Double Machine Learning: Explaining the Post-Earnings Announcement Drift Jacob H. Hansen and Mathias V. Siggaard† October 16, 2022 Abstract We demonstrate the benefits of merging traditional hypothesis-driven research with new methodsfrommachinelearningthatenablehigh-dimensionalinference.Becausetheliterature on post-earnings announcement drift (PEAD) is characterized by a “zoo” of explanations, limited academic consensus on model design, and reliance on massive data, it will serve as a leading example to demonstrate the challenges of high-dimensional analysis. We identify a small set of variables associated with momentum, liquidity, and limited arbitrage that explain PEAD directly and consistently, and the framework can be applied broadly in finance. Keywords: Post-Earnings Announcement Drift, Double Machine Learning, Inference, Lasso, Variable Selection JEL: C14, G12, G14 †jacobhald@econ.au.dk, Aarhus University Department of Economics and Business Economics, CREATES (corresponding author); siggaard@econ.au.dk, Aarhus University Department of Economics and Business Economics, CREATES. We thank participants of the Duke financial econometrics seminar, Aarhus University econometrics- finance seminar series, and Nordic Finance Network Workshop 2022 for their many useful comments and questions. We also thankStig Vinther Møller, Kim Christensen,Campbell R. Harvey, Tim Bollerslev, Allan Timmermann,JaeHoonKim,ThomasQuistgaardPedersen,TomEngsted,JonasNygaardEriksen,Nicolaj Søndergaard Mühlbach, and Jylhä Petri for their valuable comments and insightful suggestions. Special thanks are due to an anonymous referee and Jennifer Conrad (the managing editor) for detailed comments and helpful suggestions, which helped improve many aspects of this paper 1 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Document",
    "page_number": 1,
    "page_range": "p.1",
    "total_pages": 80,
    "chunk_index": 0,
    "word_count": 221,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Document (p.1)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "Tim Bollerslev, Allan Timmermann,JaeHoonKim,ThomasQuistgaardPedersen,TomEngsted,JonasNygaardEriksen,Nicolaj Søndergaard Mühlbach, and Jylhä Petri for their valuable comments and insightful suggestions. Special thanks are due to an anonymous referee and Jennifer Conrad (the managing editor) for detailed comments and helpful suggestions, which helped improve many aspects of this paper 1 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 2,
    "page_range": "p.2",
    "total_pages": 80,
    "chunk_index": 1,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.2)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "Linear regression is a simple and powerful technique: it provides interpretable coefficients, and its asymptotic properties are well-established and known. It is undoubtedly the default model when working with financial data, but its simplicity becomes its weakness in high-dimensional settings (see Gu, Kelly, and Xiu (2020) and Christensen, Siggaard, and Veliyev (2022)). Relying on standard linear regressions with few explanatory variables in high-dimensional settings induces endless design combinations and ultimately leads to countless conclusions, and the new era in finance—governed by massive datasets and increasing computational capacity—is exacerbating the problem. Therefore, we reason that moving toward high-dimensional methods and data-driven approaches is to some degree inevitable. This paper demonstrates the possibility of conducting high-dimensional inferences by combining knowledge and theory from finance with modern statistical and computational techniques. By harnessing the pioneering work of Chernozhukov, Chetverikov, Demirer, Duflo, Hansen, Newey, and Robins (2018), i.e., the double machine learning (DML) procedure, we conduct valid statistical inference in a high-dimensional setting while controlling for a large set of explanatory variables. As a direct result, we achieve a data-driven approach that reduces researcher dependency. The main objective is to construct a partially linear model with a modified moment condition. This modification ensures consistency and interpretability of the coefficient of interest equivalent to the familiar linear beta coefficient. In addition to allowing for valid inferences, the method permits a complex relationship between the dependent variable and the set of controls through a possible highly nonlinear and high-dimensional function. Because we rely on a generic approach, the proposed procedure can be applied more broadly in finance, such as to explain fund flows, pre-announcement earnings drift, dividend announcements, initial public offerings, 2 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 2,
    "page_range": "p.2",
    "total_pages": 80,
    "chunk_index": 2,
    "word_count": 281,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.2)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "and the set of controls through a possible highly nonlinear and high-dimensional function. Because we rely on a generic approach, the proposed procedure can be applied more broadly in finance, such as to explain fund flows, pre-announcement earnings drift, dividend announcements, initial public offerings, 2 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 3,
    "page_range": "p.3",
    "total_pages": 80,
    "chunk_index": 3,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.3)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "mergers and acquisitions, debt and equity issues, and stock splits. To demonstrate the benefits of the procedure, we revisit an unresolved question in finance, i.e., the origins of post-earnings announcement drift (PEAD). Known as PEAD, the tendency of stock prices to drift in the direction of an earnings surprise has attracted extensive attention since its discovery by Ball and Brown (1968). Its importance and relevance are revealed clearly by Fink (2020), who review 216 published papers on the phenomenon. As emphasized by Fama (1998), PEAD is one of the most robust and persistent financial anomalies, and it has resulted in what we—in the spirit of Cochrane (2011)—term a “zoo of controls.” The expansion of this zoo has been amplified by the reliance on high-dimensional empirical data, which are noisy and subject to omitted-variable bias (Fink (2020)). The PEAD literature is a classic example of a line of research that relies on massive sample sizes and a zoo of variables. This forces researchers to hand pick a small set of controls while being impeded by a lack of academic consensus on this choice. We demonstrate how inference is highly sensitive to the choice of controls, and we note that conclusions can favor the researchers’ hypothesis if the “right set” of controls is chosen. Moreover, by relying on massive sample sizes, smaller and more complex statistical effects can be detected, but often with little or no practical relevance (see McCloskey and Ziliak (1996), Lin, Lucas Jr., and Shmueli (2013), Kim and Ji (2015), and Kim (2017)). Consequently, if the set of choices is large enough (see Harvey, Liu, and Zhu (2016)), statistical significance can be found even if there is no meaningful effect. Therefore, we reason that the PEAD literature provides a suitable context in which to illustrate the benefits of using high-dimensional data-driven methods to reduce researcher dependency and strengthen the credibility of explanations. This paper makes four main contributions. First, we showcase the advantages of combining high-dimensional methods with finance knowledge and theory to improve our understanding of PEAD. Second, by taking numerous potential controls generated by existing theories and relying on a new testing framework, we isolate a small set of 3 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 3,
    "page_range": "p.3",
    "total_pages": 80,
    "chunk_index": 4,
    "word_count": 368,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.3)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "contributions. First, we showcase the advantages of combining high-dimensional methods with finance knowledge and theory to improve our understanding of PEAD. Second, by taking numerous potential controls generated by existing theories and relying on a new testing framework, we isolate a small set of 3 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 4,
    "page_range": "p.4",
    "total_pages": 80,
    "chunk_index": 5,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.4)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "variables that explain PEAD directly and consistently. Third, we demonstrate that if the high degree of researcher dependency is not mitigated, then incorrect conclusions can be drawn. Fourth, by exploring a large set of potential controls from the cross- section of stock returns literature, we find a more prominent role for price trends than that suggested in the PEAD literature. ThemajorityofstudiesexaminingPEADseektoidentifyavariablethatcanexplain cross-sectional differences in the drift. These studies rely on the earnings response coefficient framework, where the cumulative abnormal return after the announcement is regressed on (i) SUE (the main surprise in earnings), (ii) a variable of interest, (iii) their interaction, and (iv) a set of control variables.1 To date, it has been standard to investigate a single variable of interest and rely on simple linear regression. However, our aim herein is to go further, with the empirical section investigating 20 different variables of interest previously related to the PEAD literature. Furthermore, we ensure a close link to the existing literature and robustness of the results because we test the DML framework against three standard ordinary least squares (OLS) specifications commonly applied in the literature. The first OLS regression often serves as a motivating regression, where the abnormal returns are regressed on SUE and a variable of interest. The second OLS regression allows for a small subset of control variables chosen ex ante, whereas the third OLS regression includes a multitude of controls. However, it is still doubtful whether this set of variables guarantees correct model specification and valid statistical inference. Therefore, we leverage the new capabilities of the DML procedure, where we extend the set of control variables to include 73 stock-specific variables from Green, Hand, and Zhang (2017), all first-order interactions, and a large set of fixed effects, totaling 2,836 controls. By harnessing the capabilities of post-lasso developed by Belloni and Chernozhukov (2013), we assume that a sparse linear combination of controls can approximate PEAD, and we allow 1When the interaction between the variable of interest and the SUE (surprise in earnings) variable can explain the cumulative abnormal return with statistical significance, it is said to explain the variations in PEAD. 4 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 4,
    "page_range": "p.4",
    "total_pages": 80,
    "chunk_index": 6,
    "word_count": 359,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.4)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "sparse linear combination of controls can approximate PEAD, and we allow 1When the interaction between the variable of interest and the SUE (surprise in earnings) variable can explain the cumulative abnormal return with statistical significance, it is said to explain the variations in PEAD. 4 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 5,
    "page_range": "p.5",
    "total_pages": 80,
    "chunk_index": 7,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.5)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "the potential set to be high-dimensional. In this way, we can adhere to the idea that PEAD is approximated well by a sparse linear combination and also reduce researcher dependency. The instability of linear regression in high-dimensional settings becomes clear when its coefficients are compared to those of the DML procedure. Out of 20 variables, 17 are statistically significantly associated with either variation in PEAD or cumulative abnormal returns for the simplest model. The same issue arises in a “kitchen sink” approach controlling for a long list of variables (see Whited, Swanquist, Shipman, and Moon (2022)). Yet when leveraging the high-dimensional capabilities of the DML procedure by using all 2,836 controls, we find a 28% reduction in the number of variables explaining PEAD. Specifically, the procedure finds the following variables to explain variations in PEAD with statistical significance: the reporting lag between quarter end and announcement date, a loss indicator showing whether a past announcement was negative, an indicator for announcements in the same fiscal year, past returns over the last year, and the amount of other earnings news. These results imply that familiar variables such as firm size, pre-announcement returns, and trading volume are not associated with PEAD when accounting for the large set of controls. Considering how inferences have changed with time, the DML procedure identifies a small set of variables that are consistently statistically significant, and the remaining variables are sporadically significant. Weillustratethegeneralityoftheframeworkbytestingwhetheranyoftheadditional 73 stock-specific variables of Green et al. (2017) explain PEAD. Interestingly, the statistically significant variables are mainly those associated with price trends, liquidity, and volatility, consistent with the findings of Gu et al. (2020), who explore return predictability. To ensure the stability of the inferences from our main analysis, we consider several different popular quantile ranks of the variables and demonstrate how inferences are stable across different model specifications, estimation methods, and variable definitions. Our study contributes to several strands of the literature. We are among the 5 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 5,
    "page_range": "p.5",
    "total_pages": 80,
    "chunk_index": 8,
    "word_count": 329,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.5)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "the inferences from our main analysis, we consider several different popular quantile ranks of the variables and demonstrate how inferences are stable across different model specifications, estimation methods, and variable definitions. Our study contributes to several strands of the literature. We are among the 5 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 6,
    "page_range": "p.6",
    "total_pages": 80,
    "chunk_index": 9,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.6)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "first to use the advantages of the DML procedure to overcome omitted variables, model misspecification, and nonlinearities in a finance application.2 In recent years, machine learning methods have become popular because of their attractive ability in handling complex and high-dimensional data. The main reason for the success of these new methods is their ability to balance the bias–variance tradeoff. However, by allowing for bias, interpretability of estimates becomes challenging, therefore much effort has been made to de-bias coefficients and generate confidence intervals when—for instance—relying on regularization methods such as ridge or lasso (e.g., see Nickl and Van De Geer (2013), Javanmard and Montanari (2014), Lee, Sun, Sun, and Taylor (2016), Belloni, Chen, Chernozhukov, and Hansen (2012), Belloni, Chernozhukov, and Hansen (2014b), and Athey, Imbens, and Wager (2018)). Although these are novel methods, the present paper goes even further in that we rely on the more general DML procedure by Chernozhukov et al. (2018). Its generality ensures interpretability in high-dimensional settings via a broad array of machine learning methods such as lasso, random forests, boosted trees, and neural networks. Second, we contribute to the literature explaining PEAD by systematically evaluating multiple explanations while accounting for a high-dimensional set of controls. The origins of this literature can be traced back to Foster, Olsen, and Shevlin (1984) and Bernard and Thomas (1989), who find a negative relationship between PEAD and firm size, which is one of the best-established factors. Countless other explanations exist, such as limited arbitrage (Mendenhall (2004)), information uncertainty (Kormendi and Lipe (1987), Jiang, Lee, and Zhang (2005), and Francis, Lafond, Olsson, and Schipper (2007)), illiquidity (Bhushan (1994) and Chordia, Goyal, Sadka, Sadka, and Shivakumar (2009)), and under-reaction to earnings news (Mendenhall (1991), DellaVigna and Pollet (2009), and Hirshleifer, Lim, and Teoh (2009)). We refer to Fink (2020) for an excellent and more-extensive review of the PEAD literature. Third, the present paper adds to the 2Yang, Chuang, and Kuan (2020) study the DML procedure using simulations and investigate the Big N audit quality effect. 6 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 6,
    "page_range": "p.6",
    "total_pages": 80,
    "chunk_index": 10,
    "word_count": 339,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.6)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "and Teoh (2009)). We refer to Fink (2020) for an excellent and more-extensive review of the PEAD literature. Third, the present paper adds to the 2Yang, Chuang, and Kuan (2020) study the DML procedure using simulations and investigate the Big N audit quality effect. 6 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 7,
    "page_range": "p.7",
    "total_pages": 80,
    "chunk_index": 11,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.7)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "new line of research addressing the issue of omitting relevant variables, which is a prevalent problem in finance (e.g., see Harvey et al. (2016), Freyberger, Neuhierl, and Weber (2020), Feng, Giglio, and Xiu (2020), and Giglio and Xiu (2021)).3 Yet, in the empirical accounting literature, omitted variables have been addressed mainly in relation to causal relationships (e.g., see Roberts and Whited (2013) and Gow, Larcker, and Reiss (2016)). Furthermore, issues with reliance on p-values are well established in the finance literature (e.g., see Keuzenkamp and Magnus (1995), McCloskey and Ziliak (1996), Kim and Ji (2015), and Harvey et al. (2016)). However, few papers address the risk of model misspecification (e.g., see Feng et al. (2020)), which is our main focus. The remainder of this paper is organized as follows. Section II sets the theoretical foundation by introducing the DML procedure. Section III describes the data and defines important variables. Section IV demonstrates the capabilities of DML and the issues with least squares in high-dimensions. Finally, Section V concludes the paper. II. Methodology Selecting the correct covariates is challenging when theory about doing so is scarce and when relations are many and may be complex and nonlinear. In such settings, it is infeasible to assume that researchers can choose the correct set of controls unambiguously to ensure correct model specification. Therefore, the possibility of misspecifying the model and thereby creating omitted-variable bias cannot be neglected. When exploring PEAD, it is of utmost importance to select the set of explanatory variables consistently associated with PEAD in order to ensure valid inference of new variables. One strategy for doing so is to run a standard lasso regression assuming sparsity and define all nonzero variables as important; however, this naive method does not ensure valid inference because the coefficients will be biased, and so it 3Feng et al. (2020) used double selection to mitigate an omitted-variable bias with lasso estimation to investigate the marginal importance of factors related to cross section of stock returns. 7 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 7,
    "page_range": "p.7",
    "total_pages": 80,
    "chunk_index": 12,
    "word_count": 336,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.7)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "method does not ensure valid inference because the coefficients will be biased, and so it 3Feng et al. (2020) used double selection to mitigate an omitted-variable bias with lasso estimation to investigate the marginal importance of factors related to cross section of stock returns. 7 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 8,
    "page_range": "p.8",
    "total_pages": 80,
    "chunk_index": 13,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.8)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "is applicable only for prediction tasks. To overcome this, Nickl and Van De Geer (2013) explore the possibility of constructing confidence intervals in high-dimensional settings, and Javanmard and Montanari (2014) propose an efficient algorithm for constructing confidence intervals and p-values. Lee et al. (2016) propose a general approach to conduct valid inference after model selection and a variable relevance test.4 Furthermore, several novel findings and methods have been proposed in the statistical literature on estimating treatment effects (see Belloni et al. (2012), Belloni et al. (2014b), Belloni, Chernozhukov, and Hansen (2014a), Belloni, Chernozhukov, Fernández-Val, and Hansen (2017), and Athey et al. (2018)). However, the present paper relies on the more general and flexible DML procedure of Chernozhukov et al. (2018), which can determine the correct set of explanatory variables in a purely data- driven way. The method enables estimation of the familiar linear beta coefficient with valid confidence intervals using a broad set of machine learning methods. Unlike other high-dimensional approaches, the DML framework is not restricted to a linear functional form because the procedure relies on a partial linear structure. The loss function is modified to ensure valid statistical inference of the variable of interest. II.A. The DML Procedure For the DML procedure, as in Chernozhukov et al. (2018), we consider the partially linear model (PLM) given by (1) Y = Xθ +g (Z)+ε, E(cid:2)ε|Z,X(cid:3) = 0, 0 0 (2) X = m (Z)+ν, E(cid:2)ν|Z(cid:3) = 0, 0 where θ is the parameter of interest, X is the variable of interest, Y is the outcome 0 variable, ε and ν are disturbance terms, and Z∈RP contains P covariates used as control variables. The main takeaways from the model are the following. First, θ can 0 4AdditionalstudiesincludeVandeGeer,Bühlmann,Ritov,andDezeure(2014),ZhangandZhang(2014), and Lei, G’Sell, Rinaldo, Tibshirani, and Wasserman (2018). 8 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 8,
    "page_range": "p.8",
    "total_pages": 80,
    "chunk_index": 14,
    "word_count": 301,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.8)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "interest, Y is the outcome 0 variable, ε and ν are disturbance terms, and Z∈RP contains P covariates used as control variables. The main takeaways from the model are the following. First, θ can 0 4AdditionalstudiesincludeVandeGeer,Bühlmann,Ritov,andDezeure(2014),ZhangandZhang(2014), and Lei, G’Sell, Rinaldo, Tibshirani, and Wasserman (2018). 8 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 9,
    "page_range": "p.9",
    "total_pages": 80,
    "chunk_index": 15,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.9)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "be interpreted as a standard beta coefficient with valid standard errors in a linear regression. In relation to the PEAD literature, θ is the parameter explaining the 0 association between the variable of interest and PEAD. Second, the functional form by which Z affects X and Y can be nonlinear and high-dimensional. Third, we can use a broad set of machine learning methods to uncover these high-dimensional nonlinear relationships between Z and X and between Z and Y. To clarify, equation (1) is the main equation, describing the relationship between the outcome variable and the variable of interest, X. Equation (2) is not of direct interest, but it accounts for the dependency between the controls and X; it is critical when removing the regularization bias, akin to omitted-variable bias. The PLM structure makes no parametric assumptions about g (Z) or m (Z), thus it induces fewer 0 0 researcher-dependent choices and limits the risk of model misspecification. Instead, the two functions are treated as high-dimensional nuisance functions permitting nonlinear effects of Z. The term “nuisance function” refers to a function that is not of immediate interest but is necessary for ensuring correct model specification. Estimates of both g and m are needed to partial out the impact of Z on X and Y, in the spirit of 0 0 Frisch–Waugh–Lovell, ensuring an unbiased estimate of θ (see Chernozhukov et al. 0 (2018)). A straightforward albeit naive approach would be to estimate g in a separate part 0 of the dataset—known as the auxiliary part—via machine learning, then partial out the effect of Z on Y, and finally estimate θ by using the least squares of X on Y −gˆ (Z). 0 0 However, as discussed by Chernozhukov et al. (2018), this naive approach will induce ˆ overfitting and regularization bias, triggered by θ not being root-n consistent. To 0 overcome the “inferior” rate of convergence, Chernozhukov et al. (2018) proposed an orthogonalized formulation of the PLM; this accounts for regularization bias resulting in root-n consistency of θ . Thus, the new representation of the PLM is given as 0 (3) Y −‘ (Z) = (cid:0)X −m (Z)(cid:1)θ +ε, 0 0 0 9 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 9,
    "page_range": "p.9",
    "total_pages": 80,
    "chunk_index": 16,
    "word_count": 367,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.9)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "al. (2018) proposed an orthogonalized formulation of the PLM; this accounts for regularization bias resulting in root-n consistency of θ . Thus, the new representation of the PLM is given as 0 (3) Y −‘ (Z) = (cid:0)X −m (Z)(cid:1)θ +ε, 0 0 0 9 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 10,
    "page_range": "p.10",
    "total_pages": 80,
    "chunk_index": 17,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.10)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "where the estimate of the conditional expectation functions ‘ (Z) = E[Y | Z] = 0 m (Z)θ +g (Z)andm (Z) = E[X | Z]arenonparametricregressiontasksestimated 0 0 0 0 ˆ in an auxiliary sample via machine learning yielding ‘ and mˆ . With the primary 0 0 object of predicting conditional expectations, machine learning is a good candidate for the task in hand. The impact by which Z affects X and Y is then partialled out in the main sample, followed by the double-residualized regression of equation (3). Following Chernozhukov et al. (2018), two-fold cross-fitting is applied to ensure that an overfitting bias from using machine learning will not distort the θ estimates. Specifically, the 0 data are split in two, the main part n = N/2 and an auxiliary part of size N −n. We use the auxiliary part to obtain an estimate of E[Y | Z] and E[X | Z], enabling us to achieve a valid estimate of θ in the main part. This cross-fitting strategy yields 0 a root-n consistent estimate of θ for a large set of machine learning methods. As 0 argued by Chernozhukov et al. (2018), the two-fold cross-fitting procedure reduces the efficiency of the estimate because the data are split in two. Efficiency can be restored by flipping the role of the main and auxiliary samples.5 The main results rely on the post-lasso estimator of Belloni and Chernozhukov (2013) when estimating the nuisance functions. In a robustness check we also consider the random forest estimator. We provide further detail on the DML procedure and post-lasso estimator in Internet Appendix A. III. Data The sample of stocks used herein includes all listed securities from the Center for Research on Security Prices (CRSP) database with share codes 10 and 11. We require that all securities are listed on the New York Stock Exchange, NASDAQ, or AMEX and report earnings announcements in the merged CRSP/Compustat database.6 Before 5The two estimates will be approximately independent; thus, averaging will restore full efficiency. 6WelinkfirmPERMNOoftheCRSP/CompustatdatabasetoCUSIPcodesusedintheThomsonReuters I/B/E/S and Datastream database using the linking suite from Wharton Research Data Services. 10 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 10,
    "page_range": "p.10",
    "total_pages": 80,
    "chunk_index": 18,
    "word_count": 354,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.10)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "New York Stock Exchange, NASDAQ, or AMEX and report earnings announcements in the merged CRSP/Compustat database.6 Before 5The two estimates will be approximately independent; thus, averaging will restore full efficiency. 6WelinkfirmPERMNOoftheCRSP/CompustatdatabasetoCUSIPcodesusedintheThomsonReuters I/B/E/S and Datastream database using the linking suite from Wharton Research Data Services. 10 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 11,
    "page_range": "p.11",
    "total_pages": 80,
    "chunk_index": 19,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.11)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "matching across variables, the entire sample spans from July 1971 to the end of March 2020, totaling 781,975 firm-quarters across 19,253 unique companies. III.A. Variable Construction We construct 20 control variables previously used in the empirical literature; the constructionof each variable isdescribedin InternetAppendix B.Toimprovenumerical optimization and ease the interpretation of coefficients, we standardize the continuous value of each control. In a robustness check reported in Section IV.E, we consider various quantile ranks of the variables. Summary statistics for the variables are given in Table 1. To control for additional stock-specific covariates, we consider 96 stock-specific variables from the cross-section of the stock returns literature as used by Green et al. (2017).7 After matching with our data, we remove all variables for which our dataset has more than 50,000 observations with missing values, which yields 73 variables. We measure stock-specific variables in the same month as the event date.8 These stock-specific predictive characteristics have not necessarily been linked to PEAD but have been found to explain the cross-section of stock returns. We provide a list of the stock-specific variables in Internet Appendix B.9 To control for possible industry and time effects, we include (i) industry dummies constructed using French’s 48 industry classifications and (ii) the year, month, and day of the week dummies. After matching across variables, we have 97 fixed effects. 7See the corresponding paper for details about the variables. We thank the authors for making their SAS code available; it can be found on Jeremiah Green’s website: https://sites.google.com/site/jeremiahrgreenacctg/home. 8Results are robust to measuring the stock-specific variables in the prior month. The main results are reported using this measurement period in Internet Appendix C. 9Because of data availability, we do not consider all the variables used by Green et al. (2017). 11 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 11,
    "page_range": "p.11",
    "total_pages": 80,
    "chunk_index": 20,
    "word_count": 297,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.11)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "website: https://sites.google.com/site/jeremiahrgreenacctg/home. 8Results are robust to measuring the stock-specific variables in the prior month. The main results are reported using this measurement period in Internet Appendix C. 9Because of data availability, we do not consider all the variables used by Green et al. (2017). 11 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 12,
    "page_range": "p.12",
    "total_pages": 80,
    "chunk_index": 21,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.12)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "Table 1: Summary Statistics of Variables of Interest. Variables are scaled for comparability. Variable definitions are provided in Internet Appendix B. Variable Type Scaling Mean 25th 50th 75th Std. CAR Value 102 −0.71 −11.27 −0.61 9.63 22.90 SUE Decile - 5.55 3.00 6.00 8.00 2.77 RUNUP Value 102 0.27 −6.28 0.16 6.57 14.22 PASTRET Value 102 6.21 −9.59 4.17 18.07 31.93 EARET Value 102 0.17 −2.27 0.05 2.50 5.99 PRICE Value 10−2 3.64 0.09 0.17 0.33 96.53 SIZE Value - 6.78 5.40 6.68 8.01 1.88 DOLVOL Value 10−5 9.29 0.18 0.94 4.54 90.94 VOL Value 10−4 2.53 0.14 0.53 1.95 6.73 BM Value - 0.53 0.28 0.46 0.70 0.66 ANALYST Value - 7.35 2.00 5.00 10.00 6.52 LEV Value - 0.21 0.04 0.18 0.31 0.20 TURNOVER Value - 0.26 0.07 0.14 0.26 0.97 DECR Dummy - 0.39 0.00 0.00 1.00 0.49 LOSS Dummy - 0.15 0.00 0.00 0.00 0.36 NRANK Decile - 5.86 3.00 6.00 8.00 2.94 REPLAG Value 10−1 3.59 2.40 3.10 4.30 1.75 SAMEFIS Dummy - 0.75 0.00 1.00 1.00 0.43 EXPRISK Value 103 0.16 0.03 0.07 0.16 0.30 ARBRISK Value 103 1.14 0.36 0.68 1.34 1.48 BETA Value - 1.16 0.75 1.09 1.49 0.58 ILLIQ Value 107 3.00 0.01 0.04 0.34 35.46 III.A.1. Surprise in Earnings Our main results are based on the earnings surprise measure using analyst forecasts and actual earnings rather than time series forecasts (see the discussion in Livnat and Mendenhall (2006)).10 We define the main surprise in earnings (SUE) variable for firm i in quarter t as: ˆ EPS −EPS i,t i,t (4) SUE = , i,t PRICE i,t 10For completeness, we also consider standardizing using the standard deviation of analyst forecasts and a time series measure of SUE (see Livnat and Mendenhall (2006) and Jegadeesh and Livnat (2006)). We again find a small set of variables explain PEAD. These results are included in Internet Appendix D. 12 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 12,
    "page_range": "p.12",
    "total_pages": 80,
    "chunk_index": 22,
    "word_count": 320,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.12)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "consider standardizing using the standard deviation of analyst forecasts and a time series measure of SUE (see Livnat and Mendenhall (2006) and Jegadeesh and Livnat (2006)). We again find a small set of variables explain PEAD. These results are included in Internet Appendix D. 12 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 13,
    "page_range": "p.13",
    "total_pages": 80,
    "chunk_index": 23,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.13)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "ˆ where EPS is the actual earnings per share reported in I/B/E/S, EPS is the median i,t i,t analyst expectation, and PRICE is the price reported in I/B/E/S. All stocks with a i,t share price less than $1 and observations with actual or forecasted earnings exceeding the share price are removed to reduce the noise of SUE deflators (see Livnat and Mendenhall (2006)). After matching across all variables and removing those missing, the sample spans from the start of April 1984 to the end of March 2020, totaling 170,719 firm-quarters across 5,315 unique companies. To address the existence of outliers and nonlinearity in the earnings surprise-return relation, we replace the continuous value of SUE with its decile rank computed using yearly breakpoints. We use decile ranks because PEAD is strongest for relatively extreme announcements (see Bernard and Thomas (1989), Bernard and Thomas (1990), Bhushan (1994), and Bartov, Radhakrishnan, and Krinsky (2000)). III.A.2. Abnormal Returns We calculate the abnormal return using the period after the earnings announcement (occurring at time t = 0) from time t+2 to t+61, CAR[2,61], because Bernard and Thomas (1989) show that PEAD is strongest in the three months after the earnings announcement. The firm-specific cumulative abnormal return is determined as the actual return minus the return predicted by the CAPM model.11 The model uses a fixed estimation window of t−231 to t−31 days prior to the announcement to avoid potential short-term trends in returns (see MacKinlay (1997)).12 11FollowingMacKinlay(1997),weregressthefirm-specificreturnforudaysintheestimationwindowon the market return, that is R −r =α +β (R −r ), where R is the CRSP value-weighted market u,i f i i u,m f u,m return. The abnormal return at time t for firm i is given as AR =R −r −αˆ −β ˆ(R −r )+ε . We t,i t,i f i i t,m f i require that at least 140 observations are present within the estimation window. 12The results are robust to changing the measurement horizon to CAR[2,21] or CAR[2,41] and to risk- adjustments of CAR using the Fama-French 3-factor model and its extension with momentum (see Carhart (1997)). 13 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 13,
    "page_range": "p.13",
    "total_pages": 80,
    "chunk_index": 24,
    "word_count": 349,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.13)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "require that at least 140 observations are present within the estimation window. 12The results are robust to changing the measurement horizon to CAR[2,21] or CAR[2,41] and to risk- adjustments of CAR using the Fama-French 3-factor model and its extension with momentum (see Carhart (1997)). 13 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "I. Introduction",
    "page_number": 1,
    "page_range": "p.1",
    "total_pages": 80,
    "chunk_index": 25,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "I. Introduction (p.1)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "IV.A. Model Specifications The majority of studies examining PEAD seek to identify a variable that can explain cross-sectional differences in the drift. These studies rely on the earnings response coefficient framework, where the next three months’ abnormal returns after an announcement are regressed on SUE, a variable of interest, their interaction, and a set of control variables. The aim is to find a significant relation between the variable of interest and PEAD. The main focus is therefore on the interaction term, which gauges how the stock market response varies across firms with different levels of the variable of interest. We create four different model specifications to test the sensitivity of inferences from the ex ante model chosen by the researcher and illuminate potential issues associated with omitted-variable bias. First, we estimate the cross-sectional differences in CAR[2,61] by including SUE, the variable of interest, X, and its interaction—often used as a motivating regression in empirical studies (see Hirshleifer et al. (2009) and DellaVigna and Pollet (2009)). We consider L variables of interest, X ∈ RL, where each variable i of interest is estimated in a separate regression, totaling L regressions. The general equation for the l-th variable is as follows: (cid:16) (cid:17) (5) CAR[2,61] = θ +SUE θ +X θ + X ×SUE θ +ε , 1 ≤ l ≤ L, i l,0 i l,1 l,i l,2 l,i i l,3 l,i where X is the variable of interest for announcement i, θ , and θ are parameters of l,i l,2 l,3 interest, and ε is an error term.13 Thus, θ measures the effect of SUE on CAR[2,61] l,i l,3 for different values of X and is therefore the parameter of primary interest. The l,i parameter of secondary interest is the estimate on the variable of interest, namely 13Whenpredictingthecross-sectionaldifferencesinCAR[2,61] andSUE ,werunthefollowingregression: i CAR[2,61] =θ +θ SUE +ε . i 0 l,1 i l,i 14 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 14,
    "page_range": "p.14",
    "total_pages": 80,
    "chunk_index": 26,
    "word_count": 317,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.14)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "l,3 for different values of X and is therefore the parameter of primary interest. The l,i parameter of secondary interest is the estimate on the variable of interest, namely 13Whenpredictingthecross-sectionaldifferencesinCAR[2,61] andSUE ,werunthefollowingregression: i CAR[2,61] =θ +θ SUE +ε . i 0 l,1 i l,i 14 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 15,
    "page_range": "p.15",
    "total_pages": 80,
    "chunk_index": 27,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.15)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "θ , which measures its association with CAR[2,61]. In addition to SUE, we consider 20 l,2 variables previously used in the empirical literature, hence L = 20. For the second specification, a subset of control variables chosen ex ante, x ∈ i X and the corresponding interactions, x ×SUE , are added. We define Z(1) = (−l),i i i i {x ,x ×SUE }. In line with the first specification, the general equation for the l-th i i i variable is as follows: (6) (cid:16) (cid:17) CAR[2,61] = θ +SUE θ +X θ + X ×SUE θ +Z(1)β +ε , 1 ≤ l ≤ L, i l,0 i l,1 l,i l,2 l,i i l,3 i l,i where Z(1) denotes the set of control variables chosen ex ante and β = (β ,β ,...,β )0 i 1 2 P is a P vector. This is the most common specification used in the empirical literature explaining PEAD (see, e.g., Bhushan (1994), Bartov et al. (2000), and Mendenhall (2004)). However, it is notable that this specification often relies on five to ten control variables with little justification for including or excluding particular variables (Whited et al. (2022)). Consistent with the literature, we consider only a subset of common control variables among the 20 variables studied, i.e., the abnormal one-month prior return (RUNUP), returns over the past year (PASTRET), stock price (PRICE), firm size (SIZE), dollar trading volume (DOLVOL), book-to-market (BM), explained risk (EXPRISK), arbitrage risk (ARBRISK), and illiquidity (ILLIQ), hence P = 9×2 = 18.14 We consider the impact of altering the set of controls in Section IV.B.1. The third specification mimics a “kitchen sink” approach in which a large set of controls is included to avoid potential review comments (see Whited et al. (2022)). We include the full set of control variables, i.e., SUE, all 20 variables of interest, 47 industry fixed effects, and 50 time fixed effects (year, month, and day of the week), n o defined as D . We define Z(2) = X ,X ×SUE ,D and the equation for the i i (−l),i (−l),i i i 14Note that if one of the controls is the variable of interest then P =16. 15 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 15,
    "page_range": "p.15",
    "total_pages": 80,
    "chunk_index": 28,
    "word_count": 369,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.15)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "day of the week), n o defined as D . We define Z(2) = X ,X ×SUE ,D and the equation for the i i (−l),i (−l),i i i 14Note that if one of the controls is the variable of interest then P =16. 15 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 16,
    "page_range": "p.16",
    "total_pages": 80,
    "chunk_index": 29,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.16)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "l-th variable as: (7) (cid:16) (cid:17) CAR[2,61] = θ +SUE θ +X θ + X ×SUE θ +Z(2)β +ε , 1 ≤ l ≤ L, i l,0 i l,1 l,i l,2 l,i i l,3 i l,i where Z(2) contains the set of controls and β = (β ,β ,...,β )0 is a P vector. A total i 1 2 P of P =19+19+97=135 variables are included in Z(2). i The fourth specification removes the need for ex ante variable selection by utilizing the DML procedure, and it also allows for a more flexible PLM structure. We consider the following equations for the l-th variable: (8) (cid:16) (cid:17) (cid:18) (cid:19) CAR[2,61] = SUE θ +X θ + X ×SUE θ +g Z(3) +ε , 1 ≤ l ≤ L, i l,i l,0 l,i l,1 l,i i l,2 l,0 i l,i (cid:18) (cid:19) (9) SUE = m Z(3) +ν0 , l,i l,0 i l,i (cid:18) (cid:19) (10) X = m Z(3) +ν1 , l,i l,1 i l,i (cid:16) (cid:17) (cid:18) (cid:19) (11) X ×SUE = m Z(3) +ν2 , l,i i l,2 i l,i where θ and θ are the parameters of interest, Z(3) contains the set of controls, and l,1 l,2 i ε , ν0 , ν1 , and ν2 are error terms. Because θ measures if the effect of SUE on l,i l,i l,i l,i l,2 CAR[2,61] varies significantly for different values of the variable of interest, it is our primary parameter of interest. We follow the method described in Section II and use the post-lasso method to estimate ‘ ˆ , mˆ , mˆ , and mˆ (see equation (3)).15 To l,0 l,0 l,1 l,2 leverage the high-dimensional capabilities of the post-lasso estimator, we also consider 73 stock-specific variables, S , from Green et al. (2017). Therefore, Z(2) is extended i i by S , S2, and all first-order interaction terms, hence Z(3) encompasses 135 main i i i variables, 73 stock-specific variables, and 2,628 derived variables. 15As discussed in Section II, we ensure full efficiency and valid standard errors by employing two-fold cross-fitting. The cross-fitting procedure introduces randomness but to limit the effect of this variability, we obtain 100 estimates of each parameter of interest and apply the median method, see Chernozhukov et al. (2018). 16 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 16,
    "page_range": "p.16",
    "total_pages": 80,
    "chunk_index": 30,
    "word_count": 383,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.16)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "we ensure full efficiency and valid standard errors by employing two-fold cross-fitting. The cross-fitting procedure introduces randomness but to limit the effect of this variability, we obtain 100 estimates of each parameter of interest and apply the median method, see Chernozhukov et al. (2018). 16 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 17,
    "page_range": "p.17",
    "total_pages": 80,
    "chunk_index": 31,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.17)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "As noted, we systematically examine each variable of interest, which yields L unique separate regressions. This allows for more flexibility in the DML method, compared to simply expanding X to X ∈ RL in equation (8). First, such an expansion will l,i i considerably restrict the model by assuming no dependency and no nonlinearities between the variable of interest X and X . Second, a linear relation between X l,i −l,i −l,i and CAR[2,61] is imposed by the researcher. Therefore, to reduce researcher dependency i and enable a more data-driven approach, we examine each variable sequentially, as opposed to performing a joint examination.16 To increase flexibility and allow for potential nonlinearities, we repeat the analysis using the random forest method to estimate the nuisance function in Section IV.E.1. The random forest method not only allows for nonlinearity but also implicitly accommodates interaction effects between explanatory variables, which enables us to exclude all first-order and second-order interaction terms in Z(3). i IV.B. Empirical Results of the Model Specifications Inferences for both the primary interaction term estimates and the total number of significant estimates across the four model specifications are summarized in Table 2 and the corresponding coefficient estimates for the interaction terms are presented in Table 3. The number of significant variables are reported using a 1% standard significance level and also with a Benjamini-Hochberg correction, which controls for the error rate when conducting multiple testing (Benjamini and Hochberg (1995)). We cluster standard errors by announcement day and firm (Petersen (2009)) to account for potential time-series and cross-sectional dependencies. After partialling out the effect of the nuisance functions, we compute cluster robust standard errors for the DML procedure. 16NotethatwecannotcomputemeaningfulandcomparableR-squaredvaluesbetweenOLSandtheDML procedure. As seen in equation (3), the resulting R-squared from the DML specification will only be based on the residual regression after partialling out. 17 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 17,
    "page_range": "p.17",
    "total_pages": 80,
    "chunk_index": 32,
    "word_count": 308,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.17)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "After partialling out the effect of the nuisance functions, we compute cluster robust standard errors for the DML procedure. 16NotethatwecannotcomputemeaningfulandcomparableR-squaredvaluesbetweenOLSandtheDML procedure. As seen in equation (3), the resulting R-squared from the DML specification will only be based on the residual regression after partialling out. 17 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 18,
    "page_range": "p.18",
    "total_pages": 80,
    "chunk_index": 33,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.18)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "Table 2: Summary of Inferences Across Model Specifications. Thefirsttworowsofthetablereportthenumbersofsignificantinteractionterms—whicharetheparameters ofprimaryinterest—acrossthefourmodelspecificationsata1%standardsignificancelevelandaBenjamini– Hochbergcorrectedlevel.Thebottomtworowsreportthetotalnumbersofsignificantinteractiontermsand variables of interest (non-interaction terms). DML OLS OLS OLS w. post-lasso Selected Full set of Nuisance Separate regressions using: No controls controls controls function Significant interaction terms (1%) Standard significance level 8/20 8/20 7/20 5/20 B-H. corrected 7/20 5/20 6/20 4/20 Significant variables (1%) Standard significance level 23/41 23/41 21/41 13/41 B-H. corrected 23/41 20/41 20/41 12/41 The first column of Table 2 reports the results for the first specification, which depends on a single variable (see equation (5)). In total, eight out of 20 interaction terms can significantly explain the variation in PEAD. Interestingly, we observe only a minimal drop in the number of significant variables when considering the more conservative Benjamini–Hochberg corrected p-values. It is difficult to justify the assumption that the model specification is correct, because inferences are only based on SUE, the variable of interest, and their interaction. If this naive specification is perfectly specified and no omitted-variable bias is present, then including more controls will have a limited effect on the coefficient estimates and their standard errors. Reported respectively in the second and third columns, the second and third specificationsshowlittleornochangeinthenumbersofsignificantvariables,tentatively suggesting that there is no omitted-variable bias in the first specification.17 However, when investigating the coefficient estimates below, a profound inconsistency is detected 17The second specification uses a set of controls chosen ex ante, namely RUNUP, PASTRET, PRICE, SIZE, DOLVOL, BM, EXPRISK, ARBRISK, and ILLIQ, as explained in Section IV.A. 18 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 18,
    "page_range": "p.18",
    "total_pages": 80,
    "chunk_index": 34,
    "word_count": 252,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.18)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "bias in the first specification.17 However, when investigating the coefficient estimates below, a profound inconsistency is detected 17The second specification uses a set of controls chosen ex ante, namely RUNUP, PASTRET, PRICE, SIZE, DOLVOL, BM, EXPRISK, ARBRISK, and ILLIQ, as explained in Section IV.A. 18 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 19,
    "page_range": "p.19",
    "total_pages": 80,
    "chunk_index": 35,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.19)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "across columns. The fourth specification makes no ex ante model selection choices. Instead, it relies on the DML procedure and the extended dataset (see equations (8)–(11)). Only one out of four interaction terms are significant at a 1% level, equivalent to at least a 28% decrease compared to the first, second, and third specifications. The decrease is even more pronounced for all variables, reported in the bottom two rows of Table 2. Table 3 reports the coefficient estimates of primary interest, i.e., the interactions between SUE and each variable of interest. We also report estimation results for the variables of interest themselves (non-interaction terms) in Table C1 in Internet Appendix C. As stated in Section IV.A, we estimate a single regression for each variable, so each row of Table 3 represents 20 separate regressions. Variables are listed based on the magnitude of differences in coefficient estimates between the first and fourth columns, and significance at the 1% level is indicated by bold font. When disagreements about the conclusion of significance are observed between the first and fourth columns, we underline the variable name. We provide a visual summary of the results in Figures C1 and C2 in Internet Appendix C. As reported in the first column of Table 3, eight out of 20 variables are statistically significant, whereas 15 out of 20 are significant in the first column of the non-interaction terms estimates in Table C1. The ease of detecting small and complex effects with the first specification is clearly illustrated when merging the results of the two columns, because 17 out of 20 variables can statistically significantly explain either PEAD or the abnormal return at a 1% level. It is important to note that the ease of detecting statistical significance is amplified by the reliance on over 170,000 earnings announcements.18 18ThehighnumberofobservationsusedhereinisconsistentwiththePEADliterature(e.g.,seeBhushan (1994), Livnat and Mendenhall (2006), and DellaVigna and Pollet (2009)). 19 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 19,
    "page_range": "p.19",
    "total_pages": 80,
    "chunk_index": 36,
    "word_count": 318,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.19)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "explain either PEAD or the abnormal return at a 1% level. It is important to note that the ease of detecting statistical significance is amplified by the reliance on over 170,000 earnings announcements.18 18ThehighnumberofobservationsusedhereinisconsistentwiththePEADliterature(e.g.,seeBhushan (1994), Livnat and Mendenhall (2006), and DellaVigna and Pollet (2009)). 19 Electronic copy available at: https://ssrn.com/abstract=4017917 Table 3: Estimates of Interaction Terms Across Model Specifications. Variables are listed based on the magnitude of the differences in coefficient estimates from the first and fourthcolumns.Underscoredvariablenamesdenotechangesinsignificance,andboldcoefficientvaluesdenote significanceatthe1%level.Thespecificationsuseallfirm-quartersinthesampleandeachcontrolvariableis continuousbutstandardized,exceptforSUE,whichisindeciles.Thefirstnumericalcolumnreportsestimates (in percent) from separate regressions with no controls for the parameters of primary interest. The second column adds the set of controls chosen ex ante and their interactions with SUE, and the third column uses the full set of controls. The fourth column reports estimates using the high-dimensional nuisance function. The estimates for the variables of interest themselves (non-interaction terms) are reported in Table C1 in Internet Appendix C. Standard errors are clustered by day and firm. DML OLS OLS OLS w. post-lasso Selected Full set of Nuisance Separate regressions using: No controls controls controls function SUE×REPLAG −3.588 −3.264 −3.693 −2.051 SUE×SIZE 0.138 −1.792 −2.969 −1.338 SUE×LOSS 0.077 −0.343 −0.270 −1.170 SUE×VOL 0.405 1.111 1.162 −0.817 SUE×DOLVOL 0.732 0.893 0.651 −0.418 SUE×LEV 0.435 −0.018 0.167 −0.499 SUE×EXPRISK −1.231 0.563 0.642 −0.383 SUE×DECR 0.197 0.173 0.060 −0.624 SUE×EARET 1.333 0.905 0.861 0.548 SUE×ARBRISK −1.534 −1.464 −1.419 −0.886 SUE×ANALYST −0.317 0.043 −0.281 −0.873 SUE×ILLIQ 0.399 0.178 0.084 −0.078 SUE×SAMEFIS 1.504 1.654 1.117 1.925 SUE×BETA −1.480 −0.710 −0.833 −1.183 SUE×PASTRET 3.242 3.225 3.381 2.973 SUE×BM −0.608 −0.506 −0.645 −0.751 SUE×TURNOVER 0.143 0.369 0.146 0.009 SUE×PRICE 1.086 1.226 1.199 0.969 SUE×RUNUP 0.656 0.746 0.714 0.719 SUE×NRANK 1.317 0.766 −1.680 1.317 Observations 170,719 170,719 170,719 170,719 Fixed effects X X No. of variables 3 21 138 2,839 20 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 20,
    "page_range": "p.20",
    "total_pages": 80,
    "chunk_index": 37,
    "word_count": 297,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.20)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "3.225 3.381 2.973 SUE×BM −0.608 −0.506 −0.645 −0.751 SUE×TURNOVER 0.143 0.369 0.146 0.009 SUE×PRICE 1.086 1.226 1.199 0.969 SUE×RUNUP 0.656 0.746 0.714 0.719 SUE×NRANK 1.317 0.766 −1.680 1.317 Observations 170,719 170,719 170,719 170,719 Fixed effects X X No. of variables 3 21 138 2,839 20 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 21,
    "page_range": "p.21",
    "total_pages": 80,
    "chunk_index": 38,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.21)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "Table 3 shows substantial changes in the coefficient estimates reported across columns. This suggests the presence of an omitted-variable bias, which was not evident from the summary in Table 2. For instance, the estimate of SUE×NRANK changes sign from 1.317 in the first column to −1.680 in the third column, but it is statistically significant in both cases. This example demonstrates the failure of linear regression in high-dimensional settings. However, by relying on the high-dimensional capabilities of DML, we find support for the hypothesis of a positive association between the amount of other distracting earnings news (NRANK) and PEAD (see Hirshleifer et al. (2009)). The DML results in the fourth column confirm the statistical significance of the interaction terms of reporting lag (REPLAG), a same fiscal quarter indicator (SAMEFIS), PASTRET, and NRANK. Diving further into the DML procedure, results show that a loss indicator if the last announcement was negative (LOSS) is positive and significant at the 1% level, with a larger magnitude than in the OLS specifications. In contrast to the OLS specifications, the DML procedure does not detect statistical significance for SIZE, number of shares traded (VOL), or announcement date abnormal returns (EARET). The non-significance of SIZE is surprising, because this is one of the oldest explanations of PEAD. In Section IV.C, we document how SIZE has been significant in subsamples spanning from 1998 to 2005, which may explain its earlier importance. As reported in Table 3 and illustrated in Figure C1 in Internet Appendix C, when comparing DML to the OLS specifications, we observe a noticeable change in coefficient magnitudes and increased standard errors. To quantify the differences in coefficient estimates, we compute the standardized difference between two means using Cohen’s d. Comparing the third and fourth columns, almost 60% (41%) of the variables show a Cohen’s d above 1 (2), so they have a difference between the effects of more than one (two) standard deviations. From Table 3, it is difficult to gauge whether inferences change because of the high-dimensional set of controls used or the DML procedure. Therefore, we restrict DML to incorporate the full set of controls, Z(2), without stock-specific variables or i 21 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 21,
    "page_range": "p.21",
    "total_pages": 80,
    "chunk_index": 39,
    "word_count": 365,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.21)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "one (two) standard deviations. From Table 3, it is difficult to gauge whether inferences change because of the high-dimensional set of controls used or the DML procedure. Therefore, we restrict DML to incorporate the full set of controls, Z(2), without stock-specific variables or i 21 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 22,
    "page_range": "p.22",
    "total_pages": 80,
    "chunk_index": 40,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.22)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "second-order interaction terms (see Table C2 in Internet Appendix C). We find that standard errors generally increase because of this procedure, whereas coefficients change because of the exponential increase in controls, indicating that coefficient estimates should be more precise when accounting for the high-dimensional set of controls. With a more flexible structure and cross-fitting, it is not surprising that DML yields higher standard errors. Overall, DML provides a strong conservative baseline for statistical significance in high dimensions compared to traditional linear regression methods. Therefore, we argue that the credibility of these variables is thus strengthened. IV.B.1. The Sensitivity of OLS To illustrate the sensitivity of the standard linear regression, we randomly permute the set of controls chosen ex ante. Figure 1 plots t-statistics from a linear regression where the set of controls is selected randomly (either five, ten, or 20 different controls) from the 20 variables of interest and the 73 stock-specific variables.19 The figure reports the results for SUE, SIZE×SUE, ANALYST×SUE, and BM×SUE using 500 different permutations of controls. Therefore, this test assumes that the researcher has access to the full set of variables but has no prior knowledge about which to choose. This illustration simulates a common hurdle that researchers face in many aspects of financial research. Figure 1 shows the instability of inferences when randomly permuting the set of controls. As demonstrated in panel A, the inferences for SUE are very volatile and vary from non-significant to highly significant, with t-statistics well above ten. The t-statistics are found more frequently to be close to zero when relying on five controls compared to ten or 20. Conditioning on five controls, 19% of the permutations are significant at the 1% level, in contrast to 74% when conditioning on 20 controls. The same sensitivity is evident in panels B and C for SIZE×SUE and ANALYST×SUE, respectively. Even though the number of analysts following a stock (ANALYST) was 19The results remain similar when selecting randomly from the set of 20 variables of interest. 22 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 22,
    "page_range": "p.22",
    "total_pages": 80,
    "chunk_index": 41,
    "word_count": 338,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.22)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "on 20 controls. The same sensitivity is evident in panels B and C for SIZE×SUE and ANALYST×SUE, respectively. Even though the number of analysts following a stock (ANALYST) was 19The results remain similar when selecting randomly from the set of 20 variables of interest. 22 Electronic copy available at: https://ssrn.com/abstract=4017917 found to be non-significant in all four specifications in Table 3, Figure 1 reveals that ANALYST can statistically significantly explain PEAD for 60% of the permutations using 20 variables. Figure 1: Sensitivity of OLS Inferences. This figure plots t-statistics obtained with OLS for four different estimates using 500 different permutations of controls. Each panel shows the outcomes of randomly selecting five, ten, or 20 different controls from the variables of interest and the set of stock-specific variables, S. Panel A: SUE Panel B: SIZE×SUE Panel C: ANALYST× SUE Panel D: BM× SUE Finally, panel D documents how BM×SUE is detected consistently as non-significant. 23 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 23,
    "page_range": "p.23-24",
    "total_pages": 80,
    "chunk_index": 42,
    "word_count": 159,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.23-24)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "selecting five, ten, or 20 different controls from the variables of interest and the set of stock-specific variables, S. Panel A: SUE Panel B: SIZE×SUE Panel C: ANALYST× SUE Panel D: BM× SUE Finally, panel D documents how BM×SUE is detected consistently as non-significant. 23 Electronic copy available at: https://ssrn.com/abstract=4017917 This small illustration demonstrates a major challenge in the high-dimensional setting, i.e., when relying on traditional statistical methods, hand picking the “correct” set of controls can lead to unreliable inferences. IV.C. Inferences Through Time A natural concern is the reliance on a sample spanning from 1984 to 2020, which includes years that were unavailable for researchers in the 1990s and 2000s. Therefore, this section examines systematically the consistency of variables’ relevance through time to detect whether pockets of significance have occurred. We compute inferences based on ten years of data and roll the window from 1993 to 2019. Panel A in Figure 2 reports significance using the full set of controls, whereas panel B reports significance using DML.20 The panels show the p-value for each corresponding interaction term displayed on the vertical axis. Figure 2: Inferences Through Time. This figure reports p-values from separate regressions based on ten years of data. We use a rolling window from 1993 to 2019. Panel A uses OLS with the full set of controls, and panel B uses DML. Both panels consider the respective interaction term between SUE and the variable listed on the y-axis. Variables are listed according to Table 3. The colors illustrate the significance level: 1% (blue), 5% (green), 10% (yellow), and non-significant (white). Panel A: OLS - Full Set of Controls Panel B: DML REPLAG REPLAG SIZE SIZE LOSS LOSS p<0.01 VOL VOL DOLVOL DOLVOL LEV LEV EXPRISK EXPRISK DECR DECR p<0.05 EARET EARET ARBRISK ARBRISK ANALYST ANALYST ILLIQ ILLIQ SAMEFIS SAMEFIS p<0.1 BETA BETA PASTRET PASTRET BM BM TURNOVER TURNOVER PRICE PRICE p>=0.1 RUNUP RUNUP NRANK NRANK 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 20Results for the first and second model specifications and for both the interaction terms and variables themselves are presented in Figure C3 in Internet Appendix C. 24 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 24,
    "page_range": "p.24",
    "total_pages": 80,
    "chunk_index": 43,
    "word_count": 404,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.24)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 20Results for the first and second model specifications and for both the interaction terms and variables themselves are presented in Figure C3 in Internet Appendix C. 24 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 25,
    "page_range": "p.25",
    "total_pages": 80,
    "chunk_index": 44,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.25)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "Panels A and B in Figure 2 show that a small set of variables has consistently explained PEAD through all subsamples. Across both panels, REPLAG, SAMEFIS, and PASTRET are highly statistically significant for the majority of the sample period, supporting the full sample evidence in Table 3. A direct comparison between the panels reveals more conservative estimates for DML. For example, SIZE, DOLVOL, and NRANK are significant across the majority of the subsamples in panel A, but not those in panel B. Although Table 3 identifies LOSS and NRANK as significant based on DML, panel B reveals only pockets of significance. Furthermore, pockets of significance are also found for SIZE, DOLVOL, a decreasing earnings between quarters indicator (DECR), and BM, which can explain earlier findings in the literature (see, e.g., Foster et al. (1984), Narayanamoorthy (2006) and Shivakumar (2006)). Overall, the results in panel B supports that a small set of variables has consistently explained PEAD through time. IV.D. Controls That Matter This subsection investigates the advantages of relying on the more conservative inferences obtained from DML when exploring a new high-dimensional set of potential variables. We question whether any of the 73 stock-specific variables from Green et al. (2017) are associated with PEAD. We expect a low signal-to-noise ratio because we investigate a high-dimensional set of potential controls with no former association to PEAD, and therefore we propose a two-step scheme. First, a pre-inference step is conducted with the object of reducing dimensionality and increasing computational feasibility. We employ lasso’s ability to perform variable selection on the following regression: (12) CAR[2,61] = Z β +ε , i i i where Z = {1,SUE ,X ,SUE ×X ,S ,SUE ×S } and β = (β ,β ,...,β )0 is a P i i i i i i i i 1 2 P vector. A total of P =2+2×(20+73) =188 variables are included in Z . As variables of i 25 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 25,
    "page_range": "p.25",
    "total_pages": 80,
    "chunk_index": 45,
    "word_count": 325,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.25)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": ",SUE ×X ,S ,SUE ×S } and β = (β ,β ,...,β )0 is a P i i i i i i i i 1 2 P vector. A total of P =2+2×(20+73) =188 variables are included in Z . As variables of i 25 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 26,
    "page_range": "p.26",
    "total_pages": 80,
    "chunk_index": 46,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.26)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "interest, we consider all variables for which either the interaction term or the variable itself has a nonzero coefficient.21 In the second step, we follow the same procedure as in Section IV.B, where we conduct inferences on each nonzero variable from the pre-inference step using all four model specifications. Results for the nonzero stock-specific variables are summarized in Table 4, and coefficient estimates are reported in Table 5. Because each selected variable is estimated in a separate regression and conditioned on the same explanatory variables as in Section IV.B, the 20 estimated variables from that section have identical coefficients and are therefore excluded from the table. The nonzero variables chosen by lasso in the first pre-inference step are associated with price trends, liquidity, and arbitrage risk. Specifically, the 11 newly selected stock- specific variables are the number of earnings increases (NINCR), industry momentum (INDMOM), bid-ask spread (BASPREAD), 12-month momentum (MOM12M), 1- month momentum (MOM1M), idiosyncratic volatility (IDIOVOL), change in tax expense (CHTX), 36-month momentum (MOM36M), asset growth (AGR), volatility of dollar trading volume (STD_DOLVOL), and financial statement score (MS).22 The selected variables are consistent with findings of Gu et al. (2020), who find prominent roles for momentum, liquidity, and volatility in explaining general equity risk premia. Therefore, relying on the pre-inference step, we document a clear link between the variables explaining general return patterns and PEAD. In addition to the four dominant momentum variables, we find joint evidence of two well-established PEAD hypotheses, i.e. illiquidity (see Chordia et al. (2009)) and limited arbitrage (see Mendenhall (2004)). Consistent with the first hypothesis, lasso detects VOL, TURNOVER, BASPREAD, and STD_DOLVOL, which proxy illiquidity (see Chordia, Subrahmanyam, and Anshuman (2001) and Amihud and Mendelson (1989)). The 21Note, a naive approach relying on the estimated coefficients from lasso will be biased because of regularization. 22From the set of the initial 20 variables of interest SUE, PASTRET, EARET, SIZE, VOL, BM, ANALYST,leverage(LEV),shareturnover(TURNOVER),NRANK,REPLAG,SAMEFIS,EXPRISK,and ARBRISK are found to be nonzero. 26 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 26,
    "page_range": "p.26",
    "total_pages": 80,
    "chunk_index": 47,
    "word_count": 329,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.26)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "and Mendelson (1989)). The 21Note, a naive approach relying on the estimated coefficients from lasso will be biased because of regularization. 22From the set of the initial 20 variables of interest SUE, PASTRET, EARET, SIZE, VOL, BM, ANALYST,leverage(LEV),shareturnover(TURNOVER),NRANK,REPLAG,SAMEFIS,EXPRISK,and ARBRISK are found to be nonzero. 26 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 27,
    "page_range": "p.27",
    "total_pages": 80,
    "chunk_index": 48,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.27)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "second hypothesis of limited arbitrage is supported by the detection of the variables ARBRISK and IDIOVOL. Furthermore, in line with Gu et al. (2020), we find the last group of important variables to be valuation ratios and fundamental signals. There is a possibility that the small set of variables selected by lasso could be a direct result of its sparsity assumption, i.e., if two collinear variables predictive of the outcome are present, lasso tends to set one of them to zero. To address this concern, we re-run the analysis relying on the ridge method (Hoerl and Kennard (1970)) for the pre-inference step to ensure robustness. We find strong alignment between the 11 chosen variables from lasso and the size of the coefficients from ridge, suggesting lasso does not exclude any potentially essential variables. In addition to ridge, adaptive lasso can be a compelling alternative given its oracle properties (Zou (2006)). We find roughly identical results when comparing the set of nonzero variables between the two methods. Table 4: Summary of Inferences From Controls That Matter. Thefirsttworowsofthetablereportthenumbersofsignificantinteractionterms—whicharetheparameters ofprimaryinterest—acrossthefourmodelspecificationsata1%standardsignificancelevelandaBenjamini– Hochbergcorrectedlevel.Thebottomtworowsreportthetotalnumbersofsignificantinteractiontermsand variables of interest (non-interaction terms). DML OLS OLS OLS w. post-lasso Selected Full set of Nuisance Separate regressions using: No controls controls controls function Significant interaction terms (1%) Standard significance level 4/11 3/11 2/11 5/11 B-H. corrected 4/11 3/11 1/11 3/11 Significant variables (1%) Standard significance level 14/22 13/22 13/22 11/22 B-H. corrected 14/22 13/22 12/22 8/22 The summary for the second step is reported in Table 4, where DML identifies five of the 11 selected interaction terms as significant, which is slightly more than the OLS 27 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 27,
    "page_range": "p.27",
    "total_pages": 80,
    "chunk_index": 49,
    "word_count": 271,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.27)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "(1%) Standard significance level 14/22 13/22 13/22 11/22 B-H. corrected 14/22 13/22 12/22 8/22 The summary for the second step is reported in Table 4, where DML identifies five of the 11 selected interaction terms as significant, which is slightly more than the OLS 27 Electronic copy available at: https://ssrn.com/abstract=4017917 specifications. Because a minor set of interaction terms survives the two-step procedure, significance for the remaining 93% stock-specific variables cannot be claimed. Table 5: Controls That Matter. Variablesarelistedbasedonthemagnitudeofthedifferencesincoefficientestimatesfromthefirstandfourth columns. Underscored variable names indicate changes in significance, and bold coefficient values indicate significanceatthe1%level.Thespecificationsuseallfirm-quartersacrossthesample,andallcontrolvariables are continuous but standardized except for SUE, which is in deciles. The first numerical column reports estimates (in percent) from separate regressions with no controls for the parameters of primary interest. The second column adds the set of controls chosen ex ante and their interactions with SUE, and the third columnusesthefullsetofcontrols.Thefourthcolumnreportsestimatesusingthehigh-dimensionalnuisance function.Theestimatesforthevariablesofinterestthemselves(non-interactionterms)arereportedinTable C3 in Internet Appendix C. Standard errors are clustered by day and firm. DML OLS OLS OLS w. post-lasso Selected Full set of Nuisance Separate regressions using: No controls controls controls function SUE×NINCR −0.237 0.154 0.142 1.132 SUE×INDMOM 1.126 0.305 0.470 2.189 SUE×BASPREAD −1.996 −0.841 −0.863 −0.964 SUE×MOM12M 3.735 2.455 2.523 2.766 SUE×MOM1M 0.546 −0.015 0.337 1.367 SUE×IDIOVOL −0.522 0.290 0.667 0.150 SUE×CHTX −0.235 −0.197 −0.168 0.437 SUE×MOM36M −0.332 0.179 0.072 0.241 SUE×AGR −0.685 −0.303 −0.361 −0.434 SUE×STD_DOLVOL 0.988 1.518 1.116 1.152 SUE×MS 0.638 0.881 0.386 0.670 Observations 170,719 170,719 170,719 170,719 Fixed effects X X No. of variables 3 21 138 2,839 Comparing DML with the OLS specifications in Table 5, we see a notable difference in the coefficient estimate of the significant variables, e.g., NINCR, INDMOM, and MOM1M. Although little consistency in the coefficient estimate is detected, two variables stand out with consistent estimates across model specifications, namely 28 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 28,
    "page_range": "p.28",
    "total_pages": 80,
    "chunk_index": 50,
    "word_count": 300,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.28)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "the OLS specifications in Table 5, we see a notable difference in the coefficient estimate of the significant variables, e.g., NINCR, INDMOM, and MOM1M. Although little consistency in the coefficient estimate is detected, two variables stand out with consistent estimates across model specifications, namely 28 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 29,
    "page_range": "p.29",
    "total_pages": 80,
    "chunk_index": 51,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.29)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "MOM12M and STD_DOLVOL. With large coefficient estimates for the momentum variables INDMOM, MOM12M, and MOM1M in the fourth column, we find support for the importance of price trends in explaining PEAD using DML. Hence, firms whose stock price has momentum prior to the earnings announcement experience a larger drift. Together, these results provide important insights into how inferences can be conducted when investigating the link between PEAD and a high-dimensional set of new potential explanations with no former association. IV.D.1. Controls That Matter Through Time To strengthen the robustness of the results in the previous section, we examine whether either this new set of significant variables is only sporadically significant or a true association can be concluded. We conduct the same two-step scheme as in Section IV.D, where inferences are obtained over ten years and rolled from 1993 to 2019. Figure 3 reports the results based on OLS using the full set of controls in panel A and those based on DML in panel B.23 Panel A and B show the significance of each interaction term between the variable of interest and SUE. White color denotes that the variable is not selected in a given subsample, and for selected variables, blue denotes significance at the 1% level, green denotes 5%, yellow denotes 10%, and gray denotes selected but not significant. When considering the pre-inference step by lasso, a slight increase in the number of nonzero variables is reported when we split the data into 27 subsamples. In contrast to the 11 variables detected in the full sample, 16 stock-specific variables are found to be nonzero in the 27 subsamples.24 The new variables include change in 6-month momentum (CHMOM), industry-adjusted size (MVEIA), capital expenditures and inventory (INVEST), sales to price (SP), and revenue surprises (RSUP). Although 23Theresultsforthefirstandsecondmodelspecificationsandforboththeinteractiontermsandvariables themselves are reported in Figure C7 in Internet Appendix C. 24Theoriginal20variablesofinterestselectedbythepre-inferencestepareshowninFigureC5inInternet Appendix C. 29 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 29,
    "page_range": "p.29",
    "total_pages": 80,
    "chunk_index": 52,
    "word_count": 315,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.29)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "in the 27 subsamples.24 The new variables include change in 6-month momentum (CHMOM), industry-adjusted size (MVEIA), capital expenditures and inventory (INVEST), sales to price (SP), and revenue surprises (RSUP). Although 23Theresultsforthefirstandsecondmodelspecificationsandforboththeinteractiontermsandvariables themselves are reported in Figure C7 in Internet Appendix C. 24Theoriginal20variablesofinterestselectedbythepre-inferencestepareshowninFigureC5inInternet Appendix C. 29 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 30,
    "page_range": "p.30",
    "total_pages": 80,
    "chunk_index": 53,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.30)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "a more extensive set of variables is found to be nonzero, 85% of the 73 variables are constantly set to zero, emphasizing that the majority of variables are detected as not important by lasso. Turning to the second inference step of the two-step scheme, some interesting patterns emerge. As demonstrated by the colored squares, variables consistently chosen by the first step are generally highly significant, whereas variables selected sporadically are generally not significant. Focusing on the significant variables in panel B, MOM12M and MOM1M are consistently detected as significant, which is in line with the full sample results in Table 5. The variable MS was identified as non-significant in Section IV.D, but Figure 3 identifies it as significant from 1998 to 2009. Overall, compared to Section IV.D, we identify an even smaller set of variables that are consistently associated with PEAD, and these are related mainly to price trends. Figure 3: Controls That Matter Through Time. Thisfigurereportsp-valuesforstock-specificcovariatesfromseparateregressionsbasedontenyearsofdata using a rolling window from 1993 to 2019. Panel A uses OLS with the full set of controls, and panel B uses DML. Both panels consider the respective interaction terms between SUE and the variables listed on the vertical axis. Variables are listed according to Table 5. Colors illustrate levels of significance: 1% (blue), 5% (green),10%(yellow),non-significant(gray),andnotselectedbylasso(white).Weusetwo-foldcross-fitting and obtain estimates using two splits. Panel A: OLS - Full Set of Controls Panel B: DML NINCR NINCR INDMOM INDMOM p<0.01 BASPREAD BASPREAD MOM12M MOM12M MOM1M MOM1M p<0.05 IDIOVOL IDIOVOL CHTX CHTX MOM36M MOM36M p<0.1 AGR AGR STDDOLVOL STDDOLVOL MS MS CHMOM CHMOM p>=0.1 MVEIA MVEIA INVEST INVEST SP SP Not identified RSUP RSUP 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 30 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 30,
    "page_range": "p.30",
    "total_pages": 80,
    "chunk_index": 54,
    "word_count": 328,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.30)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 30 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 31,
    "page_range": "p.31",
    "total_pages": 80,
    "chunk_index": 55,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.31)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "IV.E. Stability of Inferences In this section, we examine the stability of our main results and test whether our main conclusion directly results from the specific model setup. First, we replace the post-lasso estimator with a random forest estimator when estimating the nuisance function to examine sensitivity to the choice of machine learning algorithm. Second, we investigate the impact of using various quantile ranks of variables, which is a method commonly used to facilitate interpretation of the effects.25 IV.E.1. A Nonlinear Nuisance Function Although we assume a PLM structure (see equation (1)), a linear relation between covariates is still imposed when estimating the nuisance function with the post-lasso method. This subsection addresses this drawback by allowing for a more flexible machine learning model by replacing the post-lasso method with the random forest method.26 We rely on the random forest method’s ability to implicitly account for nonlinearities and interaction effects between explanatory variables. By leveraging its capabilities, we are able to omit a priori construction of interaction terms from Z(3) (see Section IV.A), so Z(3) encompasses 135+73=208 explanatory i i,RF variables, i.e., 135 main variables and 73 stock-specific variables.27 We summarize the results in Table 6 and report estimates in Table 7. To facilitate comparison to the results for OLS specifications and DML using post-lasso, the first and second columns of Table 6 are identical to the second and fourth columns, respectively, of Table 2. As reported in Table 6, post-lasso and random forest identify the same number of significant interactions terms, i.e., one out of four. Therefore, these results support how 25We report results using different measures of SUE, measurement horizons, and risk-adjustments of abnormalreturns,andalsoconsiderchangingthemeasurementperiodofstock-specificvariables,inInternet Appendix D. 26The DML procedure provides valid inferences for a broad range of machine learning methods, such as random forest, boosted trees, and neural networks, as shown by Chernozhukov et al. (2018). 27WeestimaterandomforestusingitsplainvanillasettingsofBreiman(2001)wherethenumberoftrees is set to 400. 31 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 31,
    "page_range": "p.31",
    "total_pages": 80,
    "chunk_index": 56,
    "word_count": 318,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.31)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "SUE, measurement horizons, and risk-adjustments of abnormalreturns,andalsoconsiderchangingthemeasurementperiodofstock-specificvariables,inInternet Appendix D. 26The DML procedure provides valid inferences for a broad range of machine learning methods, such as random forest, boosted trees, and neural networks, as shown by Chernozhukov et al. (2018). 27WeestimaterandomforestusingitsplainvanillasettingsofBreiman(2001)wherethenumberoftrees is set to 400. 31 Electronic copy available at: https://ssrn.com/abstract=4017917 the conservatism of the DML procedure is invariant to the choice of machine learning method. Table 6: Summary of Inferences From Random Forest. Thefirsttworowsofthetablereportthenumbersofsignificantinteractionterms—whicharetheparameters ofprimaryinterest—acrossthefourmodelspecificationsata1%standardsignificancelevelandaBenjamini– Hochbergcorrectedlevel.Thebottomtworowsreportthetotalnumbersofsignificantinteractiontermsand variables of interest (non-interaction terms). DML DML OLS w. post-lasso w. random forest Selected Nuisance Nuisance Separate regressions using: controls function function Significant interaction terms (1%) Standard significance level 8/20 5/20 5/20 B-H. corrected 5/20 4/20 4/20 Significant variables (1%) Standard significance level 23/41 13/41 11/41 B-H. corrected 20/41 12/41 9/41 When investigating the coefficient estimates in Table 7, we find variations between random forest and post-lasso results. Although post-lasso and random forest agree about the significance of REPLAG, PASTRET, and SAMEFIS, random forest does not identify LOSS or NRANK as significant. Instead, RUNUP and ANALYST are identified as highly significant. Interestingly, these variables are not found to be significant by any of the OLS specifications. In line with post-lasso, random forest finds a large set of well-established variables to be non-significant, such as firm beta (BETA), SIZE, or BM. The inconsistency between the post-lasso and random forest methods is not surprising: post-lasso assumes that a sparse set of control variables linearly affects the variable of interest and the explanatory variable, whereas random forest allows these relationships to be highly complex and nonlinear. 32 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 32,
    "page_range": "p.32",
    "total_pages": 80,
    "chunk_index": 57,
    "word_count": 265,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.32)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "BM. The inconsistency between the post-lasso and random forest methods is not surprising: post-lasso assumes that a sparse set of control variables linearly affects the variable of interest and the explanatory variable, whereas random forest allows these relationships to be highly complex and nonlinear. 32 Electronic copy available at: https://ssrn.com/abstract=4017917 Table 7: Estimates of Interaction Terms Using Random Forest. Variables are listed based on the magnitude of the differences in coefficient estimates from the first and thirdcolumns.Underscoredvariablenamesdenotechangesinsignificance,andboldcoefficientvaluesdenote significanceatthe1%level.Thespecificationsuseallfirm-quartersinthesample,andeachcontrolvariableis continuousbutstandardizedexceptforSUE,whichisindeciles.Thefirstnumericalcolumnreportsestimates (inpercent)fromseparateregressionswiththesetofexantechosencontrolsandtheirinteractionswithSUE for the parameters of primary interest. The second column report the estimates using the high-dimensional nuisance function estimated using post-lasso, and the third column is estimated using random forest. The estimatesforthevariablesofinterestthemselves(non-interactionterms)arereportedinTableC4inInternet Appendix C. Standard errors are clustered by day and firm. DML DML OLS w. post-lasso w. random forest Selected Nuisance Nuisance Separate regressions using: controls function function SUE×REPLAG −3.264 −2.051 −1.627 SUE×EXPRISK 0.563 −0.383 0.278 SUE×ARBRISK −1.464 −0.886 −0.213 SUE×BETA −0.710 −1.183 −0.409 SUE×EARET 0.905 0.548 0.390 SUE×SIZE −1.792 −1.338 −0.697 SUE×LOSS −0.343 −1.170 −0.746 SUE×VOL 1.111 −0.817 −0.393 SUE×RUNUP 0.746 0.719 1.411 SUE×ANALYST 0.043 −0.873 −1.020 SUE×NRANK 0.766 1.317 0.624 SUE×DECR 0.173 −0.624 −0.303 SUE×PASTRET 3.225 2.973 2.758 SUE×LEV −0.018 −0.499 0.070 SUE×ILLIQ 0.178 −0.078 0.046 SUE×DOLVOL 0.893 −0.418 0.396 SUE×SAMEFIS 1.654 1.925 1.816 SUE×TURNOVER 0.369 0.009 −0.156 SUE×PRICE 1.226 0.969 0.826 SUE×BM −0.506 −0.751 −0.412 Observations 170,719 170,719 170,719 Fixed effects X X No. of variables 21 2,839 211 33 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 33,
    "page_range": "p.33-34",
    "total_pages": 80,
    "chunk_index": 58,
    "word_count": 238,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.33-34)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "2.973 2.758 SUE×LEV −0.018 −0.499 0.070 SUE×ILLIQ 0.178 −0.078 0.046 SUE×DOLVOL 0.893 −0.418 0.396 SUE×SAMEFIS 1.654 1.925 1.816 SUE×TURNOVER 0.369 0.009 −0.156 SUE×PRICE 1.226 0.969 0.826 SUE×BM −0.506 −0.751 −0.412 Observations 170,719 170,719 170,719 Fixed effects X X No. of variables 21 2,839 211 33 Electronic copy available at: https://ssrn.com/abstract=4017917 Although the two machine learning methods estimate the nuisance function differently, they agree about a more conservative number of significant variables compared to the more traditional OLS specifications. IV.E.2. Quantile Rank of Variables To facilitate interpretation of the magnitude of estimated PEAD effects, it is common to transform data into deciles (see e.g., Bhushan (1994), Mendenhall (2004), Garfinkel and Sokobin (2006), and Hirshleifer et al. (2009)). Therefore, Tables 8 and 9 investigate whether variables remain significant when relying on decile ranks instead of continuous values.Notethatsomeinformationwillbelostwhensuchatransformationisconducted, which may impact the conclusions. Following the literature, we form deciles using yearly decile breakpoints to allow for potential time trends. Table 8: Summary of Inferences Using Deciles. Thefirsttworowsofthetablereportthenumbersofsignificantinteractionterms—whicharetheparameters ofprimaryinterest—acrossthefourmodelspecificationsata1%standardsignificancelevelandaBenjamini– Hochbergcorrectedlevel.Thebottomtworowsreportthetotalnumbersofsignificantinteractiontermsand variables of interest (non-interaction terms). DML OLS OLS OLS w. post-lasso Selected Full set of Nuisance Separate regressions using: No controls controls controls function Significant interaction terms (1%) Standard significance level 13/20 6/20 5/20 5/20 B-H. corrected 13/20 5/20 5/20 4/20 Significant variables (1%) Standard significance level 30/41 23/41 23/41 16/41 B-H. corrected 30/41 22/41 22/41 15/41 34 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 34,
    "page_range": "p.34-35",
    "total_pages": 80,
    "chunk_index": 59,
    "word_count": 229,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.34-35)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "set of Nuisance Separate regressions using: No controls controls controls function Significant interaction terms (1%) Standard significance level 13/20 6/20 5/20 5/20 B-H. corrected 13/20 5/20 5/20 4/20 Significant variables (1%) Standard significance level 30/41 23/41 23/41 16/41 B-H. corrected 30/41 22/41 22/41 15/41 34 Electronic copy available at: https://ssrn.com/abstract=4017917 Table 9: Estimates Using Deciles. Interaction-term estimates for each decile-transformed control variable. Variables are listed based on the magnitudeofthedifferencesincoefficientestimatesfromthefirstandfourthcolumns.Underscoredvariable names denote changes in significance, and bold coefficient values denote significance at the 1% level. The specifications use all firm-quarters in the sample, and deciles are computed using yearly breakpoints. The first column reports estimates (in percent) from separate regressions with no controls for the parameters of primary interest. The second column adds the set of controls chosen ex ante and their interactions with SUE,andthethirdcolumnusesthefullsetofcontrols.Thefourthcolumnreportsestimatesusingthehigh- dimensionalnuisancefunction.Theestimatesforthevariablesofinterestthemselves(non-interactionterms) are reported in Table C5 in Internet Appendix C. Standard errors are clustered by day and firm. DML OLS OLS OLS w. post-lasso Selected Full set of Nuisance Separate regressions using: No controls controls controls function SUE×PASTRET 1.929 1.530 1.540 3.299 SUE×VOL −1.227 −1.584 −1.877 0.117 SUE×REPLAG −3.753 −3.403 −3.462 −2.417 SUE×LOSS 0.077 −0.557 −0.599 −1.092 SUE×EXPRISK −1.464 −0.111 0.016 −0.524 SUE×ILLIQ 0.890 1.285 0.556 −0.038 SUE×EARET 1.293 0.342 0.451 0.404 SUE×DECR 0.197 0.158 0.111 −0.619 SUE×BETA −1.696 −0.267 −0.465 −0.885 SUE×DOLVOL −1.048 0.033 0.499 −0.383 SUE×LEV 0.302 −0.213 0.075 −0.307 SUE×PRICE −0.300 −1.167 −1.976 0.273 SUE×ANALYST −1.114 −0.651 −0.641 −0.604 SUE×SIZE −0.302 −0.098 0.425 0.181 SUE×BM −0.471 −0.621 −0.773 −0.948 SUE×ARBRISK −1.382 −1.750 −0.803 −0.906 SUE×TURNOVER −1.138 −0.131 0.172 −0.743 SUE×SAMEFIS 1.504 1.805 1.199 1.890 SUE×NRANK 1.317 0.714 −1.207 1.246 SUE×RUNUP 0.786 0.376 0.608 0.841 Observations 170,719 170,719 170,719 170,719 Fixed effects X X No. of variables 3 21 138 2,839 35 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 35,
    "page_range": "p.35",
    "total_pages": 80,
    "chunk_index": 60,
    "word_count": 293,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.35)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "−0.621 −0.773 −0.948 SUE×ARBRISK −1.382 −1.750 −0.803 −0.906 SUE×TURNOVER −1.138 −0.131 0.172 −0.743 SUE×SAMEFIS 1.504 1.805 1.199 1.890 SUE×NRANK 1.317 0.714 −1.207 1.246 SUE×RUNUP 0.786 0.376 0.608 0.841 Observations 170,719 170,719 170,719 170,719 Fixed effects X X No. of variables 3 21 138 2,839 35 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 36,
    "page_range": "p.36",
    "total_pages": 80,
    "chunk_index": 61,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.36)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "Comparing the first three numerical columns of Table 8 to the main results in Table 2, we observe strong variation in the number of significant variables across all OLS specifications. Whereas the first column of Table 2 finds eight variables to be significant, Table 8 reports a notable 62% increase, with the first specification identifying 13 variables as significant. Inconsistent results are also reported for the second and third columns, where a decrease of at least 25% is detected between Table 2 and Table 8 for the two specifications (from eight to six and seven to five variables, respectively). We find similar results when transforming the data into quintile ranks and when restricting the data to the 10th and 1st deciles (see Table C6 and C7 in Internet Appendix C). In contrast, strong robustness is detected for the DML procedure, where a quarter of variables are identified as statistically significant, identical to the main results. The coefficient estimates in the fourth column of Table 9 show even greater robustness because estimates vary only slightly compared to the main results in Table 3. Overall, we find that across time and transformations, only PASTRET, REPLAG, and SAMEFIS have consistently been significant for DML when using both post- lasso and random forest. Hence, 17 variables do not survive the more conservative DML procedure and our broad set of robustness checks. Interestingly, well-established variables such as BETA, SIZE, and BM do not survive. V. Conclusion This paper combines a high-dimensional inference technique based on the machine- learning literature with traditional hypothesis-driven research to demonstrate how valid statistical inference can be conducted in a high-dimensional setting. As well as inferences in high dimensions, the DML procedure of Chernozhukov et al. (2018) can control for a large set of covariates and reduce researcher dependency. As a prominent example, we revisit an unresolved question in finance namely the origins of the PEAD. 36 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 36,
    "page_range": "p.36",
    "total_pages": 80,
    "chunk_index": 62,
    "word_count": 321,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.36)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "As well as inferences in high dimensions, the DML procedure of Chernozhukov et al. (2018) can control for a large set of covariates and reduce researcher dependency. As a prominent example, we revisit an unresolved question in finance namely the origins of the PEAD. 36 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 37,
    "page_range": "p.37",
    "total_pages": 80,
    "chunk_index": 63,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.37)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "The empirical literature striving to explain PEAD has uncovered what we term a “zoo of controls”. There is little academic consensus on model design, and researchers rely on datasets comprising thousands of earnings announcements, which has led to an environment in which researchers can detect complex effects with little practical use. After more than 60 years of research and over 216 published papers (Fink (2020)), taming the zoo has so far been neglected. Therefore, PEAD serves as a strong showcase of the need to move toward high-dimensional methods to reduce researcher dependency and strengthen the credibility of explanations. In the reported study, we conduct a comprehensive comparison between DML and three standard OLS specifications. To ensure comparability, each chosen OLS specificationhasbeenappliedbroadlyinthePEADliterature,i.e.,(i)anOLSregression with zero controls, (ii) a regression that allows for a small subset of control variables chosen ex ante, and (iii) a final regression that includes a multitude of controls. In contrast to the general PEAD literature and to ensure the robustness of our results, we conduct a comprehensive study of 20 different variables of interest, which we compare across models. Our concern becomes clear when investigating the inferences from the three OLS specifications. Of 20 variables, 17 were statistically significantly associated with either variation in PEAD or cumulative abnormal returns for the simplest model. To stress our concern further, we demonstrate how inferences are highly sensitive to the choice of controls by permuting the set in a linear regression. This shows that researchers can either implicitly or explicitly choose a set of controls to support their hypothesis. By leveraging the high-dimensional capabilities of the DML procedure, we extended the set of controls by adding 73 stock-specific variables from the cross-section of the stock returns literature (Green et al. (2017)), all first-order interaction terms, and fixed effects, yielding a total of 2,836 controls. With a 28% reduction in the number of variables explaining the drift, we demonstrate how the more conservative DML procedure can strengthen the credibility of a small set of factors. A direct comparison between DML and the OLS specifications illustrates that the coefficient estimates 37 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 37,
    "page_range": "p.37",
    "total_pages": 80,
    "chunk_index": 64,
    "word_count": 353,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.37)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "With a 28% reduction in the number of variables explaining the drift, we demonstrate how the more conservative DML procedure can strengthen the credibility of a small set of factors. A direct comparison between DML and the OLS specifications illustrates that the coefficient estimates 37 Electronic copy available at: https://ssrn.com/abstract=4017917 change considerably for several variables. Thus, we conjecture that an omitted-variable bias distorts the coefficient estimates from the standard OLS procedure. A vast set of robustness checks is conducted to strengthen our results, including analyzing inferences through time, using various quantile ranks of variables, and allowing for nonlinearities in the DML procedure. When exploring the additional 73 stock-specific variables using a two-step scheme, we find prominent roles for momentum, liquidity, and volatility, consistent with the findings of Gu et al. (2020). Therefore, these variables are crucial in explaining not only general equity risk premia but also abnormal returns around earnings announcements. To the best of our knowledge, this study is the first to leverage the capabilities of DML to strengthen the credibility of a small set of PEAD explanations. Our hope is that this paper highlights the dangers of hand picking a small set of controls and helps to establish a new standard for testing new explanations of PEAD. Furthermore, we envision this paper joining a new line of papers combining statistical and computational techniqueswithhypothesis-drivenresearchtoincreasethecredibilityofexistingfindings and theory. 38 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "IV. Results",
    "page_number": 38,
    "page_range": "p.38",
    "total_pages": 80,
    "chunk_index": 65,
    "word_count": 233,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "IV. Results (p.38)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "this paper highlights the dangers of hand picking a small set of controls and helps to establish a new standard for testing new explanations of PEAD. Furthermore, we envision this paper joining a new line of papers combining statistical and computational techniqueswithhypothesis-drivenresearchtoincreasethecredibilityofexistingfindings and theory. 38 Electronic copy available at: https://ssrn.com/abstract=4017917 Amihud, Y. (2002). Illiquidity and stock returns: Cross-section and time-series effects. Journal of Financial Markets 5(1), 31–56. Amihud, Y. and H. Mendelson (1989). The effects of beta, bid-ask spread, residual risk, and size on stock returns. Journal of Finance 44(2), 479–486. Athey, S., G. W. Imbens, and S. Wager (2018). Approximate residual balancing: Debiased inference of average treatment effects in high dimensions. Journal of the Royal Statistical Society. Series B (Statistical Methodology) 80(4), 597–623. Ball, R. and P. Brown (1968). An empirical evaluation of accounting income numbers. Journal of Accounting Research 6(2), 159–178. Bartov, E., S. Radhakrishnan, and I. Krinsky (2000). Investor sophistication and patterns in stock returns after earnings announcements. Accounting Review 75(1), 43–63. Belloni, A., D. Chen, V. Chernozhukov, and C. Hansen (2012). Sparse models and methods for optimal instruments with an application to eminent domain. Econometrica 80(6), 2369–2429. Belloni, A. and V. Chernozhukov (2013). Least squares after model selection in high-dimensional sparse models. Bernoulli 19(2), 521–547. Belloni, A., V. Chernozhukov, I. Fernández-Val, and C. Hansen (2017). Program evaluation and causal inference with high-dimensional data. Econometrica 85(1), 233–298. Belloni, A., V. Chernozhukov, and C. Hansen (2014a). High-dimensional methods and inferenceonstructuralandtreatmenteffects. Journal of Economic Perspectives 28(2), 29–50. 39 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "References",
    "page_number": 39,
    "page_range": "p.39",
    "total_pages": 80,
    "chunk_index": 66,
    "word_count": 254,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "References (p.39)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "sparse models. Bernoulli 19(2), 521–547. Belloni, A., V. Chernozhukov, I. Fernández-Val, and C. Hansen (2017). Program evaluation and causal inference with high-dimensional data. Econometrica 85(1), 233–298. Belloni, A., V. Chernozhukov, and C. Hansen (2014a). High-dimensional methods and inferenceonstructuralandtreatmenteffects. Journal of Economic Perspectives 28(2), 29–50. 39 Electronic copy available at: https://ssrn.com/abstract=4017917 Belloni, A., V. Chernozhukov, and C. Hansen (2014b). Inference on treatment effects after selection among high-dimensional controls. Review of Economic Studies 81(2), 608–650. Benjamini, Y. and Y. Hochberg (1995). Controlling the false discovery rate: A practical and powerful approach to multiple testing. Journal of the Royal Statistical Society. Series B (Methodological) 57(1), 289–300. Bernard, V. L. and J. K. Thomas (1989). Post-earnings-announcement drift: Delayed price response or risk premium? Journal of Accounting Research 27, 1–36. Bernard, V. L. and J. K. Thomas (1990). Evidence that stock prices do not fully reflect the implications of current earnings for future earnings. Journal of Accounting and Economics 13(4), 305–340. Bhushan, R. (1994). An informational efficiency perspective on the post-earnings announcement drift. Journal of Accounting and Economics 18(1), 45–65. Breiman, L. (2001). Random forests. Machine Learning 45(1), 5–32. Carhart, M. M. (1997). On persistence in mutual fund performance. Journal of Finance 52(1), 57–82. Chernozhukov, V., D. Chetverikov, M. Demirer, E. Duflo, C. Hansen, W. Newey, and J. Robins (2018). Double/debiased machine learning for treatment and structural parameters. Econometrics Journal 21(1), C1–C68. Chordia, T., A. Goyal, G. Sadka, R. Sadka, and L. Shivakumar (2009). Liquidity and the post-earnings-announcement drift. Financial Analysts Journal 65(4), 18–32. Chordia, T., A. Subrahmanyam, and V. R. Anshuman (2001). Trading activity and expected stock returns. Journal of Financial Economics 59(1), 3–32. 40 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "References",
    "page_number": 40,
    "page_range": "p.40",
    "total_pages": 80,
    "chunk_index": 67,
    "word_count": 276,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "References (p.40)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "C1–C68. Chordia, T., A. Goyal, G. Sadka, R. Sadka, and L. Shivakumar (2009). Liquidity and the post-earnings-announcement drift. Financial Analysts Journal 65(4), 18–32. Chordia, T., A. Subrahmanyam, and V. R. Anshuman (2001). Trading activity and expected stock returns. Journal of Financial Economics 59(1), 3–32. 40 Electronic copy available at: https://ssrn.com/abstract=4017917 Christensen, K., M. Siggaard, and B. Veliyev (2022). A machine learning approach to volatility forecasting. Journal of Financial Econometrics (Forthcoming). Cochrane, J. H. (2011). Presidential address: Discount rates. Journal of Finance 66(4), 1047–1108. Dehaan, E., J. Madsen, and J. D. Piotroski (2017). Do weather-induced moods affect the processing of earnings news? Journal of Accounting Research 55(3), 509–550. DellaVigna, S. and J. M. Pollet (2009). Investor inattention and friday earnings announcements. Journal of Finance 64(2), 709–749. Fama, E. F. (1998). Market efficiency, long-term returns, and behavioral finance. Journal of Financial Economics 49(3), 283–306. Feng, G., S. Giglio, and D. Xiu (2020). Taming the factor zoo: A test of new factors. Journal of Finance 75(3), 1327–1370. Fink, J. (2020). A review of the post-earnings-announcement drift. Journal of Behavioral and Experimental Finance 29, 100446. Foster, G., C. Olsen, and T. Shevlin (1984). Earnings releases, anomalies, and the behavior of security returns. Accounting Review 59(4), 574–603. Francis, J., R. Lafond, P. Olsson, and K. Schipper (2007). Information uncertainty and post-earnings announcement drift. Journal of Business Finance & Accounting 34(3- 4), 403–433. Freyberger, J., A. Neuhierl, and M. Weber (2020). Dissecting characteristics nonparametrically. Review of Economic Studies 33(5), 2326–2377. Garfinkel, J. A. and J. Sokobin (2006). Volume, opinion divergence, and returns: A study of post-earnings announcement drift. Journal of Accounting Research 44(1), 85–112. 41 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "References",
    "page_number": 41,
    "page_range": "p.41",
    "total_pages": 80,
    "chunk_index": 68,
    "word_count": 274,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "References (p.41)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "34(3- 4), 403–433. Freyberger, J., A. Neuhierl, and M. Weber (2020). Dissecting characteristics nonparametrically. Review of Economic Studies 33(5), 2326–2377. Garfinkel, J. A. and J. Sokobin (2006). Volume, opinion divergence, and returns: A study of post-earnings announcement drift. Journal of Accounting Research 44(1), 85–112. 41 Electronic copy available at: https://ssrn.com/abstract=4017917 Giglio, S. and D. Xiu (2021). Asset pricing with omitted factors. Journal of Political Economy 129(7). Gow, I. D., D. F. Larcker, and P. C. Reiss (2016). Causal inference in accounting research. Journal of Accounting Research 54(2), 477–523. Green, J., J. R. Hand, and X. F. Zhang (2017). The characteristics that provide independent information about average us monthly stock returns. Review of Economic Studies 30(12), 4389–4436. Gu, S., B. Kelly, and D. Xiu (2020). Empirical asset pricing via machine learning. Review of Economic Studies 33(5), 2223–2273. Harvey, C. R., Y. Liu, and H. Zhu (2016). ... and the cross-section of expected returns. Review of Economic Studies 29(1), 5–68. Hirshleifer, D., S. S. Lim, and S. H. Teoh (2009). Driven to distraction: Extraneous events and underreaction to earnings news. Journal of Finance 64(5), 2289–2325. Hoerl, A. E. and R. W. Kennard (1970). Ridge regression: Biased estimation for nonorthogonal problems. Technometrics 12(1), 55–67. Javanmard, A. and A. Montanari (2014). Confidence intervals and hypothesis testing for high-dimensional regression. Journal of Machine Learning Research 15(1), 2869–2909. Jegadeesh, N. and J. Livnat (2006). Post-earnings-announcement drift: The role of revenue surprises. Financial Analysts Journal 62(2), 22–34. Jiang, G., C. M. Lee, and Y. Zhang (2005). Information uncertainty and expected returns. Review of Accounting Studies 10(2-3), 185–221. Keuzenkamp, H. A. and J. R. Magnus (1995). On tests and significance in econometrics. Journal of Econometrics 67(1), 5–24. 42 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "References",
    "page_number": 42,
    "page_range": "p.42",
    "total_pages": 80,
    "chunk_index": 69,
    "word_count": 285,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "References (p.42)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "Financial Analysts Journal 62(2), 22–34. Jiang, G., C. M. Lee, and Y. Zhang (2005). Information uncertainty and expected returns. Review of Accounting Studies 10(2-3), 185–221. Keuzenkamp, H. A. and J. R. Magnus (1995). On tests and significance in econometrics. Journal of Econometrics 67(1), 5–24. 42 Electronic copy available at: https://ssrn.com/abstract=4017917 Kim, J. H. (2017). Stock returns and investors’ mood: Good day sunshine or spurious correlation? International Review of Financial Analysis 52, 94–103. Kim, J. H. and P. I. Ji (2015). Significance testing in empirical finance: A critical review and assessment. Journal of Empirical Finance 34, 1–14. Kormendi, R. and R. Lipe (1987). Earnings innovations, earnings persistence, and stock returns. Journal of Business 60(3), 323–345. Lee, J. D., D. L. Sun, Y. Sun, and J. E. Taylor (2016). Exact post-selection inference, with application to the lasso. Annals of Statistics 44(3), 907–927. Lei, J., M. G’Sell, A. Rinaldo, R. J. Tibshirani, and L. Wasserman (2018). Distribution- free predictive inference for regression. Journal of the American Statistical Association 113(523), 1094–1111. Lin, M., H. C. Lucas Jr., and G. Shmueli (2013). Research commentary - too big to fail: Large samples and the p-value problem. Information Systems Research 24(4), 906–917. Livnat, J. and R. R. Mendenhall (2006). Comparing the post-earnings announcement drift for surprises calculated from analyst and time series forecasts. Journal of Accounting Research 44(1), 177–205. MacKinlay, A. C. (1997). Event studies in economics and finance. Journal of Economic Literature 35(1), 13–39. McCloskey, D. N. and S. T. Ziliak (1996). The standard error of regressions. Journal of Economic Literature 34(1), 97–114. Mendenhall, R. R. (1991). Evidence on the possible underweighting of earnings-related information. Journal of Accounting Research 29(1), 170–179. 43 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "References",
    "page_number": 43,
    "page_range": "p.43",
    "total_pages": 80,
    "chunk_index": 70,
    "word_count": 281,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "References (p.43)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "finance. Journal of Economic Literature 35(1), 13–39. McCloskey, D. N. and S. T. Ziliak (1996). The standard error of regressions. Journal of Economic Literature 34(1), 97–114. Mendenhall, R. R. (1991). Evidence on the possible underweighting of earnings-related information. Journal of Accounting Research 29(1), 170–179. 43 Electronic copy available at: https://ssrn.com/abstract=4017917 Mendenhall, R. R. (2004). Arbitrage risk and post-earnings-announcement drift. Journal of Business 77(4), 875–894. Narayanamoorthy, G. (2006). Conservatism and cross-sectional variation in the post- earnings announcement drift. Journal of Accounting Research 44(4), 763–789. Nickl, R. and S. Van De Geer (2013). Confidence sets in sparse regression. Annals of Statistics 41(6), 2852–2876. Petersen, M. A. (2009). Estimating standard errors in finance panel data sets: Comparing approaches. Review of Economic Studies 22(1), 435–480. Roberts, M. R. and T. M. Whited (2013). Endogeneity in empirical corporate finance. In R. M. S. Edited by George M. Constantinides, Milton Harris (Ed.), Handbook of the Economics of Finance, Volume 2, pp. 493–572. Elsevier. Shivakumar, L. (2006). Accruals, cash flows and the post-earnings-announcement drift. Journal of Business Finance & Accounting 33(1-2), 1–25. Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society. Series B (Methodological) 58(1), 267–288. Van de Geer, S., P. Bühlmann, Y. Ritov, and R. Dezeure (2014). On asymptotically optimal confidence regions and tests for high-dimensional models. Annals of Statistics 42(3), 1166–1202. Whited, R. L., Q. T. Swanquist, J. E. Shipman, and J. R. Moon (2022). Out of control: The (over) use of controls in accounting research. Accounting Review 97(3), 395–413. Yang, J., H. Chuang, and C. Kuan (2020). Double machine learning with gradient boosting and its application to the big N audit quality effect. Journal of Econometrics 216(1), 268–283. 44 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "References",
    "page_number": 44,
    "page_range": "p.44",
    "total_pages": 80,
    "chunk_index": 71,
    "word_count": 287,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "References (p.44)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "Out of control: The (over) use of controls in accounting research. Accounting Review 97(3), 395–413. Yang, J., H. Chuang, and C. Kuan (2020). Double machine learning with gradient boosting and its application to the big N audit quality effect. Journal of Econometrics 216(1), 268–283. 44 Electronic copy available at: https://ssrn.com/abstract=4017917 Zhang, C. and S. S. Zhang (2014). Confidence intervals for low dimensional parameters in high dimensional linear models. Journal of the Royal Statistical Society. Series B (Statistical Methodology) 76(1), 217–242. Zou, H. (2006). The adaptive lasso and its oracle properties. Journal of the American Statistical Association 101(476), 1418–1429. 45 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "References",
    "page_number": 45,
    "page_range": "p.45",
    "total_pages": 80,
    "chunk_index": 72,
    "word_count": 104,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "References (p.45)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "S. Zhang (2014). Confidence intervals for low dimensional parameters in high dimensional linear models. Journal of the Royal Statistical Society. Series B (Statistical Methodology) 76(1), 217–242. Zou, H. (2006). The adaptive lasso and its oracle properties. Journal of the American Statistical Association 101(476), 1418–1429. 45 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Internet Appendix",
    "page_number": 46,
    "page_range": "p.46",
    "total_pages": 80,
    "chunk_index": 73,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Internet Appendix (p.46)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "A Methodology A.1. DML The section aims to explain in more detail the theory behind the DML procedure and how valid inference can be obtained by changing the moment condition. We assume the same partial linear model (PLM) as in equations (1) and (2). Firstly, as illustrated in the following naive example, by applying machine learning for approximating g (Z), 0 √ a convergence rate slower 1/ n can be caused, which results in a regularization bias. To illustrate this point, assume the sample size N is split up into two equal sized parts, the main part n = N/2 and an auxiliary part of size N −n, which is denoted by i ∈ Ic. Then estimating gˆ (Z) by machine learning in the auxiliary sample and using the 0 ˆ main sample to estimate θ by least squares, as: 0  −1  1 1 θ ˆ = X X2 X X (cid:0)Y −gˆ (Z )(cid:1) . 0  n i   n i i 0 i  i∈I i∈I The slower convergence rate can be seen by decomposing the scaled estimation error as follows:  −1  −1 √ 1 1 1 1 n(θ ˆ −θ) = X X2 √ X X ε + X X2 √ X X (cid:0)g (Z )−gˆ (Z )(cid:1). 0  n i  n i i  n i  n i 0 i 0 i i∈I i∈I i∈I i∈I | {z } | {z } :=a :=b Under relatively mild conditions, a is asymptotically normally distributed. Hence, if b converges to zero in probability, we have the desired properties. However, the challenge occurs since b, which is given by: b = (cid:18) E h X2 i(cid:19)−1 √ 1 X m (Z )(cid:0)g (Z )−gˆ (Z )(cid:1)+o (1), i n 0 i 0 i 0 i p i∈I 46 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Internet Appendix",
    "page_number": 46,
    "page_range": "p.46",
    "total_pages": 80,
    "chunk_index": 74,
    "word_count": 313,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Internet Appendix (p.46)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "probability, we have the desired properties. However, the challenge occurs since b, which is given by: b = (cid:18) E h X2 i(cid:19)−1 √ 1 X m (Z )(cid:0)g (Z )−gˆ (Z )(cid:1)+o (1), i n 0 i 0 i 0 i p i∈I 46 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Internet Appendix",
    "page_number": 47,
    "page_range": "p.47",
    "total_pages": 80,
    "chunk_index": 75,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Internet Appendix (p.47)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "is typically a sum of n terms that do not have mean zero and hence, by dividing with √ n,itwillnotconvergeinprobability.Toclarify,whendealingwithhigh-dimensionalor highly complex data sets, using regularization is key for informative learning. Balancing the trade-off between variance and bias using regularization is often assumed to be the main driver behind machine learning’s superior performance in complex data sets. However, by relying on regularization, a converge rate of n−ϕ with ϕ < 1/2 is often triggered. In this naive example, it would lead to a “regularization bias”, given by g (Z ) − gˆ (Z ), of order O (n−ϕg), and with ϕ < 1/2, which will cause the 0 i 0 i p g √ expectation for b to be of stochastic order nn−ϕg → ∞. With this “inferior” rate of convergence of θ , it is clear that an alternative structure has to be considered 0 compared to the naive approach. To overcome the “inferior” rate of convergence, Chernozhukov et al. (2018) propose an alternative procedure named DML for estimating θ . By reformulating the 0 loss function, the regularization bias can be accounted for, and a consistent estimate of θ can be obtained. The main idea is to partial out the effect of Z from both Y and 0 X. Proof and simulation results can be found in Chernozhukov et al. (2018), but the following part will highlight the main and most important points. Consider the new representation of the PLM given by equation (3) in Section II.A and defining V = X −m (Z ) = ν and W = Y −‘ (Z ), then an estimate of i i 0 i i i i 0 i θ can be found by: 0  −1  1 1 θ ˇ = X V ˆ2 X V ˆ W ˆ . 0  n i   n i i i∈I i∈I In contrast to the naive approach, this orthogonalization will be root-n consistent and approximately Gaussian under a very mild set of conditions. In line with the naive ˇ approach, it is possible to decompose the scaled estimation error of θ : 0 47 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Internet Appendix",
    "page_number": 47,
    "page_range": "p.47",
    "total_pages": 80,
    "chunk_index": 76,
    "word_count": 361,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Internet Appendix (p.47)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "i∈I i∈I In contrast to the naive approach, this orthogonalization will be root-n consistent and approximately Gaussian under a very mild set of conditions. In line with the naive ˇ approach, it is possible to decompose the scaled estimation error of θ : 0 47 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Internet Appendix",
    "page_number": 48,
    "page_range": "p.48",
    "total_pages": 80,
    "chunk_index": 77,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Internet Appendix (p.48)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": " −1  √ n (cid:16) θ ˇ −θ (cid:17) = 1 X V2 √ 1 Xh V ˆ W ˆ −V (W −ε ) i . 0 0  n i   n i i i i i  i∈I i∈I = a∗ +b∗ +c∗. In line with the arguments for the naive approach, the leading term given by a∗ will under mild conditions be asymptotically normally distributed. The regularization bias term b∗, given as: b∗ = (cid:18) E h X2 i(cid:19)−1 √ 1 X(cid:0)mˆ (Z )−m (Z )(cid:1)(cid:0)gˆ (Z )−g (Z )(cid:1), i n 0 i 0 i 0 i 0 i i∈I differs from the naive approach since it depends on the product of the estimator errors from both mˆ (Z ) and gˆ (Z ). Consistent with the arguments above, the convergence 0 i 0 i rates of mˆ and gˆ are respectively n−ϕm and n−ϕg, causing b∗ to have an upper bound 0 0 √ of nn−(ϕm+ϕg ) . Although ϕ and ϕ are found to be below 1/2, the product is m g ˇ typically found to be above, and hence, θ has good properties even under relatively 0 slow rates of convergence of m and g . The final term, c∗, includes terms as: 0 0  −1 1 1 X V2 √ X V (cid:0)gˆ (Z )−g (Z )(cid:1),  n i  n i 0 i 0 i i∈I i∈I where correlation can induce an overfitting bias. As suggested in Chernozhukov et al. (2018), the use of sample splitting can ensure that c∗ vanishes in probability. By estimating gˆ in the auxiliary sample, and ε and ν are the errors in the main sample, 0 i i the equation would vanish in probability by Chebyshev’s inequality. By applying the orthogonalized formulation and using data splitting, both the obstacle with regularization and overfitting bias can be accounted for, which results in √ (cid:16)ˇ (cid:17) n θ −θ being asymptotically normally distributed. However, by applying data 0 0 ˆ splitting, a loss of efficiency is caused by the substantial loss of data when estimating θ. As suggested in Chernozhukov et al. (2018), full efficiency can be gained by flipping the role of the main and auxiliary samples and obtaining two estimates of the parameter of interest. Since these two estimators are approximately independent, full efficiency is obtained when averaging. 48 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Internet Appendix",
    "page_number": 48,
    "page_range": "p.48",
    "total_pages": 80,
    "chunk_index": 78,
    "word_count": 403,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Internet Appendix (p.48)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "As suggested in Chernozhukov et al. (2018), full efficiency can be gained by flipping the role of the main and auxiliary samples and obtaining two estimates of the parameter of interest. Since these two estimators are approximately independent, full efficiency is obtained when averaging. 48 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Internet Appendix",
    "page_number": 49,
    "page_range": "p.49",
    "total_pages": 80,
    "chunk_index": 79,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Internet Appendix (p.49)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "A.2. Machine Learning Methods A.2.1 Lasso Relying on a linear regression model in settings with a low signal-to-noise ratio, then increasing the number of predictors will eventually make the model fit noise rather than relevant information, also known as overfitting. To alleviate overfitting and improve the fit, a penalty term can be added to the least squares loss function, L(β): ˜ (13) L(β;γ) = L(β)+φ(β;γ), where φ(β;γ) is the penalty term, β = (β ,β ,...,β )0 is a P + 1 vector, P is the 0 1 P number of covariates, and γ is a scalar or a vector of hyperparameters. OneofthemostwidelyusedpenaltymethodsislassobyTibshirani(1996).However, to ensure theoretical justification of the performance, we consider the lasso estimator with a data-driven penalty loading: λ (cid:13) (cid:13) (14) φ(β;γ) = (cid:13)Ψ ˆ β(cid:13) , n (cid:13) (cid:13) 1 where kβk = PP (cid:12) (cid:12)β (cid:12) (cid:12),Ψ ˆ = diag (cid:16) ψ ˆ ...,ψ ˆ (cid:17) is a diagonal matrix of penalty loadings, 1 p=1(cid:12) p(cid:12) 1 p and λ controls the amount of shrinkage. This penalty term will shrink irrelevant covariates to zero and thereby generate sparsity. When using lasso, a well-documented finite-sample bias will occur. Instead, Belloni and Chernozhukov (2013) suggest using post-lasso, which performs at least as well as lasso in terms of rate of convergence and has a smaller bias. As post-lasso has more desirable statistical properties, the main analysis of this paper will be based on post-lasso. Specifically, it is a two-step ˆ procedure, where in the first step, lasso is applied as a selection model, selecting T variables, hence: T ˆ = support (cid:16) β ˆ(cid:17) = (cid:26) p ∈ {1,...,P} : (cid:12) (cid:12)β ˆ (cid:12) (cid:12) > 0 (cid:27) . (cid:12) (cid:12) Hereafter, a second step where an unpenalized estimate based on least squares, using ˆ only variables selected to have nonzero coefficients, is re-fitted, hence β = 0 if β = 0. p p 49 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Internet Appendix",
    "page_number": 49,
    "page_range": "p.49",
    "total_pages": 80,
    "chunk_index": 80,
    "word_count": 323,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Internet Appendix (p.49)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "(cid:12) (cid:12)β ˆ (cid:12) (cid:12) > 0 (cid:27) . (cid:12) (cid:12) Hereafter, a second step where an unpenalized estimate based on least squares, using ˆ only variables selected to have nonzero coefficients, is re-fitted, hence β = 0 if β = 0. p p 49 Electronic copy available at: https://ssrn.com/abstract=4017917 The coefficient estimates heavily relies on the amount of penalization, and therefore the choice of the penalization parameter λ becomes critical. In this paper, we follow r Belloni et al. (2012) and set the penalty loading to ψ ˆ = E h z2 εˆ2 i , while allowing p n i,p i for potential heteroscedasticity in ε . The penalty level is given as: i √ λ = 2c nΦ−1(cid:0)1−γ/(2P)(cid:1), where c = 1.1 and γ = 0.1/log(n). The estimates of the residuals εˆ are initialized by i running least squares of Y on five regressions, which are found to be highly correlated i ˆ with Y . Hereafter, εˆ = Y −Z β is updated and the procedure is repeated 15 times. i i i i In contrast to cross-validation, the data-driven penalty loadings have theoretically justified performance. 50 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Internet Appendix",
    "page_number": 50,
    "page_range": "p.50-51",
    "total_pages": 80,
    "chunk_index": 81,
    "word_count": 195,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Internet Appendix (p.50-51)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "regressions, which are found to be highly correlated i ˆ with Y . Hereafter, εˆ = Y −Z β is updated and the procedure is repeated 15 times. i i i i In contrast to cross-validation, the data-driven penalty loadings have theoretically justified performance. 50 Electronic copy available at: https://ssrn.com/abstract=4017917 B Variable Description Variable Description Variable Name Description Data Source CAR[2,H] Cumulative abnormal return at time τ + 2 CRSP/Compustat to τ + H, where τ denotes the time of the announcement and H days after the announcement. The abnormal return is defined as the excess return of that predicted by a simple market model. The estimation window is from time τ − 231 to τ − 31 relative to the announcement with a minimum of 140 observations. SUE Surprise in earnings defined as the I/B/E/S I/B/E/S actual earnings per share minus the corresponding median earnings per share forecast, scaled by the corresponding I/B/E/S reportedpricepershare(LivnatandMendenhall (2006)). SUE_SD Surprise in earnings defined as the I/B/E/S I/B/E/S actual earnings per share minus the corresponding median earnings per share forecast, scaled by the standard deviation of the analyst forecasts (Jegadeesh and Livnat (2006)). SIZE Log of the market capitalization of the firm Datastream as measured in the month-end prior to the earnings announcement. Market capitalization is the dollar share price multiplied by the number of ordinary shares in issue (Bhushan (1994)). BM Book-to-market value measured as the book Datastream value of equity divided by the market value of equity measured in the previous quarter to the announcement. RUNUP Measures the cumulative abnormal return in the CRSP/Compustat monthpriortotheannouncement,namely,τ−30 to τ −1. PASTRET The cumulative returns from τ −230 to τ −30. CRSP/Compustat DOLVOL The dollar trading volume measured as the Datastream average monthly dollar trading volume in the previous calendar year in millions (Bhushan (1994)). VOL Thetotalnumberofshar5e1stradedinmontht−1. Datastream Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Internet Appendix",
    "page_number": 51,
    "page_range": "p.51",
    "total_pages": 80,
    "chunk_index": 82,
    "word_count": 309,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Internet Appendix (p.51)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "return in the CRSP/Compustat monthpriortotheannouncement,namely,τ−30 to τ −1. PASTRET The cumulative returns from τ −230 to τ −30. CRSP/Compustat DOLVOL The dollar trading volume measured as the Datastream average monthly dollar trading volume in the previous calendar year in millions (Bhushan (1994)). VOL Thetotalnumberofshar5e1stradedinmontht−1. Datastream Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Internet Appendix",
    "page_number": 52,
    "page_range": "p.52",
    "total_pages": 80,
    "chunk_index": 83,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Internet Appendix (p.52)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "Table B1: Variable Description. The table reports the variables of interest previously used in the empirical literature. Variable Name Description Data Source TURNOVER Share turnover defined as volume over the entire Datastream prior fiscal year, divided by shares outstanding at the end of that fiscal year. ANALYST Number of analysts who provide earnings I/B/E/S per share forecasts in the I/B/E/S database (Bhushan (1994)). PRICE Stock price in the end of the previous calendar I/B/E/S year ranked from 1 to 5 based on the share price range of Bhushan (1994). LEV Leverage, long-term debt plus current portion of CRSP/Compustat long-term debt to total assets measured at end of month t−1 used as a control in Shivakumar (2006). SAMEFIS An indicator if earnings announcement t is in I/B/E/S same fiscal year as announcement t−1 used as a control in Narayanamoorthy (2006). LOSS An indicator if negative earnings was announced I/B/E/S in previous quarter used as a control in Narayanamoorthy (2006). REPLAG Lag between the quarter-end and earnings I/B/E/S announcementdateusedinDehaanetal.(2017). NRANK The decile rank of the number of firms CRSP/Compustat announcing earning news on the same date (Hirshleifer et al. (2009)). DECR Anindicatorofoneifearningsdecreasedbetween I/B/E/S quarter t−2 to t−1 (Narayanamoorthy (2006)). EARET The two-day cumulative abnormal return CRSP/Compustat measured using a market model on the earnings announcement date, t−1 to t. (Garfinkel and Sokobin (2006)). ARBRISK Residual variance from a market model Datastream regression estimated over the last 200 trading days ending 30 days prior to the earnings announcement (Mendenhall (2004)). EXPRISK Explained variance from a market model Datastream regression estimated over the last 200 trading days ending 30 days prior to the earnings announcement (Mendenhall (2004)). 52 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Internet Appendix",
    "page_number": 52,
    "page_range": "p.52",
    "total_pages": 80,
    "chunk_index": 84,
    "word_count": 279,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Internet Appendix (p.52)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "regression estimated over the last 200 trading days ending 30 days prior to the earnings announcement (Mendenhall (2004)). EXPRISK Explained variance from a market model Datastream regression estimated over the last 200 trading days ending 30 days prior to the earnings announcement (Mendenhall (2004)). 52 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Internet Appendix",
    "page_number": 1,
    "page_range": "p.1",
    "total_pages": 80,
    "chunk_index": 85,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Internet Appendix (p.1)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "ILLIQ Amihud (2002) illiquidity measure computed CRSP/Compustat using daily data in the month of the announcement used in Sadka (2006). Data from Green et al. (2017). BETA Estimated market beta from weekly returns CRSP/Compustat and equal weighted market returns for 3 years ending one-month prior to the month of the announcements with at least 52 weeks of returns. Data from Green et al. (2017). 53 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Variable Name Description Data Source",
    "page_number": 53,
    "page_range": "p.53",
    "total_pages": 80,
    "chunk_index": 86,
    "word_count": 70,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Variable Name Description Data Source (p.53)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "Data from Green et al. (2017). BETA Estimated market beta from weekly returns CRSP/Compustat and equal weighted market returns for 3 years ending one-month prior to the month of the announcements with at least 52 weeks of returns. Data from Green et al. (2017). 53 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Additional Explanatory Variables",
    "page_number": 54,
    "page_range": "p.54",
    "total_pages": 80,
    "chunk_index": 87,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Additional Explanatory Variables (p.54)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "Table B1: Description of Stock-Specific Variables. The table reports the list of additional control variables that have been shown to explain the cross-section of stock returns. We refer the reader to the Appendix of Green et al. (2017) for construction of the individual variables. Acronym Characteristic Data Source Variables from Green et al. (2017) ABSACC Absolute accruals CRSP/Compustat ACC Working capital accruals CRSP/Compustat AEAVOL Abnormal earnings announcement volume CRSP/Compustat AGE # years since first Compustat coverage CRSP/Compustat AGR Asset growth CRSP/Compustat BASPREAD Bid-ask spread CRSP/Compustat BETASQ Beta squared CRSP/Compustat BM_IA Industry-adjusted book to market CRSP/Compustat CASH Cash holdings CRSP/Compustat CASHDEBT Cash flow to debt CRSP/Compustat CASHPR Cash productivity CRSP/Compustat CFP Cash flow to price ratio CRSP/Compustat CFP_IA Industry-adjusted cash flow to price ratio CRSP/Compustat CHATOIA Industry-adjusted change in asset turnover CRSP/Compustat CHCSHO Change in shares outstanding CRSP/Compustat CHEMPIA Industry-adjusted change in employees CRSP/Compustat CHINV Change in inventory CRSP/Compustat CHMOM Change in six-month momentum CRSP/Compustat CHPMIA Industry-adjusted change in profit margin CRSP/Compustat CHTX Change in tax expense CRSP/Compustat CINVEST Corporate investment CRSP/Compustat CONVIND Convertible debt indicator CRSP/Compustat CURRAT Current ratio CRSP/Compustat DEPR Depreciation/PP&E CRSP/Compustat DIVI Dividend initiation CRSP/Compustat DIVO Dividend omission CRSP/Compustat DY Dividend to price CRSP/Compustat EGR Growth in common shareholder equity CRSP/Compustat EP Earnings to price CRSP/Compustat GMA Gross profitability CRSP/Compustat GRCAPX Growth in capital expenditures CRSP/Compustat GRLTNOA Growth in long-term net operating assets CRSP/Compustat HERF Industry sales concentration CRSP/Compustat HIRE Employee growth rate CRSP/Compustat IDIOVOL Idiosyncratic return volatility CRSP/Compustat INDMOM Industry momentum CRSP/Compustat INVEST Capital expenditures and inventory CRSP/Compustat LGR Growth in long-term debt CRSP/Compustat 54 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Additional Explanatory Variables",
    "page_number": 54,
    "page_range": "p.54",
    "total_pages": 80,
    "chunk_index": 88,
    "word_count": 263,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Additional Explanatory Variables (p.54)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "Growth in capital expenditures CRSP/Compustat GRLTNOA Growth in long-term net operating assets CRSP/Compustat HERF Industry sales concentration CRSP/Compustat HIRE Employee growth rate CRSP/Compustat IDIOVOL Idiosyncratic return volatility CRSP/Compustat INDMOM Industry momentum CRSP/Compustat INVEST Capital expenditures and inventory CRSP/Compustat LGR Growth in long-term debt CRSP/Compustat 54 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Additional Explanatory Variables",
    "page_number": 1,
    "page_range": "p.1",
    "total_pages": 80,
    "chunk_index": 89,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Additional Explanatory Variables (p.1)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "MAXRET Maximum daily return CRSP/Compustat MOM12M 12-month momentum CRSP/Compustat MOM1M 1-month momentum CRSP/Compustat MOM36M 36-month momentum CRSP/Compustat MS Financial statement score CRSP/Compustat MVE_IA Industry-adjusted size CRSP/Compustat NINCR Number of earnings increases CRSP/Compustat OPERPROF Operating profitability CRSP/Compustat ORGCAP Organizational capital CRSP/Compustat PCHCAPX_IA Industry-adjusted % change in capital CRSP/Compustat expenditures PCHCURRAT % change in current ratio CRSP/Compustat PCHDEPR % change in depreciation CRSP/Compustat PCHGM_PCHSALE % change in gross margin - % change in CRSP/Compustat sales PCHQUICK % change in quick ratio CRSP/Compustat PCHSALE_PPCHINVT %changeinsales-%changeininventory CRSP/Compustat PCHSALE_PCHRECT % change in sales - % change in A/R CRSP/Compustat PCHSALE_PCHXSGA % change in sales - % change in SG&A CRSP/Compustat PCHSALEINV % change in sales-to-inventory CRSP/Compustat PCTACC Percent accruals CRSP/Compustat PRICEDELAY Price delay CRSP/Compustat PS Financial statement score CRSP/Compustat QUICK Quick ratio CRSP/Compustat RD R&D increase CRSP/Compustat RD_MVE R&D to market capitalization CRSP/Compustat RD_SALE R&D to sales CRSP/Compustat REALESTATE Real estate holdings CRSP/Compustat RETVOL Return volatility CRSP/Compustat ROAQ Return on assets CRSP/Compustat ROAVOL Earnings volatility CRSP/Compustat ROEQ Return on equity CRSP/Compustat ROIC Return on invested capital CRSP/Compustat RSUP Revenue surprise CRSP/Compustat SALECASH Sales to cash CRSP/Compustat SALEINV Sales to inventory CRSP/Compustat SALEREC Sales to receivables CRSP/Compustat SECURED Secured debt CRSP/Compustat SECUREDIND Secured debt indicator CRSP/Compustat SGR Sales growth CRSP/Compustat SIN Sin stocks CRSP/Compustat SP Sales to price CRSP/Compustat 55 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 55,
    "page_range": "p.55",
    "total_pages": 80,
    "chunk_index": 90,
    "word_count": 219,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.55)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "invested capital CRSP/Compustat RSUP Revenue surprise CRSP/Compustat SALECASH Sales to cash CRSP/Compustat SALEINV Sales to inventory CRSP/Compustat SALEREC Sales to receivables CRSP/Compustat SECURED Secured debt CRSP/Compustat SECUREDIND Secured debt indicator CRSP/Compustat SGR Sales growth CRSP/Compustat SIN Sin stocks CRSP/Compustat SP Sales to price CRSP/Compustat 55 Electronic copy available at: https://ssrn.com/abstract=4017917 STD_DOLVOL Volatility of liquidity (dollar trading volume) CRSP/Compustat STD_TURN Volatility of liquidity (share turnover) CRSP/Compustat STDACC Accrual volatility CRSP/Compustat STDCF Cash flow volatility CRSP/Compustat TANG Debt capacity/firm tangibility CRSP/Compustat TB Tax income to book income CRSP/Compustat ZEROTRADE Zero trading days CRSP/Compustat 56 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 56,
    "page_range": "p.56-57",
    "total_pages": 80,
    "chunk_index": 91,
    "word_count": 97,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.56-57)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "available at: https://ssrn.com/abstract=4017917 STD_DOLVOL Volatility of liquidity (dollar trading volume) CRSP/Compustat STD_TURN Volatility of liquidity (share turnover) CRSP/Compustat STDACC Accrual volatility CRSP/Compustat STDCF Cash flow volatility CRSP/Compustat TANG Debt capacity/firm tangibility CRSP/Compustat TB Tax income to book income CRSP/Compustat ZEROTRADE Zero trading days CRSP/Compustat 56 Electronic copy available at: https://ssrn.com/abstract=4017917 C Additional Analysis Table C1: Estimates Across Model Specifications - Non-Interaction Terms. Variables are listed based on the magnitude of the differences in coefficient estimates from the first and fourthcolumns.Underscoredvariablenamesdenotechangesinsignificance,andboldcoefficientvaluesdenote significanceatthe1%level.Thespecificationsuseallfirm-quartersinthesampleandeachcontrolvariableis continuousbutstandardized,exceptforSUE,whichisindeciles.Thefirstnumericalcolumnreportsestimates (in percent) from separate regressions with no controls for the parameters of secondary interest. The second column adds the set of controls chosen ex ante and their interactions with SUE, and the third column uses the full set of controls. The fourth column reports estimates using the high-dimensional nuisance function. Standard errors are clustered by day and firm. DML OLS OLS OLS w. post-lasso Selected Full set of Nuisance Separate regressions using: No controls controls controls function PASTRET −30.213 −28.785 −29.036 −12.797 BM 12.169 8.622 8.459 6.330 ARBRISK −3.231 −3.595 −6.056 −8.208 SUE −0.440 3.078 2.791 4.529 DECR 4.242 3.111 2.919 0.050 RUNUP −3.145 −2.736 −2.969 0.612 EARET 5.411 3.604 3.381 2.121 ILLIQ 3.350 1.733 1.535 0.608 SAMEFIS −2.739 −2.035 −0.629 −0.220 TURNOVER −0.834 0.367 0.043 1.559 LOSS 2.831 3.516 2.475 0.530 REPLAG 0.987 −0.220 −1.324 −0.866 VOL 0.073 2.815 1.817 1.851 PRICE −0.272 −0.593 −0.615 −1.041 ANALYST 0.633 6.997 6.826 1.383 NRANK −0.606 0.104 0.056 0.118 EXPRISK −0.564 1.042 1.552 −1.177 SIZE −6.169 −3.620 −10.144 −5.758 BETA −1.333 −0.564 −1.342 −0.996 LEV 0.909 1.804 1.759 1.104 DOLVOL −0.012 0.663 −0.138 0.058 Observations 170,719 170,719 170,719 170,719 Fixed effects X X No. of variables 3 21 138 2,839 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 57,
    "page_range": "p.57",
    "total_pages": 80,
    "chunk_index": 92,
    "word_count": 285,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.57)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "−0.606 0.104 0.056 0.118 EXPRISK −0.564 1.042 1.552 −1.177 SIZE −6.169 −3.620 −10.144 −5.758 BETA −1.333 −0.564 −1.342 −0.996 LEV 0.909 1.804 1.759 1.104 DOLVOL −0.012 0.663 −0.138 0.058 Observations 170,719 170,719 170,719 170,719 Fixed effects X X No. of variables 3 21 138 2,839 Electronic copy available at: https://ssrn.com/abstract=4017917 Figure C1: Visualization of Estimates - Interaction Terms. ThefigurevisualizestheresultsfortheprimaryinteractiontermestimatesfromTable3acrossthefourmodel specifications. The dots indicate the standardized coefficient estimate and the tails indicate 1% confidence intervalsoftheestimates.Thetailsarecoloredblackifthevariableissignificantata1%level.Variablesare listed on the y-axis according to Table 3. SUE REPLAG OLS (No controls) OLS (Selected controls) OLS (Full set of controls) SUE SIZE DML w. post-lasso SUE LOSS SUE VOL SUE DOLVOL SUE LEV SUE EXPRISK SUE DECR SUE EARET SUE ARBRISK SUE ANALYST SUE ILLIQ SUE SAMEFIS SUE BETA SUE PASTRET SUE BM SUE TURNOVER SUE PRICE SUE RUNUP SUE NRANK -6 -4 -2 0 2 4 6 58 Electronic copy available at: https://ssrn.com/abstract=4017917 Figure C2: Visualization of Estimates - Non-Interaction Terms. ThefigurevisualizestheresultsforthevariablesofinterestthemselvesfromTableC1acrossthefourmodel specifications. The dots indicate the standardized coefficient estimate and the tails indicate 1% confidence intervals of the estimates. The tails are colored black if the variable is significant at a 1% level. To ensure proper visualization of the results, we limit the x-axis to cover the interval between -0.16 to 0.16. The PASTRETresultsfromtheOLSspecificationsareoutsidethisinterval,andarethereforeexcluded.Variables are listed on the y-axis according to Table C1. PASTRET BM ARBRISK SUE DECR RUNUP EARET ILLIQ SAMEFIS TURNOVER LOSS REPLAG VOL PRICE ANALYST NRANK EXPRISK SIZE BETA OLS (No controls) LEV OLS (Selected controls) OLS (Full set of controls) DOLVOL DML w. post-lasso -15 -10 -5 0 5 10 15 59 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 58,
    "page_range": "p.58-59",
    "total_pages": 80,
    "chunk_index": 93,
    "word_count": 268,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.58-59)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "Table C1. PASTRET BM ARBRISK SUE DECR RUNUP EARET ILLIQ SAMEFIS TURNOVER LOSS REPLAG VOL PRICE ANALYST NRANK EXPRISK SIZE BETA OLS (No controls) LEV OLS (Selected controls) OLS (Full set of controls) DOLVOL DML w. post-lasso -15 -10 -5 0 5 10 15 59 Electronic copy available at: https://ssrn.com/abstract=4017917 Figure C3: Inferences Through Time - All Variables. Thisfigurereportsp-valuesforstock-specificcovariatesfromseparateregressionsbasedontenyearsofdata. We use a rolling window from 1993 to 2019. Panel A uses OLS with the full set of controls and panel B uses DML. Both panels consider both the interaction term and the variable itself on the y-axis, where the most significant of the two is reported. Variables are listed according to Table C1. Colors illustrate levels of significance, 1% (blue), 5% (green), 10% (yellow), and non-significant (white). Panel A: OLS - Full Set of Controls Panel B: DML PASTRET PASTRET BM BM ARBRISK ARBRISK p<0.01 SUE SUE DECR DECR RUNUP RUNUP EARET EARET ILLIQ ILLIQ p<0.05 SAMEFIS SAMEFIS TURNOVER TURNOVER LOSS LOSS REPLAG REPLAG VOL VOL PRICE PRICE p<0.1 ANALYST ANALYST NRANK NRANK EXPRISK EXPRISK SIZE SIZE BETA BETA p>=0.1 LEV LEV DOLVOL DOLVOL 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 60 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 60,
    "page_range": "p.60-61",
    "total_pages": 80,
    "chunk_index": 94,
    "word_count": 244,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.60-61)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 60 Electronic copy available at: https://ssrn.com/abstract=4017917 .selbairaV fo teS lluF eht gnisU ossaL-tsoP rof setamitsE :2C elbaT etoned seman elbairav derocsrednU .snmuloc htruof dna tsrfi eht morf setamitse tneicffieoc ni secnereffid eht fo edutingam eht no desab detsil era selbairaV lortnoc hcae dna elpmas eht ni sretrauq-mrfi lla esu snoitacfiiceps ehT .level %1 eht ta ecnacfiingis etoned seulav tneicffieoc dlob dna ,ecnacfiingis ni segnahc htiwsnoissergeretarapesmorf)tnecrepni(setamitsestropersnmulocowttsrfiehT.selicednisihcihw,EUSroftpecxe,dezidradnatstubsuounitnocsielbairav snoitcaretniriehtdnaetnaxenesohcslortnocfotesehtddasnmulochtruofdnadrihtehT.ylevitcepser,flestielbairavehtdnasmretnoitcaretnirofslortnocon noitcnuf ecnasiun lanoisnemid-hgih eht gnisu setamitse stroper snmuloc owt tsal ehT .slortnoc fo tes lluf eht sesu snmuloc htxis dna htffi eht dna ,EUS htiw .mrfi dna yad yb deretsulc era srorre dradnatS .slortnoc fo tes lluf eht ylno gnisu LMD SLO SLO SLO ossal-tsop .w ecnasiuN fo tes lluF detceleS slortnoc oN :gnisu snoisserger etarapeS noitcnuf slortnoc slortnoc elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI flesti mret flesti mret flesti mret flesti mret 951.2 197.2 870.3 044.0− EUS 903.1 194.0 255.1 246.0 240.1 365.0 465.0− 132.1− KSIRPXE 121.1− 322.2− 423.1− 396.3− 022.0− 462.3− 789.0 885.3− GALPER 628.5− 271.0− 650.6− 914.1− 595.3− 464.1− 132.3− 435.1− KSIRBRA 104.01− 548.0− 441.01− 969.2− 026.3− 297.1− 961.6− 831.0 EZIS 702.1− 916.0− 243.1− 338.0− 465.0− 017.0− 333.1− 084.1− ATEB 637.1 381.0− 957.1 761.0 408.1 810.0− 909.0 534.0 VEL 194.3 277.0 183.3 168.0 406.3 509.0 114.5 333.1 TERAE 298.2 452.0− 919.2 060.0 111.3 371.0 242.4 791.0 RCED 215.1 410.0 535.1 480.0 337.1 871.0 053.3 993.0 QILLI 221.0− 853.0 831.0− 156.0 366.0 398.0 210.0− 237.0 LOVLOD 974.2 672.0− 574.2 072.0− 615.3 343.0− 138.2 770.0 SSOL 590.92− 239.2 630.92− 183.3 587.82− 522.3 312.03− 242.3 TERTSAP 586.0− 367.1 926.0− 711.1 530.2− 456.1 937.2− 405.1 SIFEMAS 368.1 261.0 718.1 261.1 518.2 111.1 370.0 504.0 LOV 467.6 661.0− 628.6 182.0− 799.6 340.0 336.0 713.0− TSYLANA 841.0 672.0 340.0 641.0 763.0 963.0 438.0− 341.0 REVONRUT 252.0 244.1 650.0 086.1− 401.0 667.0 606.0− 713.1 KNARN 407.8 755.0− 954.8 546.0− 226.8 605.0− 961.21 806.0− MB 788.2− 896.0 969.2− 417.0 637.2− 647.0 541.3− 656.0 PUNUR 727.0− 501.1 516.0− 991.1 395.0− 622.1 272.0− 680.1 ECIRP 917,071 917,071 917,071 917,071 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 61 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 61,
    "page_range": "p.61",
    "total_pages": 80,
    "chunk_index": 95,
    "word_count": 392,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.61)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "KNARN 407.8 755.0− 954.8 546.0− 226.8 605.0− 961.21 806.0− MB 788.2− 896.0 969.2− 417.0 637.2− 647.0 541.3− 656.0 PUNUR 727.0− 501.1 516.0− 991.1 395.0− 622.1 272.0− 680.1 ECIRP 917,071 917,071 917,071 917,071 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 61 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 62,
    "page_range": "p.62",
    "total_pages": 80,
    "chunk_index": 96,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.62)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "Figure C4: Inferences Through Time - OLS Specification 1 and 2. Thisfigurereportsp-valuesforstock-specificcovariatesfromseparateregressionsbasedontenyearsofdata. We use a rolling window from 1993 to 2019. Panels A and B consider the interaction term between the variable listed on the y-axes and SUE. Panels C and D consider both the estimate on the variable itself or its interaction with SUE, the most significant of the two is reported. Panels A and C uses OLS with no controlsandpanelsBandDusesOLSwithselectedcontrolvariables.Variablesinthetoppanelsaresorted according to Table 3 and bottom panels to Table C1. Colors illustrate levels of significance, 1% (blue), 5% (green), 10% (yellow), and non-significant (white). Interaction Terms Only: Panel A: OLS - No Controls Panel B: OLS - Selected Controls REPLAG REPLAG SIZE SIZE LOSS LOSS p<0.01 VOL VOL DOLVOL DOLVOL LEV LEV EXPRISK EXPRISK DECR DECR p<0.05 EARET EARET ARBRISK ARBRISK ANALYST ANALYST ILLIQ ILLIQ SAMEFIS SAMEFIS p<0.1 BETA BETA PASTRET PASTRET BM BM TURNOVER TURNOVER PRICE PRICE p>=0.1 RUNUP RUNUP NRANK NRANK 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 Variable and Interaction Terms: Panel C: OLS - No Controls Panel D: OLS - Selected Controls PASTRET PASTRET BM BM ARBRISK ARBRISK p<0.01 SUE SUE DECR DECR RUNUP RUNUP EARET EARET ILLIQ ILLIQ p<0.05 SAMEFIS SAMEFIS TURNOVER TURNOVER LOSS LOSS REPLAG REPLAG VOL VOL PRICE PRICE p<0.1 ANALYST ANALYST NRANK NRANK EXPRISK EXPRISK SIZE SIZE BETA BETA p>=0.1 LEV LEV DOLVOL DOLVOL 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 62 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 62,
    "page_range": "p.62",
    "total_pages": 80,
    "chunk_index": 97,
    "word_count": 331,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.62)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 62 Electronic copy available at: https://ssrn.com/abstract=4017917 Figure C5: Selection by Lasso. This figure reports when a variable of interest or a stock-specific variable is chosen by lasso. The model is estimated using a rolling-window containing ten years of data and with the end year of the window given by the x-axis. The y-axis considers both the estimate on the variable itself or its interaction with SUE. The area is shaded gray when lasso selects a variable. SUE PASTRET EARET SIZE VOL BM ANALYST LEV TURNOVER REPLAG SAMEFIS EXPRISK ARBRISK BETA AGR BASPREAD CHMOM CHTX IDIOVOL INDMOM INVEST MOM12M MOM1M MOM36M MS MVEIA NINCR RSUP SP STDDOLVOL 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 63 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 63,
    "page_range": "p.63-64",
    "total_pages": 80,
    "chunk_index": 98,
    "word_count": 183,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.63-64)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "BETA AGR BASPREAD CHMOM CHTX IDIOVOL INDMOM INVEST MOM12M MOM1M MOM36M MS MVEIA NINCR RSUP SP STDDOLVOL 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 63 Electronic copy available at: https://ssrn.com/abstract=4017917 Table C3: Controls That Matter - Non-Interaction Terms. Variables are listed based on the magnitude of the differences in coefficient estimates from the first and fourthcolumns.Underscoredvariablenamesdenotechangesinsignificance,andboldcoefficientvaluesdenote significanceatthe1%level.Thespecificationsuseallfirm-quartersinthesampleandeachcontrolvariableis continuousbutstandardized,exceptforSUE,whichisindeciles.Thefirstnumericalcolumnreportsestimates (in percent) from separate regressions with no controls for the parameters of secondary interest. The second column adds the set of controls chosen ex ante and their interactions with SUE, and the third column uses the full set of controls. The fourth column reports estimates using the high-dimensional nuisance function. Standard errors are clustered by day and firm. DML OLS OLS OLS w. post-lasso Selected Full set of Nuisance Separate regressions using: No controls controls controls function INDMOM −12.124 −4.916 −6.609 3.079 MOM12M −37.662 −29.570 −30.396 −30.411 NINCR −5.644 −4.526 −3.614 −0.249 CHTX −5.557 −4.643 −4.164 −0.986 BASPREAD 4.997 6.038 6.678 8.592 STD_DOLVOL 2.380 −1.849 −1.845 −0.575 IDIOVOL −5.199 −6.819 −11.934 −2.954 MOM36M 1.010 0.456 1.771 −0.722 AGR 0.053 −1.077 −0.867 −1.013 MOM1M −5.934 −2.263 −2.227 −5.280 MS 1.703 3.439 4.218 1.598 Observations 170,719 170,719 170,719 170,719 Fixed effects X X No. of variables 3 21 138 2,839 64 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 64,
    "page_range": "p.64-65",
    "total_pages": 80,
    "chunk_index": 99,
    "word_count": 232,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.64-65)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "−1.849 −1.845 −0.575 IDIOVOL −5.199 −6.819 −11.934 −2.954 MOM36M 1.010 0.456 1.771 −0.722 AGR 0.053 −1.077 −0.867 −1.013 MOM1M −5.934 −2.263 −2.227 −5.280 MS 1.703 3.439 4.218 1.598 Observations 170,719 170,719 170,719 170,719 Fixed effects X X No. of variables 3 21 138 2,839 64 Electronic copy available at: https://ssrn.com/abstract=4017917 Figure C6: Controls That Matter Through Time - All Variables. Thisfigurereportsp-valuesforstock-specificcovariatesfromseparateregressionsbasedontenyearsofdata. Weusearollingwindowfrom1993to2019.PanelAusesOLSwiththefullsetofcontrolsandpanelBuses DML.BothpanelsconsidertheinteractiontermbetweenSUEandthevariableitselflistedonthey-axis,the most significant of the two is reported. Variables are listed according to Table 5. Colors illustrate levels of significance: 1% (blue), 5% (green), 10% (yellow), non-significant (gray), and not selected by lasso (white). We use two-fold cross-fitting and obtain estimates using two splits. Panel A: OLS - Full Set of Controls Panel B: DML INDMOM INDMOM MOM12M MOM12M p<0.01 NINCR NINCR CHTX CHTX BASPREAD BASPREAD p<0.05 STDDOLVOL STDDOLVOL IDIOVOL IDIOVOL MOM36M MOM36M p<0.1 AGR AGR MOM1M MOM1M MS MS CHMOM CHMOM p>=0.1 INVEST INVEST MVEIA MVEIA RSUP RSUP Not identified SP SP 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 65 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 65,
    "page_range": "p.65-66",
    "total_pages": 80,
    "chunk_index": 100,
    "word_count": 215,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.65-66)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 65 Electronic copy available at: https://ssrn.com/abstract=4017917 Figure C7: Controls That Matter Through Time - OLS Specification 1 and 2. Thisfigurereportsp-valuesforstock-specificcovariatesfromseparateregressionsbasedontenyearsofdata. We use a rolling window from 1993 to 2019. Panels A and B consider the interaction term between the variable listed on the y-axes and SUE. Panels C and D consider both the estimate on the variable itself or its interaction with SUE, the most significant of the two is reported. Panels A and C uses OLS with no controls,whilepanelsBandDusesOLSwithselectedcontrolvariables.Variablesinthetoppanelsaresorted according to Table 5 and bottom panels to Table C3. Colors illustrate levels of significance: 1% (blue), 5% (green),10%(yellow),non-significant(gray),andnotselectedbylasso(white).Weusetwo-foldcross-fitting and obtain estimates using two splits. Interaction Terms Only: Panel A: OLS - No Controls Panel B: OLS - Selected Controls NINCR NINCR INDMOM INDMOM p<0.01 BASPREAD BASPREAD MOM12M MOM12M MOM1M MOM1M p<0.05 IDIOVOL IDIOVOL CHTX CHTX MOM36M MOM36M p<0.1 AGR AGR STDDOLVOL STDDOLVOL MS MS CHMOM CHMOM p>=0.1 MVEIA MVEIA INVEST INVEST SP SP Not identified RSUP RSUP 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 Variable and Interaction Terms: Panel C: OLS - No Controls Panel D: OLS - Selected Controls INDMOM INDMOM MOM12M MOM12M p<0.01 NINCR NINCR CHTX CHTX BASPREAD BASPREAD p<0.05 STDDOLVOL STDDOLVOL IDIOVOL IDIOVOL MOM36M MOM36M p<0.1 AGR AGR MOM1M MOM1M MS MS CHMOM CHMOM p>=0.1 INVEST INVEST MVEIA MVEIA RSUP RSUP Not identified SP SP 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 66 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 66,
    "page_range": "p.66",
    "total_pages": 80,
    "chunk_index": 101,
    "word_count": 370,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.66)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 66 Electronic copy available at: https://ssrn.com/abstract=4017917 Table C4: Estimates Using Random Forest - Non-Interaction Terms. Variables are listed based on the magnitude of the differences in coefficient estimates from the first and thirdcolumns.Underscoredvariablenamesdenotechangesinsignificance,andboldcoefficientvaluesdenote significance at the 1% level. The specifications use all firm-quarters in the sample and each control variable is continuous but standardized, except for SUE, which is in deciles. The first column reports estimates (in percent) from separate regressions with the set of controls chosen ex ante for the parameters of secondary interest.Thesecondcolumnreportsestimatesusingthehigh-dimensionalnuisancefunctionestimatedusing post-lasso and the third column using random forest. Standard errors are clustered by day and firm. DML DML OLS w. post-lasso w. random forest Selected Nuisance Nuisance Separate regressions using: controls function function PASTRET −28.785 −12.797 −8.534 ARBRISK −3.595 −8.208 −13.509 SIZE −3.620 −5.758 −14.759 EARET 3.604 2.121 1.255 DECR 3.111 0.050 0.121 BM 8.622 6.330 8.318 SUE 3.078 4.529 3.282 ILLIQ 1.733 0.608 0.771 LOSS 3.516 0.530 0.289 RUNUP −2.736 0.612 −0.720 VOL 2.815 1.851 2.249 NRANK 0.104 0.118 1.539 SAMEFIS −2.035 −0.220 −0.918 REPLAG −0.220 −0.866 −0.646 TURNOVER 0.367 1.559 0.702 ANALYST 6.997 1.383 1.965 DOLVOL 0.663 0.058 1.177 BETA −0.564 −0.996 −2.025 EXPRISK 1.042 −1.177 −1.164 PRICE −0.593 −1.041 0.151 LEV 1.804 1.104 0.989 Observations 170,719 170,719 170,719 Fixed effects X X No. of variables 21 2,839 211 67 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 67,
    "page_range": "p.67",
    "total_pages": 80,
    "chunk_index": 102,
    "word_count": 266,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.67)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "−0.866 −0.646 TURNOVER 0.367 1.559 0.702 ANALYST 6.997 1.383 1.965 DOLVOL 0.663 0.058 1.177 BETA −0.564 −0.996 −2.025 EXPRISK 1.042 −1.177 −1.164 PRICE −0.593 −1.041 0.151 LEV 1.804 1.104 0.989 Observations 170,719 170,719 170,719 Fixed effects X X No. of variables 21 2,839 211 67 Electronic copy available at: https://ssrn.com/abstract=4017917 Table C5: Estimates Using Deciles - Non-Interaction Terms. Non-interaction term estimates for each variable measured as deciles, computed using yearly quantile breakpoints. Variables are listed based on the magnitude of the differences in coefficient estimates from thefirstandfourthcolumns.Underscoredvariablenamesdenotechangesinsignificance,andboldcoefficient values denote significance at the 1% level. The specifications use all firm-quarters in the sample. The first numericalcolumnreportsestimates(inpercent)fromseparateregressionswithnocontrolsfortheparameters ofsecondaryinterest.Thesecondcolumnaddsthesetofcontrolschosenexanteandtheirinteractionswith SUE, and the third column uses the full set of controls. The fourth column reports estimates using the high-dimensional nuisance function. Standard errors are clustered by day and firm. DML OLS OLS OLS w. post-lasso Selected Full set of Nuisance Separate regressions using: No controls controls controls function PASTRET −28.263 −21.591 −20.908 −9.004 DOLVOL 1.014 38.785 40.980 12.786 VOL −2.509 0.372 2.313 3.605 BM 17.773 11.523 12.939 11.870 ARBRISK −1.674 −13.562 −14.525 −6.462 SUE −0.440 3.575 3.349 4.086 DECR 4.242 2.121 2.189 −0.143 EARET 4.790 2.164 2.170 1.295 RUNUP −2.804 −0.976 −1.048 0.685 EXPRISK −1.965 1.283 3.013 0.555 SAMEFIS −2.739 −1.724 3.457 −0.283 REPLAG 1.113 −0.537 −1.280 −0.831 LOSS 2.831 1.890 0.746 0.968 ILLIQ 7.844 25.130 26.370 9.160 SIZE −7.352 −16.355 −18.052 −6.048 PRICE −4.428 −4.846 −6.997 −5.626 NRANK −0.606 0.309 0.084 0.345 LEV 1.023 0.340 0.387 1.723 ANALYST 0.297 2.864 3.040 0.067 BETA −1.075 −2.478 −2.438 −0.846 TURNOVER −0.104 −4.001 −5.007 −0.064 Observations 170,719 170,719 170,719 170,719 Fixed effects X X No. of variables 3 21 138 2,839 68 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 68,
    "page_range": "p.68",
    "total_pages": 80,
    "chunk_index": 103,
    "word_count": 281,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.68)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "−4.846 −6.997 −5.626 NRANK −0.606 0.309 0.084 0.345 LEV 1.023 0.340 0.387 1.723 ANALYST 0.297 2.864 3.040 0.067 BETA −1.075 −2.478 −2.438 −0.846 TURNOVER −0.104 −4.001 −5.007 −0.064 Observations 170,719 170,719 170,719 170,719 Fixed effects X X No. of variables 3 21 138 2,839 68 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 69,
    "page_range": "p.69",
    "total_pages": 80,
    "chunk_index": 104,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.69)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": ".selitniuQ gnisU setamitsE :6C elbaT secnereffid eht fo edutingam eht no desab detsil era selbairaV .stniopkaerb elitnauq ylraey gnisu detupmoc ,selitniuq sa derusaem elbairav hcae rof setamitsE etoned seulav tneicffieoc dlob dna ,ecnacfiingis ni segnahc etoned seman elbairav derocsrednU .snmuloc htneves dna tsrfi eht morf setamitse tneicffieoc ni snoissergeretarapesmorf)tnecrepni(setamitsestropersnmulocowttsrfiehT.elpmasehtnisretrauq-mrfillaesusnoitacfiicepsehT.level%1ehttaecnacfiingis rieht dna etna xe nesohc slortnoc fo tes eht dda snmuloc htruof dna driht ehT .ylevitcepser ,flesti elbairav eht dna smret noitcaretni rof slortnoc on htiw ecnasiunlanoisnemid-hgihehtgnisusetamitsestropersnmulocowttsalehT.slortnocfotesllufehtsesusnmulochtxisdnahtffiehtdna,EUShtiwsnoitcaretni .mrfi dna yad yb deretsulc era srorre dradnatS .slortnoc fo tes lluf eht ylno gnisu noitcnuf LMD SLO SLO SLO ossal-tsop .w ecnasiuN fo tes lluF detceleS slortnoc oN :gnisu snoisserger etarapeS noitcnuf slortnoc slortnoc elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI flesti mret flesti mret flesti mret flesti mret 400.4 028.2 952.3 393.0− EUS 495.0− 881.2− 800.1− 181.3− 914.0− 211.3− 281.1 074.3− GALPER 604.2 451.0 005.0 592.1− 234.0 732.1− 445.2− 090.1− LOV 119.0 040.1− 282.1 344.0− 111.2 324.0− 828.2 800.0 SSOL 340.8− 139.2 978.12− 425.1 952.22− 964.1 812.72− 129.1 TERTSAP 140.0 125.0− 759.1 041.0− 916.0 622.0− 188.1− 694.1− KSIRPXE 955.4 970.0− 750.81 228.0 995.71 832.1 137.7 797.0 QILLI 783.1− 118.0− 704.2− 332.0− 442.2− 701.0− 211.1− 536.1− ATEB 853.1 634.0 583.2 455.0 753.2 764.0 126.4 932.1 TERAE 151.0− 836.0− 853.2 180.0 043.2 741.0 242.4 531.0 RCED 959.4− 468.0− 048.01− 789.0− 223.01− 096.1− 605.1− 635.1− KSIRBRA 832.1 744.0− 762.0 190.0− 251.0 643.0− 780.1 671.0 VEL 171.7 153.0− 308.62 713.0 504.72 441.0− 169.0 729.0− LOVLOD 799.0 846.0− 513.2− 131.0− 567.1− 353.0− 230.0− 802.1− REVONRUT 181.0 784.0− 099.3 166.0− 076.3 316.0− 392.0 389.0− TSYLANA 692.11 289.0− 615.31 276.0− 700.21 385.0− 574.71 894.0− MB 070.3− 262.0 126.01− 086.0 387.01− 802.0 462.7− 812.0− EZIS 523.0− 058.1 101.2 211.1 169.1− 286.1 247.2− 244.1 SIFEMAS 117.5− 061.0 223.6− 417.1− 656.4− 590.1− 624.4− 402.0− ECIRP 842.0 521.1 461.0− 141.1− 940.0 446.0 017.0− 251.1 KNARN 068.0 796.0 583.1− 394.0 552.1− 972.0 775.2− 986.0 PUNUR 917,071 917,071 917,071 917,071 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 69 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 69,
    "page_range": "p.69",
    "total_pages": 80,
    "chunk_index": 105,
    "word_count": 334,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.69)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "SIFEMAS 117.5− 061.0 223.6− 417.1− 656.4− 590.1− 624.4− 402.0− ECIRP 842.0 521.1 461.0− 141.1− 940.0 446.0 017.0− 251.1 KNARN 068.0 796.0 583.1− 394.0 552.1− 972.0 775.2− 986.0 PUNUR 917,071 917,071 917,071 917,071 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 69 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 70,
    "page_range": "p.70",
    "total_pages": 80,
    "chunk_index": 106,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.70)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": ".eliceD EUS ht01 dna ts1 eht gnisU setamitsE :7C elbaT ehtfoedutingamehtnodesabdetsileraselbairaV.dezidradnatstubsuounitnocsielbairavlortnochcaednaelicedmottobropotehtniEUSgnisusetamitsE seulav tneicffieoc dlob dna ,ecnacfiingis ni segnahc etoned seman elbairav derocsrednU .snmuloc htneves dna tsrfi eht morf setamitse tneicffieoc ni secnereffid etarapes morf )tnecrep ni( setamitse stroper snmuloc owt tsrfi ehT .elpmas eht ni sretrauq-mrfi lla esu snoitacfiiceps ehT .level %1 eht ta ecnacfiingis etoned dnaetnaxenesohcslortnocfotesehtddasnmulochtruofdnadrihtehT.ylevitcepser,flestielbairavehtdnasmretnoitcaretnirofslortnoconhtiwsnoisserger lanoisnemid-hgih eht gnisu setamitse stroper snmuloc owt tsal ehT .slortnoc fo tes lluf eht sesu snmuloc htxis dna htffi eht dna ,EUS htiw snoitcaretni rieht .mrfi dna yad yb deretsulc era srorre dradnatS .slortnoc fo tes lluf eht ylno gnisu noitcnuf ecnasiun LMD SLO SLO SLO ossal-tsop .w ecnasiuN fo tes lluF detceleS slortnoc oN :gnisu snoisserger etarapeS noitcnuf slortnoc slortnoc elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI flesti mret flesti mret flesti mret flesti mret 327.6 899.4 616.5 346.0 EUS 748.0− 227.1 132.3 462.1 836.6 579.0 241.5 666.1− KSIRPXE 037.4− 489.4 053.3− 572.3 160.1− 458.1 973.2− 655.2 LOVLOD 654.0 886.2− 278.0 797.4− 283.0− 505.4− 256.0 367.4− GALPER 523.8− 192.0− 480.6− 840.2− 037.2− 781.2− 904.1 991.2− KSIRBRA 247.0 200.0− 624.1 098.0− 407.0 779.0− 483.1 424.1− ATEB 155.0 170.1− 844.1 841.1− 904.2 889.0− 147.2 571.0 SSOL 765.5− 086.0− 326.11− 508.1− 220.7− 433.1− 016.9− 605.0 EZIS 467.0 550.0 474.2− 081.0− 545.1− 890.0 964.1− 418.0− PUNUR 348.1 534.0− 830.7 838.1− 036.7 725.1− 101.2 482.1− TSYLANA 992.1 381.1 235.0 084.0 139.0 658.0 201.0− 163.0 REVONRUT 093.0 563.0− 925.0 090.0− 907.0 560.0− 119.2 514.0 QILLI 748.31− 777.2 821.82− 161.3 550.82− 662.3 966.92− 424.3 TERTSAP 902.0 471.0 065.2 635.0 730.3 655.0 181.4 957.0 RCED 558.0 892.0 695.1 462.0 506.1 702.0 377.0− 878.0 VEL 607.0 060.1 676.0 614.1 214.2 203.1 094.0− 255.0 LOV 004.0 520.2 869.0− 493.1 426.2− 143.2 630.3− 673.2 SIFEMAS 950.6 815.1− 268.6 941.1− 170.7 160.1− 838.9 122.1− MB 879.1 355.1 137.1 691.2− 664.0 661.1 520.0− 418.1 KNARN 248.2 622.0 484.3 065.0 929.3 833.0 857.5 843.0 TERAE 701.1− 268.2 356.0− 341.3 536.0− 522.3 532.0− 389.2 ECIRP 358,92 358,92 358,92 358,92 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 70 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 70,
    "page_range": "p.70",
    "total_pages": 80,
    "chunk_index": 107,
    "word_count": 341,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.70)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "MB 879.1 355.1 137.1 691.2− 664.0 661.1 520.0− 418.1 KNARN 248.2 622.0 484.3 065.0 929.3 833.0 857.5 843.0 TERAE 701.1− 268.2 356.0− 341.3 536.0− 522.3 532.0− 389.2 ECIRP 358,92 358,92 358,92 358,92 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 70 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 71,
    "page_range": "p.71",
    "total_pages": 80,
    "chunk_index": 108,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.71)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": ".roirP htnoM-enO derusaeM selbairaV cfiicepS-kcotS gnisU setamitsE :8C elbaT ot roirp htnom-eno derusaem )7102( .la te neerG fo selbairav cfiiceps-kcots eht gnisu snoitacfiiceps ledom ruof eht ssorca stluser niam eht stroper elbat ehT .snmuloc htneves dna tsrfi eht morf setamitse tneicffieoc ni secnereffid eht fo edutingam eht no desab detsil era selbairaV .etad tnemecnuonna sgninrae eht -mrfi lla esu snoitacfiiceps ehT .level %1 eht ta ecnacfiingis etoned seulav tneicffieoc dlob dna ,ecnacfiingis ni segnahc etoned seman elbairav derocsrednU elbairav eht dna smret noitcaretni rof slortnoc on htiw snoisserger etarapes morf )tnecrep ni( setamitse stroper snmuloc owt tsrfi ehT .elpmas eht ni sretrauq sesusnmulochtxisdnahtffiehtdna,EUShtiwsnoitcaretniriehtdnaetnaxenesohcslortnocfotesehtddasnmulochtruofdnadrihtehT.ylevitcepser,flesti srorredradnatS.slortnocfotesllufehtylnognisunoitcnufecnasiunlanoisnemid-hgihehtgnisusetamitsestropersnmulocowttsalehT.slortnocfotesllufeht .mrfi dna yad yb deretsulc era LMD SLO SLO SLO ossal-tsop .w ecnasiuN fo tes lluF detceleS slortnoc oN :gnisu snoisserger etarapeS noitcnuf slortnoc slortnoc elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI flesti mret flesti mret flesti mret flesti mret 716.4 547.2 770.3 714.0− EUS 313.1− 620.2− 244.1− 276.3− 572.0− 352.3− 339.0 285.3− GALPER 834.6− 473.1− 011.01− 840.3− 426.3− 968.1− 881.6− 970.0 EZIS 884.0 940.1− 415.2 132.0− 065.3 082.0− 558.2 531.0 SSOL 509.1 858.0− 618.1 601.1 708.2 050.1 760.0 913.0 LOV 550.0 424.0− 341.0− 866.0 166.0 109.0 010.0− 017.0 LOVLOD 744.0− 833.0− 066.1 575.0 641.1 684.0 804.0− 923.1− KSIRPXE 359.0 214.0− 957.1 781.0 797.1 410.0 798.0 554.0 VEL 270.0 125.0− 259.2 941.0 951.3 162.0 672.4 082.0 RCED 125.8− 258.0− 129.5− 064.1− 765.3− 484.1− 541.3− 075.1− KSIRBRA 114.2 785.0 854.3 608.0 076.3 648.0 384.5 062.1 TERAE 742.1 059.0− 687.6 952.0− 569.6 370.0 906.0 963.0− TSYLANA 226.0 030.0− 845.1 141.0 657.1 922.0 383.3 954.0 QILLI 982.11− 898.2 860.92− 804.3 118.82− 152.3 732.03− 172.3 TERTSAP 187.1− 202.1− 584.1− 687.0− 746.0− 446.0− 353.1− 544.1− ATEB 590.0− 867.1 595.0− 021.1 999.1− 566.1 617.2− 135.1 SIFEMAS 515.1 940.0− 620.0 971.0 933.0 393.0 258.0− 451.0 REVONRUT 373.6 587.0− 094.8 356.0− 546.8 725.0− 391.21 226.0− MB 832.1− 297.0 467.0− 760.1 647.0− 680.1 724.0− 149.0 ECIRP 869.2− 108.0 058.2− 967.0 936.2− 697.0 420.3− 217.0 PUNUR 801.0 313.1 680.0 956.1− 551.0 287.0 265.0− 933.1 KNARN 917,071 917,071 917,071 917,071 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 71 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 71,
    "page_range": "p.71",
    "total_pages": 80,
    "chunk_index": 109,
    "word_count": 352,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.71)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "MB 832.1− 297.0 467.0− 760.1 647.0− 680.1 724.0− 149.0 ECIRP 869.2− 108.0 058.2− 967.0 936.2− 697.0 420.3− 217.0 PUNUR 801.0 313.1 680.0 956.1− 551.0 287.0 265.0− 933.1 KNARN 917,071 917,071 917,071 917,071 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 71 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 72,
    "page_range": "p.72",
    "total_pages": 80,
    "chunk_index": 110,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.72)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "D Alternative Measures Alternative Surprise in Earnings Measures To assess the impact of using the earnings surprise measure based on time series forecasts, we define a time series measure of SUE where quarterly earnings follow a seasonal random walk with a drift process (Jegadeesh and Livnat (2006)). The parameters of the model are estimated over rolling windows between quarters t−21 through t−1 using historical data. Thus, each quarter the following model is estimated: (15) X = δ +X +ε , i,t i,t i,t−4 i,t where X is the actual I/B/E/S reported earnings per share, while δ and ε are i,t i,t i,t drift and random noise terms, respectively. The standardized time series SUE measure is defined as in Livnat and Mendenhall (2006): ˆ X −δ −X i,t i,t i,t−4 (16) SUE_TS = , i,t PRICE i,t where PRICE is the I/B/E/S reported share price. The main advantage of the time i,t series measure is no requirement of analysts to follow a stock or provide guidance. Yet, other problems remain as discussed in Livnat and Mendenhall (2006) and Jegadeesh and Livnat (2006), which is why we rely on the analyst measure in our analysis. The results using the time series measure is reported in Table D1. We consider changing the deflator in our main specification with the standard deviation of analyst forecasts as used by Jegadeesh and Livnat (2006): ˆ EPS −EPS i,t i,t (17) SUE_SD = . i,t ˆ STD(EPS) i,t We report the results in Table D2. 72 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 72,
    "page_range": "p.72",
    "total_pages": 80,
    "chunk_index": 111,
    "word_count": 254,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.72)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "D1. We consider changing the deflator in our main specification with the standard deviation of analyst forecasts as used by Jegadeesh and Livnat (2006): ˆ EPS −EPS i,t i,t (17) SUE_SD = . i,t ˆ STD(EPS) i,t We report the results in Table D2. 72 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Acronym Characteristic Data Source",
    "page_number": 1,
    "page_range": "p.1",
    "total_pages": 80,
    "chunk_index": 112,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Acronym Characteristic Data Source (p.1)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "gnisU setamitsE :1D elbaT secnereffid eht fo edutingam eht no desab detsil era selbairaV .dezidradnats tub suounitnoc si elbairav lortnoc hcae dna ,seliced ni ST_EUS gnisu setamitsE etoned seulav tneicffieoc dlob dna ,ecnacfiingis ni segnahc etoned seman elbairav derocsrednU .snmuloc htneves dna tsrfi eht morf setamitse tneicffieoc ni snoissergeretarapesmorf)tnecrepni(setamitsestropersnmulocowttsrfiehT.elpmasehtnisretrauq-mrfillaesusnoitacfiicepsehT.level%1ehttaecnacfiingis rieht dna etna xe nesohc slortnoc fo tes eht dda snmuloc htruof dna driht ehT .ylevitcepser ,flesti elbairav eht dna smret noitcaretni rof slortnoc on htiw lanoisnemid-hgih eht gnisu setamitse stroper snmuloc owt tsal ehT .slortnoc fo tes lluf eht sesu snmuloc htxis dna htffi eht dna ,ST_EUS htiw snoitcaretni .mrfi dna yad yb deretsulc era srorre dradnatS .slortnoc fo tes lluf eht ylno gnisu noitcnuf ecnasiun LMD SLO SLO SLO ossal-tsop .w ecnasiuN fo tes lluF detceleS slortnoc oN :gnisu snoisserger etarapeS noitcnuf slortnoc slortnoc elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI flesti mret flesti mret flesti mret flesti mret 065.0 836.5− 376.5− 320.21− EUS 296.1− 832.0− 004.2 512.3− 088.2 750.3− 102.2 582.4− KSIRBRA 342.3− 766.0− 811.2− 194.0− 321.2− 163.0− 574.0− 530.4− KSIRPXE 555.2− 860.0 362.2− 967.0− 008.1− 060.0 243.0− 041.2− ATEB 415.0− 891.1− 127.0− 616.2− 111.0− 842.2− 363.1 794.2− GALPER 862.0− 004.0− 972.0− 752.1− 864.0− 694.0 460.1− 728.0 KNARN 735.0 715.0 656.2 991.2 755.2 481.2 362.4 985.1 SSOL 403.2 580.1 579.3 915.1 942.4 905.1 250.6 110.2 TERAE 924.2 012.0 198.2 239.0 615.2 700.1 899.4 670.1 QILLI 508.1 700.0− 364.2 167.0 552.2 710.1 074.0− 348.0− LOV 852.0− 439.1 546.2− 062.2 943.2− 931.2 089.1− 911.1 PUNUR 998.2 701.0− 779.2 363.0 561.2 593.0 503.1 655.0 VEL 369.21− 356.2 175.72− 316.2 196.72− 394.2 322.92− 880.3 TERTSAP 344.1 562.0 925.0 922.0 383.0 033.0 913.0− 321.0− REVONRUT 932.0 751.0− 122.2 931.0− 741.2 206.0 462.2 881.0 RCED 483.0 170.0− 600.0 520.0 697.0 672.0 511.0− 733.0− LOVLOD 835.1 718.0− 154.5 197.0− 108.4 192.0 494.1− 470.1− TSYLANA 979.6 815.1− 387.8 141.1− 456.8 413.1− 969.21 373.1− MB 572.6− 800.0− 680.01− 509.1− 375.2− 195.2− 472.8− 911.0 EZIS 060.3− 351.1 862.3− 210.1 319.3− 513.1 295.4− 830.1 SIFEMAS 081.0− 920.0 513.0− 500.0 732.0− 480.0 111.0 021.0 ECIRP 612,47 612,47 612,47 612,47 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 73 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": ".ST_EUS",
    "page_number": 73,
    "page_range": "p.73",
    "total_pages": 80,
    "chunk_index": 113,
    "word_count": 358,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": ".ST_EUS (p.73)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "MB 572.6− 800.0− 680.01− 509.1− 375.2− 195.2− 472.8− 911.0 EZIS 060.3− 351.1 862.3− 210.1 319.3− 513.1 295.4− 830.1 SIFEMAS 081.0− 920.0 513.0− 500.0 732.0− 480.0 111.0 021.0 ECIRP 612,47 612,47 612,47 612,47 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 73 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": ".ST_EUS",
    "page_number": 1,
    "page_range": "p.1",
    "total_pages": 80,
    "chunk_index": 114,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": ".ST_EUS (p.1)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "gnisU setamitsE :2D elbaT secnereffid eht fo edutingam eht no desab detsil era selbairaV .dezidradnats tub suounitnoc si elbairav lortnoc hcae dna ,seliced ni DS_EUS gnisu setamitsE etoned seulav tneicffieoc dlob dna ,ecnacfiingis ni segnahc etoned seman elbairav derocsrednU .snmuloc htneves dna tsrfi eht morf setamitse tneicffieoc ni snoissergeretarapesmorf)tnecrepni(setamitsestropersnmulocowttsrfiehT.elpmasehtnisretrauq-mrfillaesusnoitacfiicepsehT.level%1ehttaecnacfiingis rieht dna etna xe nesohc slortnoc fo tes eht dda snmuloc htruof dna driht ehT .ylevitcepser ,flesti elbairav eht dna smret noitcaretni rof slortnoc on htiw lanoisnemid-hgih eht gnisu setamitse stroper snmuloc owt tsal ehT .slortnoc fo tes lluf eht sesu snmuloc htxis dna htffi eht dna ,DS_EUS htiw snoitcaretni .mrfi dna yad yb deretsulc era srorre dradnatS .slortnoc fo tes lluf eht ylno gnisu noitcnuf ecnasiun LMD SLO SLO SLO ossal-tsop .w ecnasiuN fo tes lluF detceleS slortnoc oN :gnisu snoisserger etarapeS noitcnuf slortnoc slortnoc elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI flesti mret flesti mret flesti mret flesti mret 468.0 785.0 491.1 701.3− EUS 423.1− 202.1− 604.1− 603.2− 590.0− 377.1− 254.1 996.3− GALPER 464.0− 500.0 778.0− 385.1− 475.0− 664.0 614.1− 489.1 KNARN 192.5− 737.0 960.11− 333.2− 266.2− 240.0− 449.6− 216.2 EZIS 554.3− 640.0 029.2− 260.0 481.2− 631.0 719.0− 427.1− ATEB 978.4− 552.0− 699.0− 260.2− 220.0 548.1− 232.0 709.1− KSIRBRA 511.2− 777.0− 831.1 757.0 204.0 444.0 526.0 082.2− KSIRPXE 173.1 086.0 887.6 081.1 431.6 486.0 316.0 107.0− TSYLANA 228.1 741.1− 003.2 710.0− 573.2 590.0 434.1 410.0 VEL 952.0 711.0 243.3 121.0− 392.3 261.0− 840.4 716.0− RCED 064.2 710.0 914.3 629.0− 146.3 218.0− 799.4 127.0 TERAE 990.0− 139.1 342.0− 272.1 022.3− 576.1 842.4− 052.2 SIFEMAS 560.6 628.0 198.7 784.0 871.8 756.0 569.11 431.1 MB 264.1 533.0 663.2 802.0 676.2 545.0 393.0 730.0 LOV 984.1 282.0 093.0 292.0 172.0 402.0 203.0− 630.0 REVONRUT 286.0 123.0− 253.2 890.0 160.3 510.0 759.2 135.0− SSOL 800.1 454.0 449.2− 129.0 256.2− 473.0 158.2− 682.0 PUNUR 827.0− 982.0− 473.0− 501.0− 973.0− 730.0 211.0− 231.0− ECIRP 084.1 351.0 215.2 613.0 424.2 623.0 890.4 101.0 QILLI 340.0− 402.0 422.0− 141.0− 008.0 730.0− 570.0 951.0 LOVLOD 351.31− 027.2 649.82− 121.2 326.82− 730.2 168.92− 807.2 TERTSAP 522,38 522,38 522,38 522,38 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 74 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": ".DS_EUS",
    "page_number": 74,
    "page_range": "p.74",
    "total_pages": 80,
    "chunk_index": 115,
    "word_count": 358,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": ".DS_EUS (p.74)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "ECIRP 084.1 351.0 215.2 613.0 424.2 623.0 890.4 101.0 QILLI 340.0− 402.0 422.0− 141.0− 008.0 730.0− 570.0 951.0 LOVLOD 351.31− 027.2 649.82− 121.2 326.82− 730.2 168.92− 807.2 TERTSAP 522,38 522,38 522,38 522,38 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 74 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": ".DS_EUS",
    "page_number": 1,
    "page_range": "p.1",
    "total_pages": 80,
    "chunk_index": 116,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": ".DS_EUS (p.1)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "We consider two other measurement horizons of the cumulative abnormal return from time t+2 to t+41, CAR[2,41], and from time t+2 to t+21, CAR[2,21], in Tables D3 and D4, respectively. Additionally, we report results using CAR[2,61] risk-adjusted with the Fama-French 3-factor model and the 3-factor model extended with momentum (Carhart (1997)) rather than the market model. These results are reported in Tables D5 and D6, respectively. 75 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Alternative Cumulative Abnormal Return Measures",
    "page_number": 75,
    "page_range": "p.75-76",
    "total_pages": 80,
    "chunk_index": 117,
    "word_count": 72,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Alternative Cumulative Abnormal Return Measures (p.75-76)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "t+21, CAR[2,21], in Tables D3 and D4, respectively. Additionally, we report results using CAR[2,61] risk-adjusted with the Fama-French 3-factor model and the 3-factor model extended with momentum (Carhart (1997)) rather than the market model. These results are reported in Tables D5 and D6, respectively. 75 Electronic copy available at: https://ssrn.com/abstract=4017917 .elbairaV tnednepeD sa ]14,2[RAC gnisU setamitsE :3D elbaT etoned seman elbairav derocsrednU .snmuloc htneves dna tsrfi eht morf setamitse tneicffieoc ni secnereffid eht fo edutingam eht no desab detsil era selbairaV owt tsrfi ehT .elpmas eht ni sretrauq-mrfi lla esu snoitacfiiceps ehT .level %1 eht ta ecnacfiingis etoned seulav tneicffieoc dlob dna ,ecnacfiingis ni segnahc dna driht ehT .ylevitcepser ,flesti elbairav eht dna smret noitcaretni rof slortnoc on htiw snoisserger etarapes morf )tnecrep ni( setamitse stroper snmuloc tsal ehT .slortnoc fo tes lluf eht sesu snmuloc htxis dna htffi eht dna ,EUS htiw snoitcaretni rieht dna etna xe nesohc slortnoc fo tes eht dda snmuloc htruof .mrfidnayadybderetsulcerasrorredradnatS.slortnocfotesllufehtylnognisunoitcnufecnasiunlanoisnemid-hgihehtgnisusetamitsestropersnmulocowt LMD SLO SLO SLO ossal-tsop .w ecnasiuN fo tes lluF detceleS slortnoc oN :gnisu snoisserger etarapeS noitcnuf slortnoc slortnoc elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI flesti mret flesti mret flesti mret flesti mret 484.4 107.2 320.3 650.0− EUS 176.5− 982.1− 066.9− 404.2− 644.3− 778.1− 143.5− 550.0 EZIS 494.1− 883.1− 839.1− 294.2− 781.0− 683.2− 658.0 576.2− GALPER 923.1 898.0− 025.1 078.0 172.2 247.0 881.0− 041.0 LOV 490.0 957.0− 489.1 090.0 892.3 910.0 754.2 672.0 SSOL 701.0 554.0− 531.0− 006.0 365.0 966.0 950.0− 105.0 LOVLOD 673.0 364.0− 253.1 831.0 066.1 940.0 788.0 463.0 VEL 967.1 984.0 678.2 587.0 610.3 368.0 685.4 522.1 TERAE 321.0 952.0− 975.2 332.0 418.2 004.0 708.3 624.0 RCED 820.7− 937.0− 109.5− 318.1− 770.4− 768.1− 056.3− 614.1− KSIRBRA 023.0 396.0 536.0 828.0− 235.0 618.0 770.0− 982.1 KNARN 877.1− 851.0− 132.1 873.1 779.0 042.1 730.1− 927.0− KSIRPXE 280.2− 862.1− 522.1− 660.1− 973.0− 529.0− 023.1− 575.1− ATEB 826.0 840.0 998.0 990.0 901.1 891.0 254.2 943.0 QILLI 791.1 904.0− 650.6 947.0− 360.6 054.0− 084.0 506.0− TSYLANA 026.5 324.0− 654.7 033.0− 864.7 981.0− 575.01 942.0− MB 563.11− 167.2 653.52− 002.3 152.52− 650.3 455.62− 139.2 TERTSAP 589.0− 070.1 050.1− 476.0 513.1− 351.1 719.1− 489.0 SIFEMAS 168.0− 644.0 574.0− 356.0 764.0− 176.0 612.0− 325.0 ECIRP 392.0 886.0 637.2− 847.0 726.2− 937.0 550.3− 526.0 PUNUR 533.1 940.0 400.0 432.0 811.0 413.0 579.0− 701.0 REVONRUT 917,071 917,071 917,071 917,071 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 76 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Alternative Cumulative Abnormal Return Measures",
    "page_number": 76,
    "page_range": "p.76",
    "total_pages": 80,
    "chunk_index": 118,
    "word_count": 399,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Alternative Cumulative Abnormal Return Measures (p.76)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "SIFEMAS 168.0− 644.0 574.0− 356.0 764.0− 176.0 612.0− 325.0 ECIRP 392.0 886.0 637.2− 847.0 726.2− 937.0 550.3− 526.0 PUNUR 533.1 940.0 400.0 432.0 811.0 413.0 579.0− 701.0 REVONRUT 917,071 917,071 917,071 917,071 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 76 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Alternative Cumulative Abnormal Return Measures",
    "page_number": 77,
    "page_range": "p.77",
    "total_pages": 80,
    "chunk_index": 119,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Alternative Cumulative Abnormal Return Measures (p.77)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": ".elbairaV tnednepeD sa ]12,2[RAC gnisU setamitsE :4D elbaT etoned seman elbairav derocsrednU .snmuloc htneves dna tsrfi eht morf setamitse tneicffieoc ni secnereffid eht fo edutingam eht no desab detsil era selbairaV owt tsrfi ehT .elpmas eht ni sretrauq-mrfi lla esu snoitacfiiceps ehT .level %1 eht ta ecnacfiingis etoned seulav tneicffieoc dlob dna ,ecnacfiingis ni segnahc dna driht ehT .ylevitcepser ,flesti elbairav eht dna smret noitcaretni rof slortnoc on htiw snoisserger etarapes morf )tnecrep ni( setamitse stroper snmuloc tsal ehT .slortnoc fo tes lluf eht sesu snmuloc htxis dna htffi eht dna ,EUS htiw snoitcaretni rieht dna etna xe nesohc slortnoc fo tes eht dda snmuloc htruof .mrfidnayadybderetsulcerasrorredradnatS.slortnocfotesllufehtylnognisunoitcnufecnasiunlanoisnemid-hgihehtgnisusetamitsestropersnmulocowt LMD SLO SLO SLO ossal-tsop .w ecnasiuN fo tes lluF detceleS slortnoc oN :gnisu snoisserger etarapeS noitcnuf slortnoc slortnoc elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI flesti mret flesti mret flesti mret flesti mret 577.4 759.2 752.3 310.1 EUS 743.3− 796.1− 189.5− 503.2− 419.1− 184.2− 456.3− 533.0− EZIS 615.4− 633.0− 741.5− 861.2− 477.2− 992.2− 472.3− 934.1− KSIRBRA 267.0 783.1− 407.0 837.0 554.1 113.0 141.0− 114.0− LOV 810.1− 524.0 797.1 649.1 361.0− 007.1 044.1− 464.0− KSIRPXE 002.0 426.0− 321.0− 056.0 353.0 906.0 310.0 742.0 LOVLOD 144.0− 233.0− 717.0− 006.0− 492.0 979.0− 610.1 351.1− GALPER 783.0 653.0 628.0 380.0 291.0 267.0 062.0− 990.1 KNARN 905.0 994.0− 088.0 451.0− 316.0 801.0− 610.0 602.0 VEL 490.0 700.0− 889.1 574.0 100.2 066.0 767.2 296.0 RCED 642.0 241.0− 317.1 883.0 704.2 023.0 175.1 964.0 SSOL 228.2− 771.1− 617.0− 293.1− 291.0 482.1− 249.0− 486.1− ATEB 752.1 457.0− 617.4 500.1− 137.4 169.0− 837.0 561.1− TSYLANA 526.1 185.0 573.2 037.0 194.2 627.0 976.3 869.0 TERAE 536.0 897.0 594.0 297.0 102.0− 890.1 956.0− 849.0 SIFEMAS 595.0− 864.0 873.2− 944.0 213.2− 425.0 866.2− 073.0 PUNUR 763.5 026.0− 806.6 586.0− 693.6 065.0− 716.8 625.0− MB 370.1 015.0− 491.0 162.0− 054.0 242.0− 414.0− 134.0− REVONRUT 081.1 081.0− 509.0 693.0− 348.0 833.0− 748.1 132.0− QILLI 922.1− 543.0− 149.0− 581.0− 229.0− 871.0− 247.0− 603.0− ECIRP 272.8− 530.2 586.91− 792.2 675.91− 352.2 855.02− 840.2 TERTSAP 917,071 917,071 917,071 917,071 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 77 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Alternative Cumulative Abnormal Return Measures",
    "page_number": 77,
    "page_range": "p.77",
    "total_pages": 80,
    "chunk_index": 120,
    "word_count": 349,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Alternative Cumulative Abnormal Return Measures (p.77)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "REVONRUT 081.1 081.0− 509.0 693.0− 348.0 833.0− 748.1 132.0− QILLI 922.1− 543.0− 149.0− 581.0− 229.0− 871.0− 247.0− 603.0− ECIRP 272.8− 530.2 586.91− 792.2 675.91− 352.2 855.02− 840.2 TERTSAP 917,071 917,071 917,071 917,071 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 77 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Alternative Cumulative Abnormal Return Measures",
    "page_number": 78,
    "page_range": "p.78",
    "total_pages": 80,
    "chunk_index": 121,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Alternative Cumulative Abnormal Return Measures (p.78)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": ".ledoM rotcaF-3 hcnerF-amaF gnisU snruteR lamronbA detsujdA-ksiR - setamitsE :5D elbaT etoned seman elbairav derocsrednU .snmuloc htneves dna tsrfi eht morf setamitse tneicffieoc ni secnereffid eht fo edutingam eht no desab detsil era selbairaV owt tsrfi ehT .elpmas eht ni sretrauq-mrfi lla esu snoitacfiiceps ehT .level %1 eht ta ecnacfiingis etoned seulav tneicffieoc dlob dna ,ecnacfiingis ni segnahc dna driht ehT .ylevitcepser ,flesti elbairav eht dna smret noitcaretni rof slortnoc on htiw snoisserger etarapes morf )tnecrep ni( setamitse stroper snmuloc tsal ehT .slortnoc fo tes lluf eht sesu snmuloc htxis dna htffi eht dna ,EUS htiw snoitcaretni rieht dna etna xe nesohc slortnoc fo tes eht dda snmuloc htruof .mrfidnayadybderetsulcerasrorredradnatS.slortnocfotesllufehtylnognisunoitcnufecnasiunlanoisnemid-hgihehtgnisusetamitsestropersnmulocowt LMD SLO SLO SLO ossal-tsop .w ecnasiuN fo tes lluF detceleS slortnoc oN :gnisu snoisserger etarapeS noitcnuf slortnoc slortnoc elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI flesti mret flesti mret flesti mret flesti mret 711.4 407.2 490.3 061.0− EUS 870.2 049.0− 030.2 550.1 250.3 639.0 860.0 554.0 LOV 510.1 873.1− 899.2 152.0− 392.4 573.0− 745.2 210.0− SSOL 890.0 534.0− 241.0− 246.0 417.0 918.0 100.0 277.0 LOVLOD 438.0− 243.2− 092.1− 047.3− 843.0− 981.3− 276.0 084.3− GALPER 039.5− 958.0− 838.9− 474.2− 138.3− 574.1− 861.5− 622.0 EZIS 250.1 364.0− 495.1 151.0 385.1 230.0− 708.0 693.0 VEL 890.0 015.0− 148.2 211.0 153.3 102.0 313.4 702.0 RCED 518.1 655.0 510.3 748.0 521.3 029.0 176.4 871.1 TERAE 771.0− 060.2 625.0− 681.1 219.0− 946.1 145.1− 574.1 SIFEMAS 617.0 511.0− 106.1 601.0 838.1 932.0 650.3 704.0 QILLI 519.01− 368.0− 903.8− 731.1− 863.6− 012.1− 427.6− 692.1− KSIRBRA 002.0 475.1 400.0− 177.1− 753.0 976.0 062.0− 281.1 KNARN 555.1 191.0− 281.0 510.0 875.0 402.0 007.0− 220.0 REVONRUT 719.1− 787.0− 849.0− 426.0 114.0− 075.0 729.3− 399.0− KSIRPXE 531.6 657.0− 230.8 996.0− 108.7 235.0− 758.01 646.0− MB 304.1 152.0− 973.6 894.0− 085.6 532.0− 895.0 013.0− TSYLANA 459.01− 128.2 235.52− 670.3 858.52− 810.3 493.72− 478.2 TERTSAP 019.0− 400.1 385.0− 781.1 315.0− 781.1 313.0− 450.1 ECIRP 683.0 924.0 737.2− 485.0 377.2− 565.0 744.3− 683.0 PUNUR 244.2− 024.1− 305.0− 118.0− 174.0 018.0− 229.1− 134.1− ATEB 917,071 917,071 917,071 917,071 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 78 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Alternative Cumulative Abnormal Return Measures",
    "page_number": 78,
    "page_range": "p.78",
    "total_pages": 80,
    "chunk_index": 122,
    "word_count": 352,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Alternative Cumulative Abnormal Return Measures (p.78)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "TERTSAP 019.0− 400.1 385.0− 781.1 315.0− 781.1 313.0− 450.1 ECIRP 683.0 924.0 737.2− 485.0 377.2− 565.0 744.3− 683.0 PUNUR 244.2− 024.1− 305.0− 118.0− 174.0 018.0− 229.1− 134.1− ATEB 917,071 917,071 917,071 917,071 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 78 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Alternative Cumulative Abnormal Return Measures",
    "page_number": 79,
    "page_range": "p.79",
    "total_pages": 80,
    "chunk_index": 123,
    "word_count": 50,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Alternative Cumulative Abnormal Return Measures (p.79)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": ".mutnemoM dna ledoM rotcaF-3 hcnerF-amaF gnisU snruteR lamronbA detsujdA-ksiR - setamitsE :6D elbaT etoned seman elbairav derocsrednU .snmuloc htneves dna tsrfi eht morf setamitse tneicffieoc ni secnereffid eht fo edutingam eht no desab detsil era selbairaV owt tsrfi ehT .elpmas eht ni sretrauq-mrfi lla esu snoitacfiiceps ehT .level %1 eht ta ecnacfiingis etoned seulav tneicffieoc dlob dna ,ecnacfiingis ni segnahc dna driht ehT .ylevitcepser ,flesti elbairav eht dna smret noitcaretni rof slortnoc on htiw snoisserger etarapes morf )tnecrep ni( setamitse stroper snmuloc tsal ehT .slortnoc fo tes lluf eht sesu snmuloc htxis dna htffi eht dna ,EUS htiw snoitcaretni rieht dna etna xe nesohc slortnoc fo tes eht dda snmuloc htruof .mrfidnayadybderetsulcerasrorredradnatS.slortnocfotesllufehtylnognisunoitcnufecnasiunlanoisnemid-hgihehtgnisusetamitsestropersnmulocowt LMD SLO SLO SLO ossal-tsop .w ecnasiuN fo tes lluF detceleS slortnoc oN :gnisu snoisserger etarapeS noitcnuf slortnoc slortnoc elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI elbairaV noitcaretnI flesti mret flesti mret flesti mret flesti mret 925.4 197.2 870.3 044.0− EUS 668.0− 150.2− 423.1− 396.3− 022.0− 462.3− 789.0 885.3− GALPER 857.5− 833.1− 441.01− 969.2− 026.3− 297.1− 961.6− 831.0 EZIS 035.0 071.1− 574.2 072.0− 615.3 343.0− 138.2 770.0 SSOL 158.1 718.0− 718.1 261.1 518.2 111.1 370.0 504.0 LOV 850.0 814.0− 831.0− 156.0 366.0 398.0 210.0− 237.0 LOVLOD 401.1 994.0− 957.1 761.0 408.1 810.0− 909.0 534.0 VEL 771.1− 383.0− 255.1 246.0 240.1 365.0 465.0− 132.1− KSIRPXE 050.0 426.0− 919.2 060.0 111.3 371.0 242.4 791.0 RCED 121.2 845.0 183.3 168.0 406.3 509.0 114.5 333.1 TERAE 802.8− 688.0− 650.6− 914.1− 595.3− 464.1− 132.3− 435.1− KSIRBRA 383.1 378.0− 628.6 182.0− 799.6 340.0 336.0 713.0− TSYLANA 806.0 870.0− 535.1 480.0 337.1 871.0 053.3 993.0 QILLI 022.0− 529.1 926.0− 711.1 530.2− 456.1 937.2− 405.1 SIFEMAS 699.0− 381.1− 243.1− 338.0− 465.0− 017.0− 333.1− 084.1− ATEB 797.21− 379.2 630.92− 183.3 587.82− 522.3 312.03− 242.3 TERTSAP 033.6 157.0− 954.8 546.0− 226.8 605.0− 961.21 806.0− MB 955.1 900.0 340.0 641.0 763.0 963.0 438.0− 341.0 REVONRUT 140.1− 969.0 516.0− 991.1 395.0− 622.1 272.0− 680.1 ECIRP 216.0 917.0 969.2− 417.0 637.2− 647.0 541.3− 656.0 PUNUR 811.0 713.1 650.0 086.1− 401.0 667.0 606.0− 713.1 KNARN 917,071 917,071 917,071 917,071 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 79 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Alternative Cumulative Abnormal Return Measures",
    "page_number": 79,
    "page_range": "p.79",
    "total_pages": 80,
    "chunk_index": 124,
    "word_count": 354,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Alternative Cumulative Abnormal Return Measures (p.79)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  },
  {
    "text": "REVONRUT 140.1− 969.0 516.0− 991.1 395.0− 622.1 272.0− 680.1 ECIRP 216.0 917.0 969.2− 417.0 637.2− 647.0 541.3− 656.0 PUNUR 811.0 713.1 650.0 086.1− 401.0 667.0 606.0− 713.1 KNARN 917,071 917,071 917,071 917,071 snoitavresbO X X stceffe dexiF 938,2 831 12 3 selbairav fo .oN 79 Electronic copy available at: https://ssrn.com/abstract=4017917 80 Electronic copy available at: https://ssrn.com/abstract=4017917",
    "title": "Double Machine Learning: Explaining the Post - Earnings Announcement Drift",
    "source_type": "pdf",
    "document_id": "c58be5d45b5b",
    "source_file": "Double Machine Learning Explaining the Post-Earnings Announcement Drift.pdf",
    "section": "Alternative Cumulative Abnormal Return Measures",
    "page_number": 80,
    "page_range": "p.80",
    "total_pages": 80,
    "chunk_index": 125,
    "word_count": 56,
    "author": "Anonymous",
    "video_id": "",
    "video_url": "",
    "video_url_with_timestamp": "",
    "start_timestamp": "Alternative Cumulative Abnormal Return Measures (p.80)",
    "start_timestamp_seconds": 0,
    "upload_date": "D:20221016111455+02'00'",
    "duration": null
  }
]